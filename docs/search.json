{
  "articles": [
    {
      "path": "Abrindo_Manipulando.html",
      "title": "Abrindo e Manipulando Dados",
      "description": "Entendendo o mundo de Big Data\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nManipulando Dados\r\n1. Renomear Variáveis (Rename)\r\n2. Selecionar Variáveis (Select)\r\n3. Transformar Variáveis (Mutate)\r\n4. Cortar/selecionar Observações (Slice)\r\n5. Filtrar Observações (Filter)\r\nCombinando Manipulações\r\n\r\nControlando o que Aparece no Relatório Final\r\nAbrindo Dados\r\nDados em arquivos textuais (.csv, .tsv, .txt)\r\nDados em arquivos de Excel\r\nDados de SPSS, Stata e SAS\r\n\r\n\r\nManipulando Dados\r\nEstamos trabalhando com um banco de dados, mas ele não está pronto para a análise que desejamos fazer. Por exemplo, as variáveis não contêm os indicadores relevantes, os nomes das variáveis não fazem sentido, a unidade de análise precisa ser mais agregada, queremos retirar alguns outliers etc. Como podemos ‘manipular’ um banco de dados para o tamanho, a estrutura e o conteúdo apropriado para a análise desejada?\r\nFazemos a manipulação da mesma forma que trabalhamos com os ingredientes de uma receita: executando ações para cortar, selecionar e combinar os ingredientes. Sempre começando com o nosso tibble (data.frame) e aplicamos ações (‘verbos’) que transformam o nosso banco de dados.\r\nNa verdade, esta lógica de manipulação de dados baseada em ‘verbos’ é apenas uma abordagem no mundo flexível de R, e no futuro vamos ver alternativas. Por enquanto, vamos trabalhar com a abordagem de verbos do pacote tidyverse porque (i) é mais fácil para aprender, (ii) é mais sistemático, e (iii) é mais transparente para ler e entender do que outras abordagens.\r\nAntes de começar, lembre-se de abrir o projeto com o qual você trabalhou no tutorial anterior (deve aparecer na lista no menu (‘Project:’) no canto superior à direita), ou um novo projeto se necessário. Em seguida, abra um novo arquivo de R Markdown (File -> New File -> R Markdown), e apague tudo exceto o cabeçalho:\r\n\r\n---\r\ntitle: \"Examplo\"\r\nauthor: \"Jonathan\"\r\ndate: \"1 de abril 2022\"\r\noutput: html_document\r\n---\r\n\r\nOs códigos descritos no restante do tutorial só funcionam se você abrir a biblioteca do tidyverse (que já instalamos no tutorial anterior) num chunk inicial:\r\n\r\n\r\n\r\n```{r}\r\nlibrary(\"tidyverse\")\r\n```\r\nTambém sugerimos instalar e abrir o pacote tidylog, que automaticamente fornece mais informação sobre cada uma das operações que executamos no tidyverse. Por isso, executamos uma vez só no console (e não no seu script) a instalação do pacote:\r\n\r\n\r\ninstall.packages(\"tidylog\")\r\n\r\n\r\nE em seguida, adicionamos a biblioteca no início do nosso script:\r\n```{r}\r\nlibrary(\"tidyverse\")\r\nlibrary(\"tidylog\")\r\n```\r\n1. Renomear Variáveis (Rename)\r\nComeçamos com uma transformação bem simples, mas se você já abriu um banco de dados com variáveis nomeadas como ‘hu52_lm_00’ você vai entender o valor dessa transformação. Cada coluna (variável) em nosso tibble sempre tem um nome, e podemos trocá-lo a qualquer momento.\r\nPara inspecionar os nomes das variáveis num tibble, podemos simplesmente executar o nome do objeto no modo interativo e ver o que aparece na tabela abaixo do chunk ou no Console. Ou então, podemos usar a função names(). Vamos utilizar como exemplo de banco de dados os voos de Nova York, dados que usamos no tutorial anterior, lembrando que temos que abrir a biblioteca de voos primeiramente (se esqueceu dê uma olhada no tutorial 1).\r\n\r\n\r\nlibrary(\"nycflights13\")\r\nnames(flights)\r\n\r\n [1] \"year\"           \"month\"          \"day\"           \r\n [4] \"dep_time\"       \"sched_dep_time\" \"dep_delay\"     \r\n [7] \"arr_time\"       \"sched_arr_time\" \"arr_delay\"     \r\n[10] \"carrier\"        \"flight\"         \"tailnum\"       \r\n[13] \"origin\"         \"dest\"           \"air_time\"      \r\n[16] \"distance\"       \"hour\"           \"minute\"        \r\n[19] \"time_hour\"     \r\n\r\nNote que o R descreve os índices (as posições na lista) dos nomes na esquerda.\r\nQueremos renomear a variável arr_time para arrival_time - como faremos? Temos que aplicar o verbo e função rename() ao banco de dados flights. Agora temos um princípio fundamental da manipulação de dados no tidyverse: começamos com o substantivo (o objeto; o tibble) e depois aplicamos o verbo (a transformação; a função). Como em português: “A universidade [objeto] fechou [verbo]”.\r\nPara conectar o substantivo com o verbo, usamos um símbolo bizarro que se chama o ‘pipe’: %>%. Não me pergunte o motivo para usar este símbolo; apenas Deus tem a resposta. A única coisa que importa é como a usar. O modelo é:\r\n\r\n\r\nflights %>% rename()\r\n\r\n\r\n\r\nHabilidade Básica de Programação: Pipes, %>%\r\nO pipe conecta um tibble a uma função. Pode ser traduzido como ‘e depois’, ou ‘then’ em inglês. Por exemplo, “pegue o banco de dados de flights, e depois aplique a função renomear”.\r\nPodemos juntar vários pipes para combinar funções diferentes e gerar uma análise mais complexa. Por exemplo:\r\n\r\n\r\nflights %>% rename() %>% outra_funcao() %>% mais_uma_funcao()\r\n\r\n\r\n\r\n\r\nO código acima não faz nada porque ainda não especificamos qual variável renomear e o novo nome. Qual variável a renomear e o novo nome da variável são parâmetros da função rename, que tem um formato específico:\r\n\r\n\r\nflights %>% rename(arrival_time = arr_time)\r\n\r\n\r\n\r\n\r\n\r\n\r\nQual o formato aqui? Dentro dos parênteses, colocamos o novo nome primeiro, depois o sinal de igual, depois o nome antigo/original. Se digitarmos o nome original errado, a função não vai funcionar e vai aparecer uma mensagem de erro. O nome novo pode ser diversas coisas (não abuse da sua criatividade aqui), mas evite começar com números e, por enquanto para simplificar, evite usar espaços (pode usar “_” em vez de um espaço).\r\nVamos inspecionar o nosso novo tibble renomeado:\r\n\r\n\r\nflights\r\n\r\n\r\n…O que aconteceu?? Porque você acha a variável em nosso tibble ainda tem o nome antigo `arr_time’?\r\nPorque o nosso código não mudou nada: aplicar verbos não salva o novo tibble renomeado automaticamente. Efetivamente, o novo tibble renomeado desaparece no momento que é criado. Para salvar, temos que usar a seta de atribuição ao um novo objeto (se esqueceu, dê uma olhada no tutorial 1):\r\n\r\n\r\nflights_renomeado <- flights %>% rename(arrival_time=arr_time)\r\n\r\nflights_renomeado\r\n\r\n\r\nAgora, o tibble de flights_renomeado tem a variável chamada arrival_time, correto?\r\nDependendo do nosso objetivo, às vezes faz sentido salvar o nosso objeto com o mesmo nome que ele tinha antes, sobrescrevendo o conteúdo dele, ao invés de criar um novo objeto toda vez que executamos uma função. (Pelo menos, isso economiza memória).\r\n\r\n\r\nflights <- flights %>% rename(arrival_time=arr_time)\r\n\r\nflights\r\n\r\n\r\nMais uma detalhe: será que para renomear colunas diversas temos que escrever a função rename() diversas vezes?\r\n\r\n\r\nflights <- flights %>% rename(arrival_time=arr_time) %>%\r\n  rename(departure_time=dep_time)\r\n\r\n\r\nPodemos fazer isso, mas é mais eficiente fazer dentro da mesma função, separando as colunas por vírgula (e inserindo uma nova linha para deixar o código claro). Lembre-se da vírgula para separar cada renomeação, muitas vezes passamos para a linha de baixo e esquecemos a vírgula; quando rodamos o código aparece mensagem de erro e demoramos para descobrir que o único erro é a vírgula faltante.\r\n\r\n\r\nflights <- flights %>% rename(arrival_time=arr_time,\r\n                              departure_time=dep_time)\r\n\r\n\r\nObserve que você pode receber um erro aqui - por que? Já renomeamos as variáveis acima e salvamos, então arr_time não existe mais em flights para renomear.\r\n2. Selecionar Variáveis (Select)\r\nJá aprendemos o formato para utilizar funções, e tudo o que vamos aprender daqui para frente possui o mesmo padrão. Quando temos colunas demais em nosso banco de dados, sempre ajuda focar nas variáveis mais relevantes, excluindo aquelas que não serão utilizadas. Para selecionar um subconjunto das variáveis (colunas) para manter no tibble, usamos o verbo select(). De novo, começamos com o tibble, o pipe, e finalmente o verbo, select:\r\n\r\n\r\nflights %>% select(year, month, day)\r\n\r\n\r\n\r\n\r\n\r\n\r\nNote que podemos selecionar várias variáveis usando uma vírgula para separar os nomes das variáveis. Fácil, certo?\r\nMas preste atenção - se você salvar o seu objeto com o mesmo nome do original, vai perder as outras variáveis definitivamente (ou pelo menos até que abra o banco de dados original novamente ou rode o script do início de novo):\r\n\r\n\r\nflights <- flights %>% select(year, month, day)\r\n\r\n\r\n3. Transformar Variáveis (Mutate)\r\nE se quisermos criar novas variáveis? Isso é comum, por exemplo, quando queremos o PIB per capita e não simplesmente o PIB. Para isso, temos que pegar duas variáveis, PIB e população e dividir o primeiro pelo segundo. Em R, o verbo para realizar isso se chama mutate(). Ele permite a combinação, usando qualquer tipo de matématica que você desejar, de colunas que já existem no banco de dados (se quer trazer dados de fora, tem que usar um join que vamos discutir logo no futuro).\r\nComo funciona? Como sempre, pegamos o nosso tibble relevante, depois o pipe, depois a função mutate(). Dentro dos paramêtros de mutate precisamos especificar o cálculo a ser realizado usando os nomes de colunas atuais, e o nome da nova variável (coluna) em que vamos guardar o resultado do cálculo. Por exemplo, se queremos dobrar o dep_delay:\r\n\r\n\r\nflights <- flights %>% mutate(dep_delay_dobro=dep_delay*2)\r\n\r\n\r\n\r\n\r\n\r\n\r\nNote que dentro do mutate, usamos o igual “=” em vez da flecha para salvar o resultado como uma nova variável.\r\nOnde fica a nossa nova coluna? Na última posição à direita do tibble (última coluna do banco de dados).\r\nPodemos combinar variáveis múltiplas para fazer cálculos mais complexos. Por exemplo, se por algum motivo eu quero saber metade da diferença entre o dep_time e arr_time:\r\n\r\n\r\nflights <- flights %>% mutate(calculo=(arr_time-dep_time)/2)\r\n\r\n\r\nComo na matemática, lembre-se que os parênteses importam. Então o que fizemos acima (arr_time-dep_time)/2 é diferente de arr_time-dep_time/2. Se quiser, teste para ter certeza.\r\nMais uma possibilidade: podemos transformar uma coluna atual sem criar uma nova coluna. Para fazer isso, é só renomear a coluna com o mesmo nome do original, dessa maneira sobrescrevemos o conteúdo original da coluna pelo novo conteúdo que calculamos. Por exemplo, podemos recalcular o dep_delay de minutos para segundos:\r\n\r\n\r\nflights <- flights %>% mutate(dep_delay=dep_delay*60)\r\n\r\n\r\nE finalmente, podemos usar funções dentro de mutate e não simplesmente símbolos matemáticos. No futuro, isso abre um mundo de possibilidades. Por enquanto, vamos apenas usar a função tolower() para mudar a origem (variável origin) do voo de maiúsculas para minúsculas:\r\n\r\n\r\nflights <- flights %>% mutate(origin=tolower(origin))\r\n\r\n\r\nAbra os dados para ver se deu certo a função tolower().\r\n\r\nHabilidade Básica de Programação: Operações Matemáticas\r\nR serve como calculadora e é simples realizar operações matemáticas, seja com números ou com variáveis.\r\nSoma:\r\n\r\n\r\nx + y\r\n\r\n\r\nSubtração:\r\n\r\n\r\nx - y\r\n\r\n\r\nMultiplicação\r\n\r\n\r\nx * y\r\n\r\n\r\nDivisão:\r\n\r\n\r\nx / y\r\n\r\n\r\nPotência:\r\n\r\n\r\nx ^ y\r\n\r\n\r\nDivisão inteira (sem resto):\r\n\r\n\r\nx %/% y\r\n\r\n\r\nResto da divisão:\r\n\r\n\r\nx %% y\r\n\r\n\r\n\r\n4. Cortar/selecionar Observações (Slice)\r\nAté agora, trabalhamos com manipulações de variáveis (colunas). Mas podemos também mexer com as observações (linhas). Podemos, por exemplo, limitar a nossa análise apenas para a quinta linha do banco de dados usando o verbo slice().\r\n\r\n\r\nflights %>% slice(5)\r\n\r\n\r\n\r\n\r\n\r\n\r\nUm pouco triste perder todo o resto da informação…, então, como selecionamos todas as primeiras cinco linhas?\r\n\r\n\r\nflights %>% slice(1:5)\r\n\r\n\r\n\r\nHabilidade Básica de Programação: Conjuntos de números\r\nPara selecionar observações ou outros elementos de objetos, temos que criar um vetor com os índices (as posições) dos elementos desejados. Um jeito de fazer isso é usando a nossa função para criar vetores, c():\r\n\r\n\r\nlinhas_desejadas <- c(1,4,5,8,22,169)\r\n\r\n\r\nAgora, podemos usar este vetor, chamando ele por nome, dentro da função slice().\r\n\r\n\r\nflights %>% slice(linhas_desejadas)\r\n\r\n\r\nO R substituirá o objeto (o vetor) linhas_desejadas com os 6 números e devolverá um tibble das 6 linhas.\r\nTambém é possível selecionar as observações não desejadas, inserindo o sinal de menos, “-”, em frente ao número. O R devolve o tibble inteiro sem a linha identificada.\r\n\r\n\r\nflights %>% slice(-1)\r\n\r\n\r\nCompare o número de linhas do código acima com o número de linhas no tibble original de flights.\r\nPara conjuntos de números mais sistemáticos, temos várias opções. Usamos os dois pontos para indicar um conjunto sequencial de números, por exemplo 10:20 significa o mesmo que c(10,11,12,13,14,15,16,17,18,19,20).\r\n\r\n\r\nflights %>% slice(10:20)\r\n\r\n\r\nPara conjuntos não-sequenciais mais sistemáticos, podemos usar a função seq(), que tem três parâmetros: valor inicial, valor final, e incremento. Por exemplo, para selecionar cada 10 linhas nas primeiras 100 linhas, usamos:\r\n\r\n\r\nflights %>% slice(seq(from=1,\r\n                      to=100,\r\n                      by=10))\r\n\r\n\r\nQuais os números que a função seq(from=1, to=100, by=10) devolve? Copie e cole a função no “Console” para ver o resultado. Aparece (1, 11, 21, 31, 41, 51, 61, 71, 81, 91).\r\nNote que aqui usamos os nomes de cada parâmetro/argumento seguido por um sinal de igual e o valor relevante. Estes argumentos têm uma ordem oficial dentro da função, e se soubermos a ordem e especificarmos todos os argumentos, podemos evitar os nomes dos parâmetros/argumentos. O código abaixo é idêntico ao código acima:\r\n\r\n\r\nflights %>% slice(seq(1,100,10))\r\n\r\n\r\nComo podemos saber os nomes e a ordem dos argumentos? Consultamos o help da função:\r\n\r\n\r\n?seq\r\n\r\n\r\n\r\n5. Filtrar Observações (Filter)\r\nMais frequentemente, não importa a posição vertical (linha) da observação no conjunto de dados. Para limitar a nossa análise o que importa é o valor de uma variável. Por exemplo, podemos buscar apenas os dados da Ásia, do século 20, de mulheres, ou de homens acima de 18 anos de idade que moram em São Paulo.\r\nEstes critérios podem ser aplicados usando o verbo filter(). Nos parâmetros de filter(), temos que especificar as condições do banco de dados final. O R vai avaliar se o parâmetro de cada observação é verdadeiro ou falso (TRUE ou FALSE), armazenando apenas as observações ‘verdadeiras’.\r\nEm nosso banco de dados de voos, vamos selecionar apenas os voos do mês 6 (junho). Como definimos esta condição? Precisamos de três elementos:\r\nNome de variável - aqui, o mês, month.\r\nTipo de comparação - aqui, queremos selecionar um mês específico, então precisamos de uma igualdade que digitamos em R como ==. Sim, dois iguais juntos! Explicamos abaixo.\r\nCritério - aqui, qual mês? Nos dados, junho está codificado como número (int), então ‘6’.\r\n\r\n\r\nflights %>% filter(month==6)\r\n\r\n\r\n\r\n\r\n\r\n\r\nO resultado é um novo tibble com quantas linhas? Se o nosso filtro funcionou, o novo tibble deve ter bem menos observações (linhas) que o tibble original. Normalmente queremos salvar o tibble com outro nome, dado que ele representa, agora, um novo conjunto de observações:\r\n\r\n\r\nflights_junho <- flights %>% filter(month==6)\r\n\r\n\r\n\r\nHabilidade Básica de Programação: Operadores Relacionais (Comparativos)\r\nOs operadores relacionais são seis em R:\r\n\r\nOperador\r\nDescrição\r\n1\r\n==\r\nIgual\r\n2\r\n!=\r\nDiferente\r\n3\r\n<\r\nMenor\r\n4\r\n>\r\nMaior\r\n5\r\n<=\r\nMenor ou igual\r\n6\r\n>=\r\nMaior ou igual\r\nSimples. Alguns exemplos de uso básico de operadores abaixo. Rodar o código para verificar quais condições são verdadeiras ou falsas (TRUE ou FALSE).\r\n\r\n\r\n42 == 41\r\n42 != 41\r\n(2 + 2) == (3 + 1)\r\n(2 + 2) != (3 + 1)\r\n5 > 3\r\n5 < 3\r\n42 > 42\r\n42 < 41\r\n42 >= 42\r\n42 <= 41\r\n\r\n\r\nOperadores relacionais também valem para textos:\r\n\r\n\r\n\"texto\" == \"texto\"\r\n\"texto\" == \"texTo\"\r\n\"texto\" != \"texto\"\r\n\r\n\r\nNote no segundo exemplo que o R é “case sensitive”, ou seja, diferencia maiúsculas de minúsculas ao comparar textos.\r\nTextos também podem ser ordenados (lexicograficamente, isto é, alfabeticamente):\r\n\r\n\r\n\"a\" > \"b\"\r\n\"a\" < \"b\"\r\n\"A\" < \"b\"\r\n\"A\" > \"a\"\r\n\r\n\r\nE valores lógicos? Veja se entende o que acontece nos exemplos abaixo:\r\n\r\n\r\nTRUE == 1\r\nFALSE == 0\r\nTRUE > FALSE\r\n\r\n\r\nPodemos comparar valores armazenados em variáveis da mesma maneira que fizemos nos exemplos até aqui:\r\n\r\n\r\nx <- 5\r\ny <- 10\r\nx > y\r\n\r\n\r\n\r\n\r\nPodemos combinar critérios diversos usando o símbolo de ‘e’, “&”:\r\n\r\n\r\nflights_junho_5 <- flights %>% filter(month==6 & day==5)\r\n\r\n\r\nIncluindo maior (>) e menor (<), podemos gerar comparações complexas, ex. todos os voos da manhã do dia 5 de julho:\r\n\r\n\r\nflights_junho_5_manha <- flights %>% filter(month==6 & day==5 & dep_time<1200)\r\n\r\n\r\n\r\nHabilidade Básica de Programação: Operadores Lógicos\r\nPara combinar critérios múltiplos no mesmo filtro, temos que usar os operadores lógicos.\r\n\r\nOperador\r\nDescrição\r\n1\r\n!\r\nNão\r\n2\r\n&\r\nE\r\n3\r\n|\r\nOu\r\nVeja a tabela de possibilidades de combinação de duas proposições com a conjunção “&”:\r\nProposição 1\r\nProposição 2\r\nCombinação\r\nTRUE\r\nTRUE\r\nTRUE\r\nTRUE\r\nFALSE\r\nFALSE\r\nFALSE\r\nTRUE\r\nFALSE\r\nFALSE\r\nFALSE\r\nFALSE\r\nSe o valor atende às duas condições, então o resultado é TRUE. Se ao menos uma proposição é falsa, sob a conjunção “e”, então a combinação das proposições também é falsa.\r\nVeja a tabela de possibilidades de combinação de duas proposições com a conjunção “ou”:\r\nProposição 1\r\nProposição 2\r\nCombinação\r\nTRUE\r\nTRUE\r\nTRUE\r\nTRUE\r\nFALSE\r\nTRUE\r\nFALSE\r\nTRUE\r\nTRUE\r\nFALSE\r\nFALSE\r\nFALSE\r\nCom esta nova flexibilidade, temos que pensar com cuidado para construir o filtro apropriado. E temos que usar os parênteses apropriados, porque a lista acima é em ordem de prioridade (como na matemática quando multiplicação acontece antes de adição, aqui “E” acontece antes de “OU”). Por exemplo, se quisermos todos os voos que atrasaram na chegada por mais de 50 minutos, e que decolaram antes das 5h ou que chegaram em Atlanta (ATL), temos que escrever assim:\r\n\r\n\r\nflights %>% filter((dep_time<=500 | dest==\"ATL\") & arr_delay>=50)\r\n\r\n\r\nO resultado é diferente do pedido quando tiramos os parênteses:\r\n\r\n\r\nflights %>% filter(dep_time<=500 | dest==\"ATL\" & arr_delay>=50)\r\n\r\n\r\nNote que o número de linhas é bem diferente. Aqui, pedimos para todos os voos que decolaram antes das 5h (se tivesse atraso ou não), juntado com um outro conjunto os voos que decolaram de Atlanta com atraso de 50 minutos na chegada.\r\nÉ fácil pedir o inverso deste conjunto usando o símbolo para negação, !:\r\n\r\n\r\nflights %>% filter(!((dep_time<=500 | dest==\"ATL\") & arr_delay>=50))\r\n\r\n\r\n\r\nCombinando Manipulações\r\nFrequentemente, limpar um banco de dados exige dezenas de transformações para construir o banco de dados apropriado para a nossa análise. A lógica e estrutura de cada ação acima nos permite combinar operações em sequência; em uma sequência de pipes e verbos. Depois de uma ação, simplesmente continuamos com mais um pipe (%>%) e a próxima ação.\r\n\r\n\r\nflights %>% \r\n  rename(arrival_time=arr_time) %>% \r\n  mutate(dep_delay=dep_delay*60) %>%\r\n  filter(month==6 & day==5) %>% \r\n  select(year, month, day, arrival_time, dep_delay)\r\n\r\n\r\nÉ importante entender que depois de cada ação, o banco de dados encaminhado à próxima ação é o resultado da ação anterior. Então na linha final, select(year, month, day, arr_time, dep_delay) não funcionará, pois arr_time já foi renomeado para arrival_time e temos que fazer referência ao novo nome. Quando você enfrenta um erro num conjunto de código complexo, uma dica é rodar o seu código ação por ação em sequência, ex. selecionando flights %>% rename(arrival_time=arr_time) primeiro para saber se este componente dá um erro.\r\nVoltando à analogia de preparar uma refeição, o código acima é uma receita: Pegue o banco de dados de flights, depois renomeie a variável arr_time, depois multiplique a variável dep_delay por 60, depois filtre as observações para aquelas do dia 5 de junho, depois selecione as cinco variáveis (year, month, day, arrival_time, dep_delay), e devolva o banco de dados final.\r\nNote também que no código acima inserimos uma nova linha depois de cada pipe; isso não é necessário mas ajuda a organizar o código e deixá-lo mais fácil para ler e entender no futuro.\r\n\r\nExercício 1: Manipulando dados\r\nCom essas novas habilidades, vamos preparar uma análise rápida do banco de dados flights com o objetivo de produzir um relatório em html no final. Gere uma tabela apropriada para cada critério:\r\nOs voos de United (carrier UA) que decolaram no dia 25 de janeiro.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(carrier==\"UA\" & month==1 & day==25)\r\n\r\n\r\nOs voos de JetBlue (carrier B6) que decolaram com mais de 300 minutos de atraso de Newark (origin EWR).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(carrier==\"B6\" & dep_delay>300 & origin==\"EWR\")\r\n\r\n\r\nCalcule a velocidade dos voos que decolaram de LaGuardia (origin LGA) no dia 7 de setembro antes das 6h. Lembre-se que velocidade é a distância dividida por tempo. (Qual é a unidade desta velocidade?)\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"LGA\" & month==9 & day==7 & dep_time<600) %>%\r\n  mutate(velocidade=distance/air_time)\r\n\r\n\r\nUma tabela com apenas o atraso na chegada de todos os voos atrasados por pelo menos 60 minutos que partiram do aeroporto Newark e chegaram em Buffalo (BUF) no dia seis de todos os meses.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(dest==\"BUF\" & origin==\"EWR\" & arr_delay>=60 & day==6) %>%\r\n  select(arr_delay)\r\n\r\n\r\nUma tabela dos números dos aviões (tailnum), destino, distância e a velocidade em milhas por hora para voos que voaram em maio pelo menos 1000 milhas ou com velocidade acima de 500 milhas por hora.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% mutate(velocidade=distance/(air_time/60)) %>%\r\n  filter((distance>1000 | velocidade>500) & month==5) %>%\r\n  select(tailnum, dest, distance, velocidade) \r\n\r\n\r\nPrepare os resultados de todas as análises acima em tabelas usando a opção de R Markdown de df_print: paged (veja o Tutorial 1), e faça o knit do seu script de R markdown para produzir o relatório final.\r\n\r\nControlando o que Aparece no Relatório Final\r\nOs nossos relatórios finais são profissionais e claros, mas ficam ‘técnicos’ quando mantemos as várias linhas de código e informações do R. Isso é importante se quiser documentar e comunicar exatamente como você analisou os dados, mas provavalmente o seu orientandor não tem interesse em saber como foi feito em detalhes. Como geramos um relatório ‘limpo’ para o público geral?\r\nO R Markdown nos permite controlar os produtos de cada chunk individualmente. Existem pelo menos cinco tipos de produtos possíveis para cada chunk, e decidimos quais deles devem aparecer no relatório final com um argumento na linha inicial de cada chunk:\r\nTipo de Conteúdo\r\nQuero\r\nNão Quero\r\nCódigo em si\r\necho=TRUE\r\necho=FALSE\r\nResultados da execução do código\r\nresults=‘markup’\r\nresults=‘hide’\r\nErros\r\nerror=TRUE\r\nerror=FALSE\r\nAvisos\r\nwarning=TRUE\r\nwarning=FALSE\r\nMensagens\r\nmessage=TRUE\r\nmessage=FALSE\r\nO padrão (default) é para incluir todos os cinco tipos de conteúdo no relatório final. Mas na prática, normalmente não queremos mostrar para o leitor o código, erros, avisos e mensagens. Para cada chunk, podemos especificar as opções assim:\r\n```{r, echo=FALSE, error=FALSE, warning=FALSE, message=FALSE}\r\n600/30\r\n```\r\nSe compilamos o relatório com ‘Knit’, a única coisa que será impressa no documento final é o resultado do cálculo (20), nada do código ou o pensamento do R.\r\nPorém, num relatório grande, teremos dezenas de chunks e fica chato especificar todas as opções para cada um dos chunks. Então uma alternativa é ajustar o padrão da nossa análise para que, por exemplo, echo=FALSE seja o padrão. O melhor jeito é adicionar um novo chunk no início do seu script com a seguinte linha:\r\n```{r, echo=FALSE}\r\nknitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE)\r\n```\r\nIsso indica para o R não imprimir o código original de nenhum chunk. Note que temos que usar echo=F na linha inicial deste chunk também para esconder esta linha de código porque o novo padrão só é aplicado depois da conclusão deste chunk.\r\n\r\nExercício 2: Relatórios Limpos\r\nExperimente adicionar um chunk com essa linha acima (knitr::opts_chunk$set(echo=FALSE, error=FALSE, warning=FALSE, message=FALSE)) acima como o primeiro no seu relatório do Exercício 1, e ‘Knit’ de novo. Veja quão mais simples e bonito fica o seu relatório!\r\n\r\nAbrindo Dados\r\nDados em arquivos textuais (.csv, .tsv, .txt)\r\nAgora que estamos especialistas na manipulação de dados já disponíveis em R, queremos analisar dados mais interessantes e relevantes para a nossa própria pesquisa. Isso exige a abertura de arquivos externos; bancos de dados que criamos ou recebemos de outros estudos. Lembrando que o nosso script vai processar os comandos cada vez que é executado pelo botão ‘Knit’, então temos que incorporar a abertura de dados em código também, dentro do script.\r\nExistem muitas funções para abrir arquivos de dados, mas, para simplificar, neste curso vamos nos concentrar em algumas das mais flexíveis, simples e úteis para trabalhar com dados ‘retangulares’ (.csv, .tsv, .txt). As funções são parte da biblioteca tidyverse que já abrimos.\r\nProvavelmente a função mais usada é read_csv, que abre arquivos com extensão .csv. Em vez de abrir arquivos do nosso computador, também podemos abrir links online e, para simplificar, disponibilizamos vários arquivos em nosso repositório do github. Para começar, vamos salvar o url do link de um arquivo .csv como um objeto, file1, e abri-lo.\r\n\r\n\r\nfile1 <- \"https://raw.githubusercontent.com/leobarone/ifch_intro_r/master/data/bf_amostra_hv.csv\"\r\ndados <- read_csv(file1)\r\n\r\n\r\n‘dados’ deve aparecer como um objeto - um tibble - em seu ‘Environment’.\r\nA função read_delim nos dá mais flexibilidade para lidar com tipos incomuns de arquivos. Por exemplo, podemos especificar o caractere usado para separar as colunas (por padrão, esta é a vírgula em read_csv, mas muitos dados brasileiros usam “;” como padrão, já que a vírgula é, no Brasil, um separador decimal):\r\n\r\n\r\ndados <- read_delim(file1, \r\n                    delim = \",\")\r\n\r\nfile_semi_colon <- \"https://raw.githubusercontent.com/leobarone/ifch_intro_r/master/data/bf_amostra_hp.csv\"\r\ndados <- read_delim(file_semi_colon, \r\n                    delim = \";\")\r\n\r\nfile_tab <- \"https://raw.githubusercontent.com/leobarone/ifch_intro_r/master/data/bf_amostra_ht.csv\"\r\ndados <- read_delim(file_tab, \r\n                    delim = \"\\t\")\r\n\r\n\r\nO padrão de read_delim (e read_csv) é importar a primeira linha como o nome das variáveis. Se nossos dados não tiverem um header (cabeçalho, ou seja, nomes das variáveis na primeira linha), a primeira linha de dados se torna equivocadamente o nome das variáveis (inclusive os números, que aparecem antecedidos por um “X”). Para corrigir o problema utilizamos o argumento “col_names”, que deve ser igual a “FALSE” para os dados armazenados sem nomes de colunas, por exemplo:\r\n\r\n\r\nfile_sem_header <- \"https://raw.githubusercontent.com/leobarone/ifch_intro_r/master/data/bf_amostra_nv.csv\"\r\ndados <- read_delim(file_sem_header, \r\n                    col_names = F, \r\n                    delim = \",\")\r\n\r\n\r\nAlém dos valores lógicos, “col_names” também aceita um vetor com novos nomes para as colunas como argumento:\r\n\r\n\r\ndados <- read_delim(file_sem_header, \r\n                    col_names = c(\"estado\", \"municipio_cod\", \"municipio_nome\",\r\n                                  \"NIS\", \"transferido\"),\r\n                    delim = \",\")\r\n\r\n\r\nPor vezes, é interessante definir as classes das variáveis a serem importadas, para evitar novas transformações quando os dados forem importados. O argumento col_types deve ser uma sequência de caracteres onde “c” = “character”, “d” = “double” (numérico), “l” = “logical” e “i” = “integer” (números inteiros). Por exemplo:\r\n\r\n\r\ndados <- read_delim(file1, \r\n                    delim = \",\", \r\n                    col_types = \"cicid\")\r\n\r\n\r\nPerceba que, quando abrimos os dados sem especificar o tipo da coluna, a função read_csv tenta identificá-los automaticamente.\r\nUma complexidade de abertura de dados numéricos brasileiros é o uso da vírgula como separador decimal e o ponto para indicar milhares. Assim, temos que especificar no argumento locale essas diferenças.\r\n\r\n\r\ndados <- read_delim(file1, \r\n                    delim = \",\", \r\n                    locale = locale(decimal_mark=\",\",grouping_mark=\".\"))\r\n\r\n\r\nTambém podemos usar locale para especificar o formato da hora e o formato da data do arquivo que estamos lendo.\r\nFinalmente, é comum termos problemas para abrir arquivos que contenham caracteres especiais, pois há diferentes formas do computador interpretar vogais acentuadas, cedilha, etc. O “encoding” de cada arquivo varia de acordo com o sistema operacional e aplicativo no qual foi gerado.\r\n\r\n\r\ndados <- read_delim(file1, \r\n                    delim = \",\", \r\n                    locale = locale(encoding='latin1'))\r\n\r\n\r\nPara resolver este problema, informamos ao R o parâmetro encoding dentro do locale, que indica qual é o “encoding” esperado do arquivo.\r\n\r\nHabilidade Básica de Programação: Encoding dos Arquivos\r\nInfelizmente não há formas automáticas infalíveis de descobrir o “encoding” de um arquivo e é preciso conhecer como foi gerado – seja você quem produziu o arquivo ou se você teve acesso à documentação – ou partir para tentativa e erro. Alguns “encodings” comuns são “latin1”, “latin2”, “utf8” e “WINDOWS-1252”, mas há diversos outros. Se o arquivo com o qual estamos trabalhando não contém caracteres especiais, não é preciso fazer nada; o R vai processá-lo adequadamente.\r\nO formato mais flexível, se pretende gerar os seus próprios dados, é UTF-8 (utf8).\r\n\r\nDados em arquivos de Excel\r\nEditores de planilha são, em geral, a primeira ferramenta de análise de dados que aprendemos. Diversas organizações disponibilizam (infelizmente) seus dados em formato .xls ou .xlsx e muitos pesquisadores utilizam editores de planilha para construir bases de dados.\r\nVamos ver como obter dados em formato .xls ou .xlsx diretamente, sem precisar abrir os arquivos e exportá-los para um formato de texto.\r\nVamos trabalhar com readxl. Importe a biblioteca (não é preciso instalar, já está instalada):\r\n\r\n\r\nlibrary(\"readxl\")\r\n\r\n\r\nNosso exemplo será a Pesquisa Perfil dos Municípios Brasileiros de 2005, produzida pelo IBGE e apelidada de MUNIC. Diferentemente das demais funções deste tutorial, precisamos baixar o arquivo para o computador e acessá-lo localmente. É uma boa oportunidade para praticar. Faça o download diretamente no browser no site do IBGE e descompacte para o arquivo “Base 2005.xls” na pasta do seu projeto.\r\nNote que um ganho enorme de trabalhar dentro de um projeto é que não precisamos nos preocupar com a especificação do endereço inteiro de cada arquivo (o “C:\\Users\\Documents\\…”) - só usamos o nome do arquivo e o R acessa tudo na pasta do projeto. (Se for num sub-pasta, podemos especificar “Subpasta/Base 2005.xls”)\r\nCom a função excel_sheets examinamos quais são as planilhas existentes do arquivo:\r\n\r\n\r\nexcel_sheets(\"Base 2005.xls\")\r\n\r\n\r\nNo caso, temos 11 planilhas diferentes (e um bocado de mensagens de erro estranhas). O dicionário, para quem já trabalhou alguma vez com a MUNIC, não é uma base de dados, apenas textos espalhados entre células. As demais, no entanto, têm formato adequado para um tibble.\r\nVamos importar os dados da planilha “Variáveis externas”. As duas maneiras abaixo se equivalem:\r\n\r\n\r\n# 1\r\nexternas <- read_excel(\"Base 2005.xls\", \"Variáveis externas\")\r\n\r\n# 2\r\nexternas <- read_excel(\"Base 2005.xls\", 11)\r\n\r\n\r\nA função read_excel aceita os argumentos “col_names” e “col_types” tal como as funções de importação do pacote readr. Observe que o R não se importa e não lembra como o arquivo foi aberto - quando aberto por read_csv ou read_excel ou outra função, o tibble em R é idêntico.\r\nDados de SPSS, Stata e SAS\r\nO R é bastante flexível quanto à importação de dados de outros softwares estatísticos. Para este fim há também um pacote haven, que é, advinhe só, parte do tidyverse.\r\n\r\n\r\nlibrary(\"haven\")\r\n\r\n\r\nBasicamente, há cinco funções de importação de dados em haven: read_sas, para dados em SAS; read_stata e read_dta, idênticas, para dados em formato .dta gerados em Stata; e read_sav e read_por, uma para cada formato de dados em SPSS. O uso, como era de se esperar, é bastante similar ao que vimos no tutorial todo.\r\nVamos usar como exemplo o Latinobarômetro 2015, que está disponível para SAS, Stata e SPSS. Vamos fazer o processo manual de baixar os dados da página ‘Data’, e descompactar os arquivos de 2015. Vamos ignorar SAS por razões que não interessam agora e por não ser uma linguagem popular nas ciências sociais.\r\nVejamos o uso das funções em arquivos de diferentes formatos:\r\n\r\n\r\n# SPSS\r\nlatino_barometro_spss <- read_spss(\"Latinobarometro_2015_Eng.sav\")\r\n\r\n# Stata\r\nlatino_barometro_stata <- read_stata(\"Latinobarometro_2015_Eng.dta\")\r\n\r\n\r\nSimples assim.\r\nHá critérios de conversão de variáveis categóricas, rótulos e etc, adotados pelo R ao importar arquivos de outras linguagens, mas você pode descobri-los testando sozinho/a.\r\n\r\nExercício 3: Abrindo Dados Eleitorais\r\nAbre o link aqui com dados da eleição de 2016 em Acre do site do Tribunal Superior Eleitoral. Baixá-lo e dê unzip nele.\r\nUse uma função apropriada para abrir o arquivo em R. Verifique quantas colunas existem no banco (deve ser mais que uma!).\r\n\r\n\r\nMostrar Código\r\n\r\ndata <- read_delim(\"arquivo.csv\",\r\n                   delim=\";\")\r\n\r\n\r\nUse o arquivo leiame.pdf que fica no zip com o arquivo do TSE para identificar o encoding dos dados, e os nomes das variáveis. Incorpore esta informação na abertura do arquivo. (Imagine que os nomes das colunas já não existam dentro do banco de dados - isso foi o caso até este ano!).\r\n\r\n\r\nMostrar Código\r\n\r\ndata <- read_delim(\"arquivo.csv\",\r\n                   delim=\";\",\r\n                   locale=locale(encoding = \"latin1\"),\r\n                   col_names=c(\"Variavel_1\",\"Variavel_2\",\"...\"))\r\n\r\n\r\nCrie uma tabela bonita em R Markdown dos dados do TSE, e verifique que o número de colunas e observações fazem sentido.\r\nTente manipular a base utilizando as funções que aprendemos no tutorial de hoje para selecionar colunas e observações específicas.\r\n\r\n\r\n\r\nLeitura para Tutorial 3\r\nAntes da próxima aula, por favor leia R 4 Data Science, Capítulos 12, 15, 27\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:11:27-03:00"
    },
    {
      "path": "Analise_Texto.html",
      "title": "Análise de Texto",
      "author": [],
      "contents": "\r\n\r\nContents\r\nO que há em uma palavra? (str_length, str_detect)\r\nTransformando Strings (str_replace, str_split)\r\nTokenizer e Padronizar o Texto (unnest_tokens)\r\nFrequência de Palavras\r\nAnálise de Sentimento\r\nComparando Documentos\r\n\r\nO que há em uma palavra? (str_length, str_detect)\r\nPalavras e conjuntos de caracteres são coisas complexas que podemos manipular e transformar da mesma forma que processamos números. É importante entender que o R trata todos os textos e as palavras como ‘strings’: conjuntos sequenciais de caracteres específicos. Por exemplo, veja o string do nome do primeiro aeroporto no banco de dados airports de nycflights13.\r\n\r\n\r\nlibrary(\"nycflights13\")\r\nlibrary(\"tidyverse\")\r\nlibrary(\"tidylog\")\r\n\r\nairports %>% slice(1) %>% pull(name)\r\n\r\n[1] \"Lansdowne Airport\"\r\n\r\nO pacote stringr fornece uma variedade de funções para trabalhar com strings, todos começando com str_. Uma das funções mais úteis e fáceis é medir o número de caracteres com str_length():\r\n\r\n\r\nairports <- airports %>% mutate(caracteres=str_length(name))\r\n\r\n\r\nUma tarefa comum é identificar a presença de um string com str_detect(). Por exemplo, queremos identificar os aeroportos que contém a palavra ‘field’ (a descrição de um aeroporto pequeno):\r\n\r\n\r\nairports <- airports %>% mutate(string_field=str_detect(name, \"Field\"))\r\n\r\n\r\nObserve que o resultado aqui é verdade/falsa (TRUE/FALSE). Para identificar quantos “field”s temos nos Estados Unidos podemos usar a nova coluna para contar.\r\n\r\n\r\nairports %>% group_by(string_field) %>%\r\n  tally()\r\n\r\n\r\n\r\n\r\nstring_field\r\n\r\n\r\nn\r\n\r\n\r\nFALSE\r\n\r\n\r\n1386\r\n\r\n\r\nTRUE\r\n\r\n\r\n72\r\n\r\n\r\nTome cuidado com letras minúsculas vs. maiúsculas - elas são tratadas diferentemente!\r\nIdentificar strings é um tema de programação enorme, pois não precisamos usar uma palavra exata e fixa; podemos usar um ‘modelo’ genérico para capturar uma variedade de possibilidades. Isso se chama um ‘regex’, uma ‘expressão regular’. Por exemplo, para capturar aeroportos que contém ‘Regional’ ou ‘Rgnl’, usamos o símbolo ‘|’ (como em filter).\r\n\r\n\r\nairports %>% mutate(string_regional=str_detect(name, \"Regional|Rgnl\")) %>%\r\n  filter(string_regional==TRUE) %>%\r\n  select(name)\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\nSchaumburg Regional\r\n\r\n\r\nFinger Lakes Regional Airport\r\n\r\n\r\nPhoenix Regional Airport\r\n\r\n\r\nApalachicola Regional Airport\r\n\r\n\r\nAbilene Rgnl\r\n\r\n\r\nAberdeen Regional Airport\r\n\r\n\r\nSouthwest Georgia Regional Airport\r\n\r\n\r\nJimmy Carter Regional\r\n\r\n\r\nWaco Rgnl\r\n\r\n\r\nAugusta Rgnl At Bush Fld\r\n\r\n\r\nQue tal identificarmos os nomes que começam com ‘Z’? Para detectar caracteres apenas no início do string, usamos ‘^’. Para detectar caracteres apenas no final do string, usamos ‘$’ depois do caracter.\r\n\r\n\r\nairports %>% mutate(string_z=str_detect(name, \"^Z\")) %>%\r\n  filter(string_z==TRUE) %>%\r\n  select(name)\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\nZachar Bay Seaplane Base\r\n\r\n\r\nZamperini Field Airport\r\n\r\n\r\nAs possibilidades inúmeras e, às vezes, complexas - por exemplo, é possível identificar os nomes que contém pelo menos dois ’f’s ou ’g’s juntos, através do código abaixo:\r\n\r\n\r\nairports %>% mutate(string_ffgg=str_detect(name, \"[fg]{2,}\")) %>%\r\n  filter(string_ffgg==TRUE) %>%\r\n  select(name)\r\n\r\n\r\n\r\n\r\nname\r\n\r\n\r\nJefferson County Intl\r\n\r\n\r\nEffingham Memorial Airport\r\n\r\n\r\nJefferson County Airpark\r\n\r\n\r\nGriffin-Spalding County Airport\r\n\r\n\r\nBiggs Aaf\r\n\r\n\r\nBuffalo Niagara Intl\r\n\r\n\r\nFlagstaff Pulliam Airport\r\n\r\n\r\nMcDuffie County Airport\r\n\r\n\r\nJefferson City Memorial Airport\r\n\r\n\r\nCoffman Cove Seaplane Base\r\n\r\n\r\nNão se preocupe com todos os detalhes do ‘regex’ de texto - eles são complexos e bastante difíceis de lembrar, mas se precisar no futuro, pode utilizar a referência na segunda página do cheatsheet de stringr aqui.\r\n\r\nHabilidade Básica de Programação: Transformando PDFs em Texto Editável\r\nUm dos formatos mais comuns para a disponibilização de textos é o PDF, um formato não editável. Porém na maioria dos casos é fácil traduzir um PDF em texto simples que o R pode entender. Usamos o pacote pfdtools e a função pdf_text().\r\nPor exemplo, vamos abrir um artigo recente da Revista Brasileira da Ciência Política.\r\n\r\n\r\n#install.packages(\"pdftools\")\r\nlibrary(\"pdftools\")\r\n\r\n\r\n\r\n\r\nartigo <- tibble(páginas=pdf_text(\"https://cutt.ly/Sy4vi7F\"))\r\n\r\n\r\nQual é o resultado de pdf_text()? É um vetor de strings - um para cada página no PDF. E para conveniência nós já inserimos o vetor como uma coluna de um tibble.\r\n\r\nTransformando Strings (str_replace, str_split)\r\nQuando recebemos um banco de dados com strings, existe uma variação incrível no uso de palavras, refletindo o estilo e contexto do documento. Mas queremos trabalhar apenas com strings que nos interessam. Isso exige a manipulação e substituição de strings complexos ou “sujos”.\r\nPor exemplo, vamos substituir as instâncias de ‘Rgnl’ com ‘Regional’ com str_replace para deixar os strings mais consistentes. Os argumentos são (i) a coluna do tibble que contém os strings, (ii) o modelo (um regex) de caracteres para identificar, e, em seguida, (iii) o string para substituir.\r\n\r\n\r\nairports <- airports %>% mutate(name=str_replace(name, \"Rgnl\", \"Regional\"))\r\n\r\n\r\nOu, por exemplo, podemos substituir os hífens com um espaço para padronizar os strings, já que alguns usam hífens e outros não:\r\n\r\n\r\nairports <- airports %>% mutate(name=str_replace(name, \"-\", \" \"))\r\n\r\n\r\nObserve que os nomes dos aeroportos são geralmente compostos por várias palavras - se quisermos manter apenas a primeira palavra, temos que dividir o string único em várias partes. Nessa situação, usamos a função str_split, especificando um string (um regex) para o local da divisão. Por exemplo, para separar cada palavra temos que dividir por espaço:\r\n\r\n\r\nairports <- airports %>% mutate(nome_parcial=str_split(name, \" \"))\r\n\r\n\r\nComo fica o resultado? Cada linha tem um vetor com as palavras únicas separadas. Note que o comprimento do vetor varia para cada linha - pode ter 1, 2, 3 ou mais elementos, dependendo do número de espaços no string original. Podemos selecionar, por exemplo, a primeira palavra, aproveitando da função map do tutorial passado, e usando ‘1’ para pedir o primeiro elemento do vetor, ou tail para pedir o último elemento:\r\n\r\n\r\nairports <- airports %>% mutate(nome_parcial_primeiro=map_chr(nome_parcial, 1))\r\n\r\n\r\n\r\n\r\nairports <- airports %>% mutate(nome_parcial_final=map_chr(nome_parcial, tail, n=1))\r\n\r\n\r\nLembre-se da função separate() do Tutorial 3? É bem parecida com str_split(). A diferença é que o produto de separate não é simplesmente um vetor - mas está distribuído em colunas novas dentro do nosso tibble. Isso é muito conveniente, mas exige que determinemos o número de parcelas em que dividimos o string em avanço. Por exemplo, com separate() fica mais difícil encontrar a última palavra do nome do aeroporto como calculamos acima.\r\nseparate() é mais útil quando temos um formato fixo com um número de parcelas previsível. Por exemplo, podemos dividir a coluna tzone entre os partes antes e depois do ‘/’:\r\n\r\n\r\nairports <- airports %>% separate(tzone, \"/\", into=c(\"País\", \"Região\"))\r\n\r\n\r\nVale a pena pensar bem se str_split() (dentro de mutate()), ou separate() é mais apropriado em cada situação.\r\n\r\nHabilidade Básica de Programação: Caracteres de Escape\r\nEm algumas situações, é difícil identificar ou dividir por um caractere quando esse caractere é usado no código de programação mesmo. Por exemplo, definimos o string para dividir entre aspas: \"\", mas é possível querer dividir um string por aspas, por exemplo para dividir uma citação do autor.\r\nComo faremos? Temos que usar um indicador específico - um Caractere de ‘Escape’ para informar p R que queremos tratar o caractere como parte do string e não como parte do código de programação. O Caractere de ‘Escape’ em R é ‘\\’. Então precisamos indicar “\\”” para dividir por aspas. E se queremos dividir pela barra em si “\\”?? Usamos quatro! “\\\\\\\\”.\r\n\r\nVisualizando Strings\r\nUm jeito comum de apresentar a frequência de strings é uma nuvem de palavras - um ‘wordcloud’ - que exige os pacotes wordcloud e tm.\r\n\r\n\r\n#install.packages(\"wordcloud\")\r\n#install.packages(\"tm\")\r\nlibrary(\"wordcloud\")\r\nlibrary(\"tm\")\r\n\r\nairports %>% pull(name) %>% wordcloud()\r\n\r\n\r\n\r\nPara mais controle de apresentação, é possível criar o wordcloud em ggplot com um pouco mais de esforço: veja o pacote ggwordcloud.\r\n\r\nExercício 1: Trabalhando com Strings\r\nNo banco de dados airlines do pacote nycflights13, qual porcentagem dos nomes das companhias aéreas contém a palavra ‘Airlines’ e qual porcentagem contém a palavra ‘Airways’?\r\n\r\n\r\nMostrar Código\r\n\r\nairlines %>% mutate(airlines=str_detect(name, \"Airlines\")) %>%\r\n  group_by(airlines) %>%\r\n  tally() %>%\r\n  mutate(Pct=100*(n/sum(n)))\r\n\r\nairlines %>% mutate(airlines=str_detect(name, \"Airways\")) %>%\r\n  group_by(airlines) %>%\r\n  tally() %>%\r\n  mutate(Pct=100*(n/sum(n)))\r\n\r\n\r\nNo mesmo banco, substitua os nomes das companhias aéreas que contém ‘Inc.’ com ‘Incorporated’, e aquelas que contém ‘Co.’ com ‘Company’. (Observe que ‘.’ é um caracter especial, então tem que buscar ele com ‘\\\\.’).\r\n\r\n\r\nMostrar Código\r\n\r\nairlines\r\nairlines <- airlines %>% mutate(name=str_replace(name, \"Inc\\\\.\", \"Incorporated\"),\r\n                    name=str_replace(name, \"Co\\\\.\", \"Company\"))\r\n\r\n\r\nGere um nome curto para cada companhia aérea, refletindo apenas a primeira palavra do nome.\r\n\r\n\r\nMostrar Código\r\n\r\nairlines <- airlines %>% mutate(nome_curto=str_split(name, \" \"),\r\n                                nome_curto=map_chr(nome_curto, 1))\r\n\r\n\r\nCrie um ‘wordcloud’ dos nomes das companhias aéreas.\r\n\r\n\r\nMostrar Código\r\n\r\nairlines %>% pull(name) %>% wordcloud()\r\n\r\n\r\n\r\nTokenizer e Padronizar o Texto (unnest_tokens)\r\n\r\nPara os fins de análise de texto queremos simplificar e padronizar as milhões de variedades que cada língua permite para que podemos reconhecer a presença das mesmas palavras/sentidos mesmo em contextos diferentes. Por exemplo, a mesma palavra pode aparecer em vários formatos: ‘Regional’, ‘regional’, ‘Rgnl’, ‘Region’, ‘region’, ‘Regionally’, ‘regionally’ etc. Mas todos representam o mesmo ‘conceito’ e queremos reconhecer que eles estão falando do mesmo conceito quando analisamos o texto.\r\nPara ilustrar as possibilidades com um texto mais completo, vamos acessar o texto inteiro do livro “Dom Casmurro” de Machado de Assis, disponível no site do Project Gutenberg. Podemos usar o pacote gutenbergr para acessar o texto em um formato bem conhecido - um tibble. O pacote permite baixar o texto por código numérico.\r\n\r\n\r\n# install.packages(\"gutenbergr\") ou devtools::install_github(\"ropensci/gutenbergr\")\r\n# install.packages(\"urltools\") #Se necessário; depende do sistema\r\nlibrary(\"gutenbergr\")\r\nlibrary(\"urltools\")\r\n\r\n#http://www.gutenberg.org/cache/epub/55752/pg55752.txt #Machado de Assis, Dom Casmurro\r\n\r\nAssis <- gutenberg_download(55752, mirror = \"https://gutenberg.pglaf.org/\")\r\n\r\n\r\nTemos que limpar e organizar o texto antes de usá-lo. Por motivos chatos e técnicos, o próximo código converte o encoding para UTF-8, e depois extrai manualmente as linhas do início e fim que não pertencem ao livro original. Aproveitamos para também adicionar uma nova coluna capturando o número da linha no livro, para facilitar a restreabilidade das linhas ao longo da análise.\r\n\r\n\r\nAssis <- Assis %>% \r\n  mutate(text=iconv(text, from = \"latin1\", to = \"UTF-8\")) %>%\r\n  select(-gutenberg_id) %>% \r\n  slice(21:8549) %>%\r\n  rownames_to_column(\"Linha\") \r\n\r\n\r\nAgora observe que cada linha do tibble ‘Assis’ é uma linha do livro, enquanto a nossa unidade de análise normalmente é cada palavra. Então a nossa primeira tarefa é separar as linhas em palavras (‘tokenize’). As seguintes funções são dos pacotes tidytext, textstem e lexiconPT, então lembre-se de instalar eles uma vez e abrir as bibliotecas depois.\r\n\r\n\r\n# install.packages(\"tidytext\")\r\n# install.packages(\"textstem\")\r\n# install.packages(\"lexiconPT\")\r\n\r\nlibrary(\"tidytext\")\r\nlibrary(\"textstem\")\r\nlibrary(\"lexiconPT\")\r\n\r\n\r\nDesagregar linhas em palavras exige a função unnest_tokens(), com dois argumentos: o nome da nova coluna que contém as palavras, ‘palavra’, e o nome da coluna que contém o texto por linha, ‘text’.\r\n\r\n\r\nAssis_palavras <- Assis %>% unnest_tokens(palavra, text)\r\n\r\n\r\nAgora, ‘Assis_palavras’ tem muito mais linhas, uma para cada palavra. Perfeito.\r\nA próxima tarefa é a simplificação e padronização dessas palavras, e isso envolve vários passos:\r\nTirar Pontuação: Frases contém pontuação, mas normalmente não importa se há uma vírgula ou não depois de uma palavra para identificar a presença do conceito no texto. A pontuação é tirada automaticamente por unnest_tokens(). Se quiser, pode desligar para manter a pontuação:\r\n\r\n\r\nAssis %>% unnest_tokens(palavra, text, strip_punct=F)\r\n\r\n\r\nTirar Maiúsculas: Também queremos ignorar se as palavras estão em letras minúsculas ou maiúsculas, e padronizar, por exemplo, para minúsculas. De novo, isso é o padrão de unnest_tokens(), mas podemos desligar se quisemos:\r\n\r\n\r\nAssis %>% unnest_tokens(palavra, text, to_lower=F)\r\n\r\n\r\nTirar Números: O nosso texto contém vários números (anos, etc.) que não são relevantes para uma análise de texto. Não é a opção padrão, mas podemos tirar os números facilmente:\r\n\r\n\r\nAssis_palavras <- Assis %>% unnest_tokens(palavra, text, strip_numeric=TRUE)\r\n\r\n\r\nTirar stopwords: É comum tirar palavras pequenas e genéricas como ‘o’, ‘a’, ‘e’ etc. que são universais e não diferenciam o conteúdo dos textos. Essas palavras se chamam ‘stopwords’. Tirá-las exige mais um passo, aproveitando de um banco de dados de stopwords com a função get_stopwords() para a língua apropriada. Inspecione seu conteúdo.\r\n\r\n\r\nstopwords <- get_stopwords(language=\"pt\") %>%\r\n  rename(palavra=word)\r\n\r\nstopwords\r\n\r\n\r\n\r\n\r\npalavra\r\n\r\n\r\nlexicon\r\n\r\n\r\nde\r\n\r\n\r\nsnowball\r\n\r\n\r\na\r\n\r\n\r\nsnowball\r\n\r\n\r\no\r\n\r\n\r\nsnowball\r\n\r\n\r\nque\r\n\r\n\r\nsnowball\r\n\r\n\r\ne\r\n\r\n\r\nsnowball\r\n\r\n\r\ndo\r\n\r\n\r\nsnowball\r\n\r\n\r\nda\r\n\r\n\r\nsnowball\r\n\r\n\r\nem\r\n\r\n\r\nsnowball\r\n\r\n\r\num\r\n\r\n\r\nsnowball\r\n\r\n\r\npara\r\n\r\n\r\nsnowball\r\n\r\n\r\nLembrando que queremos manter as linhas em ‘Assis_palavras’ que não existem no banco de get_stopwords(), o jeito mais eficiente é usar um anti_join().\r\n\r\n\r\nAssis_palavras <- Assis_palavras %>% anti_join(stopwords, by=\"palavra\")\r\n\r\n\r\nA lista de stopwords não é nada oficial; são apenas as palavras que não nos interessam. Por exemplo, por algum motivo na lista de stopwords aqui falta a palavra ‘é’, que é muito comum e não agrega nada no conteúdo do texto. Nós podemos manualmente estender a lista de stopwords, adicionando mais linhas no tibble stopwords.\r\n\r\n\r\nstopwords <- stopwords %>% add_row(palavra=\"é\", lexicon=\"pessoal\")\r\n\r\nAssis_palavras <- Assis_palavras %>% anti_join(stopwords, by=\"palavra\")\r\n\r\n\r\n‘Stem’ as palavras Mais um passo de processamento é a padronização de variedades da mesma palavra - uma técnica que se chama ‘stemming’. Por exemplo, português tem milhares de conjugações de cada verbo: ‘saber’, ‘sei’, ‘soube’ etc. que significam o mesmo conceito. O que nos interessa é a raiz (o ‘stem’) consistente da palavra. Usamos a função stem_words() para adicionar mais uma coluna ao nosso tibble com a raiz das palavras, de novo especificando a língua apropriada.\r\n\r\n\r\nAssis_palavras <- Assis_palavras %>% mutate(stem=stem_words(palavra, language=\"pt\"))\r\n\r\n\r\nAgora veja a coluna ‘stem’ do tibble: observe o contraste entre ‘palavra’, e ‘stem’. Por exemplo, ambos ‘encontrei’ e ‘encontrou’ se tornam ‘encontr’. A padronização reduz bastante a base de dados - de 8.728 a 4.824 palavras distintas.\r\n\r\n\r\nAssis_palavras %>% distinct(palavra)\r\nAssis_palavras %>% distinct(stem)\r\n\r\n\r\nFrequência de Palavras\r\nAgora que temos um banco de dados textuais padronizado, podemos começar a analisar o conteúdo das palavras de Machado de Assis. Primeiramente, vamos estimar a frequência de uso das palavras, ou mais especificamente as raízes.\r\nPodemos visualizar a frequência das raízes (stems) das palavras com um wordcloud, como mostramos acima. (Vamos pedir uma amostra das linhas para acelerar o processamento).\r\n\r\n\r\nAssis_palavras %>% sample_n(2000) %>% \r\n  pull(stem) %>% \r\n  wordcloud()\r\n\r\n\r\n\r\nTambém podemos identificar as palavras (os ‘stems’ na verdade) mais frequentes usando as nossas habilidades bem conhecidas do tidyverse.\r\n\r\n\r\nAssis_palavras %>% group_by(stem) %>%\r\n  tally() %>%\r\n  arrange(-n)\r\n\r\n\r\n\r\n\r\nstem\r\n\r\n\r\nn\r\n\r\n\r\noutr\r\n\r\n\r\n372\r\n\r\n\r\ncapitú\r\n\r\n\r\n341\r\n\r\n\r\nmã\r\n\r\n\r\n329\r\n\r\n\r\ncas\r\n\r\n\r\n269\r\n\r\n\r\ná\r\n\r\n\r\n262\r\n\r\n\r\nelle\r\n\r\n\r\n239\r\n\r\n\r\ndiss\r\n\r\n\r\n218\r\n\r\n\r\ntod\r\n\r\n\r\n218\r\n\r\n\r\ndias\r\n\r\n\r\n191\r\n\r\n\r\nfal\r\n\r\n\r\n191\r\n\r\n\r\nObserve que algumas dessas palavras não são interessantes e não descreve bem o conteúdo do texto então podem ser bons candidatos para tirar na lista de stopwords, por exemplo ‘á’. E para visualizar os resultados num gráfico de barras:\r\n\r\n\r\nAssis_palavras %>% group_by(stem) %>%\r\n  tally() %>%\r\n  top_n(10, n) %>%\r\n  mutate(stem=fct_reorder(stem, n)) %>%\r\n  ggplot() +\r\n  geom_col(aes(y=stem, x=n), fill=\"blue\") +\r\n  theme_minimal()\r\n\r\n\r\n\r\nFinalmente, podemos interrogar o banco de texto para verificar a presença de uma palavra específica, por exemplo o stem ‘govern’:\r\n\r\n\r\nAssis_palavras %>% filter(stem==\"govern\")\r\n\r\n\r\n\r\n\r\nLinha\r\n\r\n\r\npalavra\r\n\r\n\r\nstem\r\n\r\n\r\n183\r\n\r\n\r\ngovernou\r\n\r\n\r\ngovern\r\n\r\n\r\n185\r\n\r\n\r\ngovernou\r\n\r\n\r\ngovern\r\n\r\n\r\n4986\r\n\r\n\r\ngoverno\r\n\r\n\r\ngovern\r\n\r\n\r\n5162\r\n\r\n\r\ngovernasse\r\n\r\n\r\ngovern\r\n\r\n\r\nHá quatro instâncias no texto, em três formas diferentes da palavra.\r\nAnálise de Sentimento\r\nO ‘Dom Casmurro’ é um livro otimista ou pessimista? Cada palavra tem um significado complexo, sutil e contextual. Porém, existem bancos de dados que avaliam o ‘sentimento’ de cada palavra. O pacote lexiconPT fornece o banco oplexicon_v3.0. Nós precisamos apenas juntar o banco de dados de sentimentos com o nosso banco de palavras:\r\n\r\n\r\nsentimento <- oplexicon_v3.0 %>% select(term, polarity) %>%\r\n  rename(palavra=term)\r\n\r\nAssis_palavras <- Assis_palavras %>% left_join(sentimento, by=\"palavra\")\r\n\r\n\r\n\r\n\r\nLinha\r\n\r\n\r\npalavra\r\n\r\n\r\nstem\r\n\r\n\r\npolarity\r\n\r\n\r\n2\r\n\r\n\r\ni\r\n\r\n\r\ni\r\n\r\n\r\nNA\r\n\r\n\r\n4\r\n\r\n\r\ntitulo\r\n\r\n\r\ntitul\r\n\r\n\r\nNA\r\n\r\n\r\n6\r\n\r\n\r\nnoite\r\n\r\n\r\nnoit\r\n\r\n\r\nNA\r\n\r\n\r\n6\r\n\r\n\r\ndestas\r\n\r\n\r\ndest\r\n\r\n\r\nNA\r\n\r\n\r\n6\r\n\r\n\r\nvindo\r\n\r\n\r\nvind\r\n\r\n\r\n-1\r\n\r\n\r\n6\r\n\r\n\r\ncidade\r\n\r\n\r\ncidad\r\n\r\n\r\nNA\r\n\r\n\r\n6\r\n\r\n\r\nengenho\r\n\r\n\r\nengenh\r\n\r\n\r\nNA\r\n\r\n\r\n6\r\n\r\n\r\nnovo\r\n\r\n\r\nnov\r\n\r\n\r\n1\r\n\r\n\r\n6\r\n\r\n\r\nencontrei\r\n\r\n\r\nencontr\r\n\r\n\r\nNA\r\n\r\n\r\n7\r\n\r\n\r\ntrem\r\n\r\n\r\ntrem\r\n\r\n\r\nNA\r\n\r\n\r\nObserve que muitas palavras - as palavras ‘neutras’ - não existem no banco de dados de sentimentos, então a coluna ‘polarity’ tem valor NA. Podemos avaliar o sentimento ‘média’ do livro com summarize. Um valor positivo significa um texto mais otimista na média, e um valor negativo um texto mais pessimista na média:\r\n\r\n\r\nAssis_palavras %>% summarize(sentimento=mean(polarity, na.rm=T))\r\n\r\n\r\n\r\n\r\nsentimento\r\n\r\n\r\n0.1157649\r\n\r\n\r\nO resultado positivo sugere que o livro é mais otimista do que pessimista na média. A análise também permite identificar as linhas mais otimistas e pessimistas do livro inteiro se agrupamos por linha e calcularmos a soma dos sentimentos contidos na linha (palavras positivas menos palavras negativas):\r\n\r\n\r\nAssis_palavras %>% mutate(Linha=as.numeric(Linha)) %>%\r\n  group_by(Linha) %>%\r\n  summarize(polarity=sum(polarity, na.rm=T)) %>%\r\n  arrange(-polarity) %>%\r\n  slice(1, n())\r\n\r\n\r\n\r\n\r\nLinha\r\n\r\n\r\npolarity\r\n\r\n\r\n7500\r\n\r\n\r\n6\r\n\r\n\r\n1403\r\n\r\n\r\n-4\r\n\r\n\r\nOk, mas quais são as linhas 7500 e 1403? Temos que voltar ao banco de dados de linhas ‘Assis’ (não ‘Assis_palavras’) e filtrar por essas linhas:\r\n\r\n\r\nAssis %>% filter(Linha==7500) %>% pull(text) #Linha mais otimista\r\n\r\n[1] \"activo, coração recto, amigo, bom amigo, digno da esposa amantissima\"\r\n\r\nAssis %>% filter(Linha==1403) %>% pull(text) #Linha mais pessimista\r\n\r\n[1] \"pouco, um intrigante, um bajulador, um especulador, e, apezar da casca\"\r\n\r\nFaz sentido, sim? Os nossos dados permitem responder a mais uma pergunta interessante: Como se desenvolve o sentimento ao longo do livro? Podemos usar o nosso resumo por linha, completar as linhas faltantes (que faltam palavras em nosso banco de dados de sentimentos) com complete, e encaminhar para ggplot para criar um gráfico de linhas.\r\n\r\n\r\nAssis_palavras %>% mutate(Linha=as.numeric(Linha)) %>%\r\n  group_by(Linha) %>%\r\n  summarize(polarity=sum(polarity, na.rm=T)) %>%\r\n  complete(Linha=1:8527, fill=list(polarity=0)) %>%\r\n  ggplot() +\r\n  geom_line(aes(x=Linha, y=polarity)) +\r\n  theme_classic() + \r\n  ylab(\"Sentimento\")\r\n\r\n\r\n\r\nO gráfico não é fácil de interpretar porque há muitas observações e variações página por página. Uma forma de melhorar a apresentação da linha é calcular uma ‘média móvel’, que ‘suaviza’ os dados de sentimento. O pacote zoo fornece a função rollapply que podemos aplicar dentro de um mutate para calcular a média móvel de cada janela de 1000 linhas.\r\n\r\n\r\nlibrary(\"zoo\")\r\nAssis_palavras %>% mutate(Linha=as.numeric(Linha)) %>%\r\n  group_by(Linha) %>%\r\n  summarize(polarity=sum(polarity, na.rm=T)) %>%\r\n  complete(Linha=1:8527, fill=list(polarity=0)) %>%\r\n  mutate(polarity_rolling=rollapply(polarity, 1000, mean, align='right', fill=NA)) %>%\r\n  ggplot() +\r\n  geom_line(aes(x=Linha, y=polarity_rolling)) +\r\n  theme_classic() + \r\n  ylab(\"Sentimento\")\r\n\r\n\r\n\r\nO fluxo do livro é mais evidente agora - períodos otimistas antes de linha 5000 e depois de linha 6500, e períodos mais pessimistas cerca de linhas 6000 e 8000. Se você conhece o livro, pode nos ajudar a verificar se é verdade!\r\nNgrams\r\nPor que estamos trabalhando com palavras únicas? Não é obrigatório - podemos dividir o texto em várias formas. Por exemplo, podemos identificar pares de palavras - cada vez que um par de palavras - ‘grande gato’ - aparecem juntos. Isso se chama um ‘bigram’. A lógica de processamento é bem parecida com a rotina para palavras únicas. É só especificar token=ngrams e n=2 na função de unnest_tokens().\r\n\r\n\r\nAssis_bigrams <- Assis %>% unnest_tokens(bigram, text,\r\n                                       token=\"ngrams\", n=2)\r\n\r\n\r\nTirar os stopwords exige um pouco mais trabalho com bigrams - temos que separar eles em palavras distintas, tirar cada instância de um stopword, e juntar de novo:\r\n\r\n\r\nAssis_bigrams <- Assis_bigrams %>% \r\n  separate(bigram, c(\"palavra1\", \"palavra2\"), sep=\" \") %>% \r\n  anti_join(stopwords, by=c(\"palavra1\"=\"palavra\")) %>%\r\n  anti_join(stopwords, by=c(\"palavra2\"=\"palavra\")) %>%\r\n  unite(\"bigram\", c(palavra1, palavra2), sep=\" \", remove=F)\r\n\r\n\r\n\r\n\r\nAssis_bigrams %>%\r\n  group_by(bigram) %>%\r\n  tally() %>%\r\n  arrange(-n)\r\n\r\n\r\n\r\n\r\nbigram\r\n\r\n\r\nn\r\n\r\n\r\nNA NA\r\n\r\n\r\n2472\r\n\r\n\r\njosé dias\r\n\r\n\r\n147\r\n\r\n\r\nprima justina\r\n\r\n\r\n47\r\n\r\n\r\ntio cosme\r\n\r\n\r\n45\r\n\r\n\r\noutra vez\r\n\r\n\r\n28\r\n\r\n\r\npóde ser\r\n\r\n\r\n27\r\n\r\n\r\noutra cousa\r\n\r\n\r\n26\r\n\r\n\r\ná porta\r\n\r\n\r\n26\r\n\r\n\r\npadre cabral\r\n\r\n\r\n22\r\n\r\n\r\nalguma cousa\r\n\r\n\r\n21\r\n\r\n\r\nO bigram mais comum (exceto ‘NA NA’ que devemos tirar) é “josé dias”, presumivelmente um personagem, e, em seguida, “prima justina”.\r\nTrabalhar com bigrams nos ajuda a identificar ao lado de quais outras palavras uma palavra aparece. Por exemplo, quais palavras aparecem ao lado da palavra ‘familia’?\r\n\r\n\r\nAssis_bigrams %>% filter(palavra1==\"familia\") %>% pull(palavra2)\r\n\r\n [1] \"padua\"     \"elle\"      \"certa\"     \"dizia\"     \"fernandes\"\r\n [6] \"tornar\"    \"imitar\"    \"saía\"      \"lembro\"    \"avisa\"    \r\n[11] \"hoje\"      \"pendura\"  \r\n\r\nAssis_bigrams %>% filter(palavra2==\"familia\") %>% pull(palavra1)\r\n\r\n[1] \"mesma\"\r\n\r\nParece que ‘familia’ aparece ao lado de ‘imitar’, ‘avisa’, ‘pendura’, etc., fornecendo um pouco de contexto.\r\nNgrams são bigrams com mais de duas palavras - vamos identificar o mais comum ‘trigram’ (com três palavras):\r\n\r\n\r\nAssis_trigrams <- Assis %>% unnest_tokens(trigram, text,\r\n                                       token=\"ngrams\", n=3)\r\n\r\nAssis_trigrams <- Assis_trigrams %>% \r\n  separate(trigram, c(\"palavra1\", \"palavra2\", \"palavra3\"), sep=\" \") %>% \r\n  anti_join(stopwords, by=c(\"palavra1\"=\"palavra\")) %>%\r\n  anti_join(stopwords, by=c(\"palavra2\"=\"palavra\")) %>%\r\n  anti_join(stopwords, by=c(\"palavra3\"=\"palavra\")) %>%\r\n  unite(\"trigram\", c(palavra1, palavra2, palavra3), sep=\" \", remove=F)\r\n\r\n\r\n\r\n\r\nAssis_trigrams %>%\r\n  group_by(trigram) %>%\r\n  tally() %>%\r\n  arrange(-n)\r\n\r\n\r\n\r\n\r\ntrigram\r\n\r\n\r\nn\r\n\r\n\r\nNA NA NA\r\n\r\n\r\n2696\r\n\r\n\r\njosé dias achou\r\n\r\n\r\n4\r\n\r\n\r\nserás feliz bentinho\r\n\r\n\r\n4\r\n\r\n\r\n1 070 000\r\n\r\n\r\n3\r\n\r\n\r\naggregado josé dias\r\n\r\n\r\n3\r\n\r\n\r\napós alguns instantes\r\n\r\n\r\n3\r\n\r\n\r\nceu oh flòr\r\n\r\n\r\n3\r\n\r\n\r\ndez libras esterlinas\r\n\r\n\r\n3\r\n\r\n\r\noh flòr candida\r\n\r\n\r\n3\r\n\r\n\r\nposso ser padre\r\n\r\n\r\n3\r\n\r\n\r\nUm dos trigrams mais comuns é “josé dias achou”.\r\n\r\nExercício 2: Analisando um Documento\r\nEscolha um livro da sua preferência no site de Projeto Gutenberg, e abra ele em R usando o código do projeto.\r\n\r\n\r\nMostrar Código\r\n\r\nBranco <- gutenberg_download(26913) %>% \r\n  mutate(text=iconv(text, from = \"latin1\", to = \"UTF-8\")) %>%\r\n  select(-gutenberg_id) %>% \r\n  rownames_to_column(\"Linha\") \r\n\r\n\r\n‘Tokenize’ o seu livro em palavras, tirando a pontuação, os números, os stopwords, virando as caracteres em minúsculo, e as palavras em seus stems (raízes).\r\n\r\n\r\nMostrar Código\r\n\r\nBranco_palavras <- Branco %>% unnest_tokens(palavra, text, strip_numeric=TRUE) %>%\r\n  anti_join(stopwords, by=\"palavra\") %>%\r\n  mutate(stem=stem_words(palavra, language=\"pt\"))\r\n\r\n\r\nIdentifique os dez stems mais frequentes no seu livro.\r\n\r\n\r\nMostrar Código\r\n\r\nBranco_palavras %>% group_by(stem) %>%\r\n  tally() %>%\r\n  top_n(10, n) %>%\r\n  arrange(-n)\r\n\r\n\r\nAplique uma análise de sentimento ao texto para identificar as linhas mais otimistas e as mais pessimistas do texto.\r\n\r\n\r\nMostrar Código\r\n\r\nBranco_palavras <- Branco_palavras %>% left_join(sentimento, by=\"palavra\")\r\n\r\nBranco_palavras %>% mutate(Linha=as.numeric(Linha)) %>%\r\n  group_by(Linha) %>%\r\n  summarize(polarity=sum(polarity, na.rm=T)) %>%\r\n  arrange(-polarity) %>%\r\n  slice(1, n()) %>%\r\n  kable()\r\n\r\nBranco %>% filter(Linha==594) %>% pull(text) #Linha mais otimista\r\nBranco %>% filter(Linha==2881) %>% pull(text) #Linha mais pessimista\r\n\r\n\r\n\r\nComparando Documentos\r\nÉ possível trabalhar além de uma descrição de um livro único e comparar o conteúdo de documentos distintos. Para isso, precisamos distinguir documentos (livros ou artigos distintos) e termos (palavras ou ngrams em um documento). O jeito mais fácil de realizar isso é juntar vários documentos no mesmo tibble, com uma coluna adicional que indica com qual documento cada palavra é associada.\r\nPrimeiramente, temos que abrir mais um documento para comparar com o livre de Machado de Assis. Vamos pegar o livro português de Jules Verne, ‘Da terra á lua’ de Projeto Gutenberg:\r\n\r\n\r\n#http://www.gutenberg.org/cache/epub/28341/pg28341.txt #Jules Verne, 'Da terra à lua'\r\n\r\nVerne <- gutenberg_download(28341) %>% \r\n  mutate(text=iconv(text, from = \"latin1\", to = \"UTF-8\")) %>%\r\n  select(-gutenberg_id) %>% \r\n  slice(71:7229) %>%\r\n  rownames_to_column(\"Linha\")\r\n\r\n\r\nE vamos processar o banco de dados para padronizar o conteúdo e gerar os stems, para que o banco de dados fica no mesmo formato que o livro de Machado de Assis:\r\n\r\n\r\nVerne_palavras <- Verne %>% unnest_tokens(palavra, text, strip_numeric=TRUE) %>%\r\n  anti_join(stopwords, by=\"palavra\") %>%\r\n  mutate(stem=stem_words(palavra, language=\"pt\"))\r\n\r\n\r\nAgora precisamos juntar os dois bancos, ‘Assis_palavras’ e ‘Verne_palavras’ em um tibble único, adicionando uma coluna identificadora para preservar o livro relevante. Também precisamos contar a frequência de cada palavra, para que possamos comparar a frequência entre os dois livros. Para deixar os resultados mais fáceis de interpretar, vamos trabalhar com as palavras mesmas em vez dos stems:\r\n\r\n\r\nAssis_prep <- Assis_palavras %>% \r\n  group_by(palavra) %>% \r\n  tally() %>%\r\n  mutate(document=\"Assis\")\r\n\r\nVerne_prep <- Verne_palavras %>% \r\n  group_by(palavra) %>% \r\n  tally() %>%\r\n  mutate(document=\"Verne\")\r\n\r\n\r\nPara juntar os dois bancos, usamos bind_rows():\r\n\r\n\r\nAssis_Verne <- Assis_prep %>% bind_rows(Verne_prep)\r\n\r\n\r\nFrequência Relativa de Palavras (bind_tf_idf)\r\nQuais palavras distinguem melhor os dois livros? Ou seja, há palavras frequentes que existem nos dois livros (palavras comuns, tipo ‘pessoa’, ‘rua’), e há palavras que são comuns e específicas para cada livro, que ajudam a caracterizar o conteúdo distinto do livro.\r\nA medida que é usada na análise de texto é a frequência do termo (‘tf’) multiplicado pela frequência inversa do termo no documento (‘idf’) - o ‘tf-idf’. Os termos com os maiores valores da medida ‘tf-idf’ são os termos que são mais presentes em um documento e não no outro.\r\nCalculamos a medida com a função bind_tf_idf(), que exige três argumentos - a coluna que contém as palavras, a coluna que indica em qual documento aparece cada palavra, e a coluna que resume a frequência de cada palavra no documento:\r\n\r\n\r\nAssis_Verne_idf <- Assis_Verne %>% bind_tf_idf(palavra, document, n)\r\n\r\n\r\nEm seguida, é fácil identificar as palavras mais distintas para cada livro:\r\n\r\n\r\nAssis_Verne_idf %>%\r\n  group_by(document) %>%\r\n  top_n(5, tf_idf)\r\n\r\n\r\n\r\n\r\ndocument\r\n\r\n\r\npalavra\r\n\r\n\r\nn\r\n\r\n\r\ntf_idf\r\n\r\n\r\nAssis\r\n\r\n\r\ncapitú\r\n\r\n\r\n341\r\n\r\n\r\n0.0065044\r\n\r\n\r\nAssis\r\n\r\n\r\ndella\r\n\r\n\r\n82\r\n\r\n\r\n0.0015641\r\n\r\n\r\nAssis\r\n\r\n\r\nescobar\r\n\r\n\r\n110\r\n\r\n\r\n0.0020982\r\n\r\n\r\nAssis\r\n\r\n\r\njosé\r\n\r\n\r\n160\r\n\r\n\r\n0.0030519\r\n\r\n\r\nAssis\r\n\r\n\r\nseminario\r\n\r\n\r\n85\r\n\r\n\r\n0.0016213\r\n\r\n\r\nVerne\r\n\r\n\r\nardan\r\n\r\n\r\n143\r\n\r\n\r\n0.0029992\r\n\r\n\r\nVerne\r\n\r\n\r\nbarbicane\r\n\r\n\r\n256\r\n\r\n\r\n0.0053692\r\n\r\n\r\nVerne\r\n\r\n\r\nclub\r\n\r\n\r\n123\r\n\r\n\r\n0.0025797\r\n\r\n\r\nVerne\r\n\r\n\r\nmaston\r\n\r\n\r\n143\r\n\r\n\r\n0.0029992\r\n\r\n\r\nVerne\r\n\r\n\r\nprojectil\r\n\r\n\r\n147\r\n\r\n\r\n0.0030831\r\n\r\n\r\nOs resultados indicam que no livro de Assis, as palavras mais distintas incluem ‘josé’, ‘escobar’, ‘capitú’ - os personagens centrais do livro. Na mesma forma, as palavras mais distintas do livro de Verne incluem ‘ardan’, ‘barbicane’, e ‘maston’, os personagens centrais. Isso é comum porque são esses nomes que são muito usados e distinguem os livros.\r\nModelagem de Tópicos\r\nUma alternativa para comparar documentos é uma técnica de clusterização que divide automaticamente (sem supervisão) o conjunto de documentos em temas, ou ‘tópicos’. Os tópicos são definidos pelo uso de conjuntos de palavras distintas, e cada documento é uma mistura de tópicos (ex. 90% A e 10% B). Essa técnica é útil para dizer que alguns documentos são mais parecidos que outros.\r\nPrimeiramente, precisamos transformar o nosso tibble dos dois livros em uma ‘matriz de documento-termo’, uma ferramenta bem usada no mundo de análise de texto, com a função cast_dtm(), indicando como argumentos a coluna que identifica o documento, a coluna que contém as palavras (termos), e a coluna que conta a frequência de cada palavra.\r\n\r\n\r\nAssis_Verne_dtm <- Assis_Verne %>%\r\n  cast_dtm(document, palavra, n)\r\n\r\n\r\nCom a nossa matriz de documento-termos, usamos a função LDA() do pacote topicmodels para classificar o conteúdo textual automaticamente (usando o modelo de Latent Dirichlet Allocation - LDA). Vamos especificar que queremos classificar os livros em quatro tópicos por enquanto.\r\n\r\n\r\n#install.packages(\"topicmodels\")\r\nlibrary(\"topicmodels\")\r\n\r\nAssis_Verne_LDA <- LDA(Assis_Verne_dtm, 4)\r\n\r\n\r\n\r\n\r\n\r\nO resultado de LDA() pode ser transformado em nosso amigo, o tibble, com a função tidy() do pacote broom(), o mesmo que usamos com regressões, especificando o matriz ‘gamma’.\r\n\r\n\r\nlibrary(\"broom\")\r\n#install.packages(\"reshape2\")\r\nlibrary(\"reshape2\")\r\n\r\nAssis_Verne_LDA_documentos <- Assis_Verne_LDA %>% tidy(matrix='gamma')\r\n\r\n\r\n\r\n\r\nAssis_Verne_LDA_documentos\r\n\r\n\r\n\r\n\r\ndocument\r\n\r\n\r\ntopic\r\n\r\n\r\ngamma\r\n\r\n\r\nAssis\r\n\r\n\r\n1\r\n\r\n\r\n0.0000016\r\n\r\n\r\nVerne\r\n\r\n\r\n1\r\n\r\n\r\n0.5997157\r\n\r\n\r\nAssis\r\n\r\n\r\n2\r\n\r\n\r\n0.0000016\r\n\r\n\r\nVerne\r\n\r\n\r\n2\r\n\r\n\r\n0.4002807\r\n\r\n\r\nAssis\r\n\r\n\r\n3\r\n\r\n\r\n0.8063967\r\n\r\n\r\nVerne\r\n\r\n\r\n3\r\n\r\n\r\n0.0000018\r\n\r\n\r\nAssis\r\n\r\n\r\n4\r\n\r\n\r\n0.1936000\r\n\r\n\r\nVerne\r\n\r\n\r\n4\r\n\r\n\r\n0.0000018\r\n\r\n\r\nO resultado indica quanto cada tópico aparece em cada livro. O livre de Assis é 42% tópico 1, 58% tópico 2, 0% tópicos 3 e 4, enquanto o livro de Verne é 0% tópico 1 e 2, 66% tópico 3 e 34% tópico 4. Ou seja - cada livro contém dois tópicos e os tópicos não se sobrepõem aos livros.\r\nMas o que representam esses tópicos? Não sabemos - eles não tem uma descrição fixa; são definidos pelo algoritmo e nós temos que interpretar o significado de cada tópico. Para facilitar isso, podemos inspecionar as palavras mais associadas a cada tópico. Pedimos o relacionamento entre os tópicos e as palavras (em vez dos documentos) com a matriz ‘beta’ em tidy(). O ‘beta’ reflete a probabilidade que a palavra é associada com o tópico.\r\n\r\n\r\nAssis_Verne_LDA_palavras <- Assis_Verne_LDA %>% tidy(matrix='beta')\r\n\r\n\r\nAgora, podemos identificar as palavras mais frequentes em cada tópico:\r\n\r\n\r\nAssis_Verne_LDA_palavras %>% group_by(topic) %>%\r\n  top_n(5, beta) %>%\r\n  arrange(topic, -beta)\r\n\r\n\r\n\r\n\r\ntopic\r\n\r\n\r\nterm\r\n\r\n\r\nbeta\r\n\r\n\r\n1\r\n\r\n\r\nha\r\n\r\n\r\n0.0066170\r\n\r\n\r\n1\r\n\r\n\r\ná\r\n\r\n\r\n0.0059549\r\n\r\n\r\n1\r\n\r\n\r\nbarbicane\r\n\r\n\r\n0.0055616\r\n\r\n\r\n1\r\n\r\n\r\npresidente\r\n\r\n\r\n0.0051129\r\n\r\n\r\n1\r\n\r\n\r\nprojectil\r\n\r\n\r\n0.0050177\r\n\r\n\r\n2\r\n\r\n\r\nbarbicane\r\n\r\n\r\n0.0110192\r\n\r\n\r\n2\r\n\r\n\r\ná\r\n\r\n\r\n0.0100520\r\n\r\n\r\n2\r\n\r\n\r\nmil\r\n\r\n\r\n0.0087459\r\n\r\n\r\n2\r\n\r\n\r\nser\r\n\r\n\r\n0.0086094\r\n\r\n\r\n2\r\n\r\n\r\nlua\r\n\r\n\r\n0.0079055\r\n\r\n\r\n3\r\n\r\n\r\ncapitú\r\n\r\n\r\n0.0102831\r\n\r\n\r\n3\r\n\r\n\r\nelle\r\n\r\n\r\n0.0079843\r\n\r\n\r\n3\r\n\r\n\r\ná\r\n\r\n\r\n0.0077444\r\n\r\n\r\n3\r\n\r\n\r\nmãe\r\n\r\n\r\n0.0070484\r\n\r\n\r\n3\r\n\r\n\r\nella\r\n\r\n\r\n0.0062040\r\n\r\n\r\n4\r\n\r\n\r\njosé\r\n\r\n\r\n0.0163633\r\n\r\n\r\n4\r\n\r\n\r\ncasa\r\n\r\n\r\n0.0118951\r\n\r\n\r\n4\r\n\r\n\r\nescobar\r\n\r\n\r\n0.0102360\r\n\r\n\r\n4\r\n\r\n\r\ndia\r\n\r\n\r\n0.0095325\r\n\r\n\r\n4\r\n\r\n\r\ntambem\r\n\r\n\r\n0.0086584\r\n\r\n\r\nA nossa tarefa agora é resumir qual tópico é representado, por exemplo, pelo conjunto de palavras ‘capitú’, ‘elle’, ‘dias’, ‘mãe’, e ‘ser’ - pode ser que eles aparecem frequentemente em um diálogo que envolve o personagem ‘capitú’ e a sua mãe, por exemplo. Cada tópico não é óbvio, mas para o computador parece que eles formam tópicos coerentes presentes nos dois livros.\r\nEm outras aplicações a modelagem de tópicos é uma forma poderosa de identificar temas pareceidos em conjuntos grandes de documentos sem precisar ler todos os documentos.\r\n\r\nExercício 3: Comparando Documentos\r\nCopie e cole um texto que você mesmo escreveu de pelo menos um parágrafo e salve ele dentro de um tibble em R.\r\n\r\n\r\nMostrar Código\r\n\r\nmeu_texto <- tibble(text=\"A Organização Mundial da Saúde (OMS) disse nesta terça-feira (9) que a 'transmissão por casos assintomáticos está ocorrendo, a questão é saber quanto'.\")\r\n\r\n\r\n‘Tokenize’ o seu texto em palavras, tirando a pontuação, os números, os stopwords, transformando os caracteres em minúsculo, e as palavras em suas raízes (stems).\r\n\r\n\r\nMostrar Código\r\n\r\nmeu_texto_palavras <- meu_texto %>% unnest_tokens(palavra, text, strip_numeric=TRUE) %>%\r\n  anti_join(stopwords, by=\"palavra\") %>%\r\n  mutate(stem=stem_words(palavra, language=\"pt\"))\r\n\r\n\r\nJunte dois textos tokenizados em um tibble com uma coluna que diferencia o documento e uma coluna que conta a frequência de cada palavra: (i) o seu texto da questão 1, e (ii) o livro que você usou no exercício 2.\r\n\r\n\r\nMostrar Código\r\n\r\nBranco_prep <- Branco_palavras %>% \r\n  group_by(palavra) %>% \r\n  tally() %>%\r\n  mutate(document=\"Branco\")\r\n\r\nmeu_texto_prep <- meu_texto_palavras %>% \r\n  group_by(palavra) %>% \r\n  tally() %>%\r\n  mutate(document=\"Meu Texto\")\r\n\r\ndois_textos <- Branco_prep %>% bind_rows(meu_texto_prep) \r\n\r\n\r\nCalcule a medida ‘tf_idf’ para identificar as 5 palavras mais distintas de cada documento. Em qual sentido o seu documento é diferente do livro?\r\n\r\n\r\nMostrar Código\r\n\r\ndois_textos %>% bind_tf_idf(palavra, document, n) %>%\r\n  group_by(document) %>%\r\n  top_n(5, tf_idf)\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:13:13-03:00"
    },
    {
      "path": "Estatisticas_Resumidas.html",
      "title": "Calculando Estatísticas Resumidas",
      "description": "Agregando os seus Dados\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nEstatísticas Resumidas (summarize)\r\nGrupos (group_by)\r\nMutate por Grupo\r\nResumos de Múltiplas Colunas (across())\r\n\r\nEstatísticas Resumidas (summarize)\r\nNos últimos tutoriais, não mexemos com a unidade de análise de nosso banco de dados - sempre avaliamos os voos individuais, por exemplo. Porém, mesmo depois de vários filtros e mutates, os seus dados provavelmente tem dezenas, centenas ou milhares de linhas - é difícil incluir toda esta informação no seu relatório, e é impossível para o leitor entender tudo. É por isso que usamos estatísticas resumidas: médias, medianas etc.\r\nPara gerar um número único que resume uma variável em nossa tabela, usamos o verbo summarize() que funciona perfeitamente dentro do fluxo da nossa análise com o pipe (%>%). O summarize() gera um novo tibble (tabela/data.frame) pequeno para conter as estatísticas resumidas, abandonando o nosso tibble original.\r\nA função exige três elementos (i) o nome da nova variável no novo tibble; (ii) a função que vai agregar/resumir a variável, e (iii) a variável que será resumida. Veja o exemplo abaixo, que calcula a distância média de todos os voos.\r\n\r\n\r\nlibrary(\"nycflights13\")\r\nlibrary(\"tidyverse\")\r\nlibrary(\"tidylog\")\r\n\r\n\r\n\r\n\r\nflights %>% summarize(media_distance=mean(distance))\r\n\r\n# A tibble: 1 × 1\r\n  media_distance\r\n           <dbl>\r\n1          1040.\r\n\r\n\r\n\r\n\r\nFácil, não? Usando a variedade das funções estatísticas em R (ou qualquer pacote adicional), você pode calcular qualquer estatística que te interesse. Experimente com os exemplos na tabela.\r\nEstatística\r\nFunção em R\r\nMédia\r\nmean(variável)\r\nMediana\r\nmedian(variável)\r\nDesvio padrão\r\nsd(variável)\r\nQuantil (10%)\r\nquantile(variável, probs=0.1)\r\nMáximo\r\nmax(variável)\r\nMínimo\r\nmin(variável)\r\nA nossa nova tabela agregada pode conter mais de uma estatística resumida, cada uma em uma coluna nova:\r\n\r\n\r\nflights %>% summarize(media_distance=mean(distance),\r\n                      mediana_distance=median(distance),\r\n                      sd_distance=sd(distance))\r\n\r\n\r\n\r\n\r\n\r\n\r\nÉ comum incorporar estatísticas resumidas no texto do nosso documento de R Markdown. Lembra-se de códigos ‘in-line’, no qual usamos `r ` fora do chunk? Como podemos inserir a nossa estatística no texto do relatório? O resultado de summarize() ainda é um tibble, e uma tabela não cabe em um parágrafo. Temos que transformar o valor no tibble em um valor único.\r\nUma função bastante útil aqui é pull() (tirar). Ele transforma uma variável de um tibble para um vetor, e quando o vetor tem apenas um elemento (ou seja, o tibble tem apenas uma linha), o resultado é um valor único, perfeito para inserir em in-line código:\r\n\r\n\r\nestatisticas <- flights %>% summarize(media_distance=mean(distance),\r\n                                      mediana_distance=median(distance),\r\n                                      sd_distance=sd(distance))\r\n\r\nmedia_distance <- estatisticas %>% pull(media_distance)\r\n\r\n\r\nAgora, posso gera a frase no relatório que se refere ao valor de media_distance:\r\n“A distância média dos voos é `r media_distance`.\r\n“A distância média dos voos é 1039.9126036”.\r\n\r\nHabilidade Básica de Programação: Excluindo NAs\r\nVamos tentar mais uma estatística:\r\n\r\n\r\nflights %>% summarize(dep_delay=mean(dep_delay))\r\n\r\n\r\nQual foi o resultado? NA? O que significa dados faltantes aqui? O padrão em R é reclamar quando tem um erro em potencial, forçando você a investigar. Isso pode ser chato às vezes, mas no longo prazo é uma medida necessária para garantir que você entenda o que você está calculando. Neste caso, na presença de pelo menos um valor NA na variável que estamos resumido, o R passa este NA para o resultado final, mesmo que existem milhares de outros valores prontos para serem resumidos. Isso é o nosso sinal que os nossos dados contém lacunas, e temos que deixar explícito para R como a tratar estes casos. Por enquanto vamos ignorar eles usando o argumento na.rm=TRUE, e calcular a estatística resumida apenas com os dados restantes:\r\n\r\n\r\nflights %>% summarize(dep_delay=mean(dep_delay,na.rm=TRUE))\r\n\r\n\r\n\r\n\r\n\r\nHabilidade Básica de Programação: Funções Novas\r\nO R é muito flexível - se você quiser uma agregação não disponível em uma função atual, pode gerar a sua própria função. Escrever uma função depende de um formato padrão - um nome pela função, os insumos que a função recebe como argumentos, e o objeto que quer devolver como resultado da função.\r\n\r\n\r\nnome_funcao <- function(insumo1, insumo2){\r\n\r\n  resultado <- ...\r\n  \r\n  return(resultado)\r\n    \r\n}\r\n\r\n\r\nImagine que queremos calcular a razão entre o percentil 90 e o percentil 10. Não existe uma função pronta para calcular isso, então vamos escrever nós mesmos.\r\n\r\n\r\npercentile_90_10 <- function(variavel) {\r\n  \r\n  calculo <- quantile(variavel, probs=0.9,na.rm=TRUE)/\r\n    quantile(variavel, probs=0.1,na.rm=TRUE)\r\n    \r\n    return(calculo)\r\n}\r\n\r\n\r\nUsamos variavel aqui para fazer referência a qualquer vetor (coluna) que o usuário vai especificar como insumo no futuro, e cada vez que precisamos pegar este vetor dentro da função, usamos o mesmo nome, variavel.\r\nNote que esta função aceita um vetor (apenas uma coluna do nosso tibble), e devolve um valor único, indicado por return(cálculo). Vamos aplicar a nossa nova função:\r\n\r\n\r\nflights %>% summarize(percentile_90_10_distance=percentile_90_10(distance),\r\n                      percentile_90_10_air_time=percentile_90_10(air_time))\r\n\r\n\r\n\r\n\r\n\r\n\r\nOs resultados significam que há mais variação na variável distance (o percentil 90 é 11 vezes maior que o percentil 10) do que na variável air_time (apenas 6.8 vezes maior).\r\nIsto é programação. Agora sabemos como trabalhar com os dois elementos fundamentais: objetos (data.frames/tibbles etc.) e funções. Tudo em R é uma combinação de objetos (substantivos) com funções (verbos) para criar a nossa receita de análise.\r\n\r\nGrupos (group_by)\r\nQuase sempre, os nossos dados estão organizados em grupos e subgrupos, pode ser anos, meses e dias, aeroportos, ou países. Frequentemente, nós queremos as estatísticas resumidas por ano, ou por país. O poder de summarize() é ampliado exponencialmente quando os resumos/agregações são feitos no nível de grupos e não para o banco de dados inteiro. O que define os grupos? Uma outra variável em nossa tabela.\r\nDado que podemos criar vários níveis/tipos de agrupamentos de nossos dados, temos que especificar quais nos queremos. Para definir os grupos relevantes, podemos criar um ‘grouped tibble’ usando o verbo group_by():\r\n\r\n\r\nflights_por_aeroporto <- flights %>% group_by(origin)\r\n\r\n\r\nQual o resultado, flights_por_aeroporto, e como difere do banco de dados original de flights? Parece igual! O número de linhas e colunas é igual, nada mudou…Se digitamos o nome do novo objeto flights_por_aeroporto no ‘Console’ no canto baixo do RStudio, podemos ver uma pequena diferença: existe uma linha Groups:   origin [3] que não existe no banco de dados original de flights. Este ‘3’ significa os três aeroportos de origem nos dados que usamos para agrupamento.\r\nNa prática, group_by() sozinho não é útil para nada. Temos que combinar com mais uma função subsequente para gerar resultados interessantes. Por exemplo, vamos calcular a média da distância por aeroporto:\r\n\r\n\r\nflights %>% group_by(origin) %>% \r\n  summarize(mean_distance=mean(distance))\r\n\r\n\r\n\r\n\r\n\r\n\r\nAgora, a nova tabela de resumo tem três linhas, uma para cada aeroporto. Os três grupos correspondem às três estatísticas resumidas. Note que não mudamos nada no summarize() do último comando - só temos mais um verbo em nosso pipe, o group_by().\r\nOs argumentos de group_by() são sempre as variáveis de agrupamento, e podem ser vários:\r\n\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  summarize(mean_distance=mean(distance))\r\n\r\n\r\n\r\n\r\n\r\n\r\nQuantas linhas têm o resultado? Porque 36? Porque pedimos agrupamento por origem (3 possibilidades) e mês (12 possibilidades): \\(3*12=36\\). A unidade de análise na tabela final é o aeroporto-mês.\r\nNote que o resultado de summarize() é sempre um tibble, então ele não precisa terminar o nosso fluxo de análise - podemos continuar processando o resultado de summarize() com todas as funções que já estamos acostumados a usar. Por exemplo, podemos combinar as funções filter e mutate para criar uma tabela apropriado para incluir em nosso relatório:\r\n\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  summarize(mean_distance=mean(distance)) %>%\r\n  filter(origin!=\"LGA\") %>%\r\n  mutate(mean_distance_km=mean_distance*1.60934)\r\n\r\n\r\n\r\n\r\n\r\n\r\nOutras funções de resumo também funcionam com group_by(). Quer o voo mais atrasado por aeroporto de origem? Use group_by conjunto com top_n (do tutorial anterior):\r\n\r\n\r\nflights %>% group_by(origin) %>%\r\n  top_n(1,dep_delay)\r\n\r\n\r\n\r\n\r\n\r\n\r\nRecebemos três voos, o mais atrasado em EWR, o mais atrasado em JFK, e o mais atrasado em LGA.\r\n\r\nExercício 1: Análises por Grupo\r\nUsando o banco de dados de flights no pacote nycflights13, responda às seguintes perguntas:\r\nCalcule a duração (air_time) média por companhia aérea (carrier).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(carrier) %>%\r\n  summarize(media_air_time=mean(air_time,na.rm=T))\r\n\r\n\r\nCalcule a duração (air_time) média por companhia aérea (carrier) e mês (month).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(carrier, month) %>%\r\n  summarize(media_air_time=mean(air_time,na.rm=T))\r\n\r\n\r\nCalcule o atraso médio (dep_delay) por aeroporto de origem (origin). Qual aeroporto tem o pior atraso?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin) %>%\r\n  summarize(media_dep_delay=mean(dep_delay,na.rm=T)) %>%\r\n  arrange(-media_dep_delay)\r\n\r\n\r\nQual companhia aérea (carrier) tem o pior registro de atrasos (dep_delay) na média no aeroporto JFK?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"JFK\") %>% \r\n  group_by(carrier) %>%\r\n  summarize(media_dep_delay=mean(dep_delay,na.rm=T)) %>%\r\n  arrange(-media_dep_delay)\r\n\r\n\r\nVocê odeia atrasos. Qual é o pior mês para viajar do aeroporto JFK?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"JFK\") %>% \r\n  group_by(month) %>%\r\n  summarize(media_dep_delay=mean(dep_delay,na.rm=T)) %>%\r\n  arrange(-media_dep_delay)\r\n\r\n\r\n\r\nNúmero de observações por Grupo (tally)\r\nUma aplicação enormemente útil de group_by() é calcular o número de observações (linhas) em cada grupo do banco de dados.\r\n\r\n\r\nflights %>% group_by(origin) %>% \r\n  tally()\r\n\r\n\r\n\r\n\r\n\r\n\r\nAssim, é fácil comparar o número de voos em cada aeroporto. A função tally não precisa de argumentos.\r\nQuantos voos decolaram de cada aeroporto de origem para cada destino?\r\n\r\n\r\nflights %>% group_by(origin, dest) %>% \r\n  tally()\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nExercício 2: Observações por Grupo\r\nQuantos voos decolaram de Nova Iorque em cada mês de 2013?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(month) %>% \r\n  tally()\r\n\r\n\r\nQual companhia aérea teve o maior número de voos em cada mês de 2013?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(month, carrier) %>% \r\n  tally() %>%\r\n  group_by(month) %>% \r\n  top_n(1,n)\r\n\r\n\r\nQual é a média do número de voos que decolaram dos três aeroportos, em cada mês?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  tally() %>%\r\n  group_by(month) %>%\r\n  summarize(media_n=mean(n,na.rm=T))\r\n\r\n\r\nQual é a média mensal do número de voos que decolaram em cada aeroporto?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  tally() %>%\r\n  group_by(origin) %>%\r\n  summarize(media_n=mean(n,na.rm=T))\r\n\r\n\r\nQual horário de partida (dep_time) é o segundo mais congestionado (medida pelo número de decolagens) em cada aeroporto? (O mais congestionado é o horário NA, então é mais interessante pegar o segundo mais congestionado).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin,dep_time) %>%\r\n  tally() %>%\r\n  group_by(origin) %>%\r\n  top_n(2,n)\r\n\r\n\r\n\r\nMutate por Grupo\r\nNão é apenas resumos que conseguimos executar por grupo. É comum também aplicar um mutate() por grupo. Esta combinação fornece muita flexibilidade e poder. Por exemplo, se quiser manter o tamanho e a unidade de análise do seu banco de dados original, e inserir a média do grupo como coluna, pode executar assim:\r\n\r\n\r\nflights %>% group_by(origin) %>%\r\n  mutate(media_distance=mean(distance,na.rm=TRUE))\r\n\r\n\r\n\r\n\r\n\r\n\r\nConfirme no tibble resultante que o número de linhas não mudou, e que a média distância é igual para todos os voos do mesmo aeroporto, e varia entre aeroportos.\r\nQual a diferença conceitual entre summarize() e mutate()?\r\nsummarize() sempre reduz o número de linhas no banco de dados - é uma agregação total ou por grupo.\r\nmutate() nunca reduz (ou aumenta) o número de linhas no banco de dados - apenas adiciona uma nova coluna.\r\nSaindo de Agrupamentos (ungroup)\r\nAgrupamentos são poderosos - eles permitem organizar os nossos dados na forma que faz sentido para a nossa análise sem calcular os denominadores separadamente. Mas tome cuidado: O R lembra de tudo. Quando você usa group_by() ele é mantido para o resto da operação (os pipes seguintes), e também dentro de objetos salvos. Isso é útil se queremos continuar com o mesmo agrupamento, mas pode gerar resultados inesperados se esquecemos que já agrupamos os nossos dados. Para tirar o agrupamento, temos que usar a função ungroup(), sem argumento.\r\nPara demonstrar isso, veja a descrição do objeto salvo abaixo com a função de utilidade groups que imprime os grupos do tibble:\r\n\r\n\r\nflights_media <- flights %>% group_by(origin) %>%\r\n  mutate(media_distance=mean(distance,na.rm=TRUE))\r\n\r\ngroups(flights_media)\r\n\r\n[[1]]\r\norigin\r\n\r\nO que acontece se usarmos o tibble agrupado em uma nova operação? Imagine que em mais três páginas de código queremos calcular a média de atrasos (dep_delay) com summarize:\r\n\r\n\r\nflights_media %>% summarize(media_atraso=mean(dep_delay,na.rm=T))\r\n\r\n\r\n\r\n\r\n\r\n\r\nRecebemos três linhas, mesmo pedindo só uma média! O agrupamento ainda restringe o escopo do resumo de summarize, e o R gerou uma média por aeroporto (origin). Mais geralmente, se esquecemos do agrupamento, é fácil gerar o resultado inesperado.\r\nPara evitar esta situação chata, temos que sempre lembrar qual é a unidade de agrupamento. Para voltar analisar o banco de dados inteiro, temos que tirar o agrupamento com ungroup():\r\n\r\n\r\nflights_media %>% ungroup() %>% \r\n  summarize(media_atraso=mean(dep_delay,na.rm=T))\r\n\r\n\r\n\r\n\r\n\r\n\r\nFácil de fazer, difícil de lembrar! Preste atenção!\r\nPorcentagens\r\nUm dos pedidos mais comuns é calcular porcentagens em R. Tome cuidado: já vi muitos cálculos errados, mesmo sendo um cálculo simples de porcentagem. A chave para evitar erros está na definição do denominador da fórmula da porcentagem:\r\n\\[\\text{%} = \\frac{\\text{Valor}}{\\text{Total do grupo relevante}}*100 \\]\r\nQueremos uma porcentagem para cada observação no banco de dados, então isso exige um mutate(). Por exemplo, se quisermos calcular a porcentagem da distância de cada voo na distância total de todos os voos, podemos calcular o total, e depois dividir cada valor pelo total:\r\n\r\n\r\nflights %>% \r\n  mutate(Total_distance=sum(distance,na.rm=TRUE)) %>% \r\n  mutate(Pct_distance=100*(distance/Total_distance))\r\n\r\n\r\nSalvando digitação, podemos combinar as duas etapas com o mesmo resultado:\r\n\r\n\r\nflights %>% mutate(Pct_distance=100*(distance/sum(distance,na.rm=TRUE)))\r\n\r\n\r\n\r\n\r\n\r\n\r\nNote que o sum() aqui está somando a distância de todas as observações. Claro que cada voo é uma porcentagem pequena do total na última coluna.\r\nSe quisermos a porcentagem da distância de cada voo no total de cada mês, temos que limitar o escopo de sum() apenas para as observações de um mesmo mês. O group_by() facilita isso:\r\n\r\n\r\nflights %>% group_by(month) %>% \r\n  mutate(Pct_distance_por_mes=100*(distance/sum(distance,na.rm=TRUE)))\r\n\r\n\r\n\r\n\r\n\r\n\r\nComo interpretamos este código? Pegue o banco de dados flights, divida ele em grupos, um para cada mês (group_by(month)), calcule a distância total voada em cada mês (sum(distance,na.rm=TRUE)), divida cada distância individual pelo total do mês apropriado (em que ele voou), multiplique ele por 100, e salve o resultado na coluna Pct_distance_por_mes.\r\nAgora a última coluna reflete a porcentagem de distância de cada voo no total de milhas de voos no mesmo mês. Podemos ser mais específico ainda, limitando o denominador e aumentado a porcentagem resultante:\r\n\r\n\r\nflights %>% group_by(month, day, hour, origin) %>% \r\n  mutate(Pct_distance_por_mes_hora_origem=100*(distance/sum(distance,na.rm=TRUE)))\r\n\r\n\r\n\r\n\r\n\r\n\r\nA variável nova agora mede: entre todos os voos que decolaram no mesmo mês, mesmo dia e mesma hora, no mesmo aeroporto, qual porcentagem da distância voada contribuiu este voo específico?\r\nFinalmente, é comum calcular a porcentagem do número de observações (linhas) em um grupo comparado com o total. Neste caso, calculamos a porcentagem não baseada em uma variável, mas baseada no número de linhas. O fluxo de trabalho recomendado é:\r\n\r\n\r\nflights %>% group_by(origin) %>% \r\n  tally() %>%\r\n  mutate(Pct_por_aeroporto=100*(n/sum(n)))\r\n\r\n\r\n\r\n\r\n\r\n\r\nSe quiser calcular a porcentagem de voos por mês em cada aeroporto separado, podemos usar dois processos de agrupamento, primeiro para calcular o número de observações por aeroporto-mês, e segundo para definir o denominador como o aeroporto para o cálculo de porcentagem:\r\n\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  tally() %>%\r\n  group_by(origin) %>% \r\n  mutate(Pct_por_mes_no_aeroporto=100*(n/sum(n)))\r\n\r\n\r\n\r\n\r\n\r\n\r\nVocê consegue descrever o que o código acima fez, passo-a-passo?\r\nÉ importante entender que as porcentagens acima são diferentes do que calculamos se trocamos origin por month no segundo agrupamento:\r\n\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  tally() %>%\r\n  group_by(month) %>% \r\n  mutate(Pct_por_mes_no_aeroporto=100*(n/sum(n)))\r\n\r\n\r\n\r\n\r\n\r\n\r\nAgora, a porcentagem representa quanto cada aeroporto contribuiu para o número de voos em cada mês, então os valores são mais próximos a um terço cada um.\r\n\r\nHabilidade Básica de Programação: Filtros Avançados (%in%)\r\nFiltros são úteis para limitar as nossas operações, mas às vezes é demorado construir condições complexas. Por exemplo, se quisermos calcular a porcentagem da distância de cada voo na distância total de todos os voos com destino de “ILM”, “ACK”, “GRR” ou “PSP”\r\n\r\n\r\nflights %>% filter(dest==\"ILM\"|dest==\"ACK\"|dest==\"GRR\"|dest==\"PSP\") %>%\r\n  mutate(Pct_distance=100*(distance/sum(distance,na.rm=TRUE)))\r\n\r\n\r\n\r\n\r\n\r\n\r\nQue chato repetir dest== cada vez… É necessário porque podemos combinar condições de várias variáveis e precisamos ser explícito com R qual variável queremos comparar cada vez. Mas existe uma alternativa: criamos um vetor de todas as opções com c() e pedimos o R filtrar a variável para qualquer elemento do vetor. É equivalente a == para cada elemento, e uma relação de ‘OR’ entre elementos.\r\n\r\n\r\nflights %>% filter(dest %in% c(\"ILM\", \"ACK\", \"GRR\", \"PSP\")) %>%\r\n  mutate(Pct_distance=100*(distance/sum(distance,na.rm=TRUE)))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nResumos de Múltiplas Colunas (across())\r\nUma limitação de summarize() é que temos que pedir a média de cada variável separadamente. Se tivermos dezenas de variáveis, isso exige muito código. Não há jeito de calcular a média de diversas variáveis? Há sim! Podemos usar uma função de utilidade, across(), dentro de summarize().\r\nO sintaxe de across() é um pouco diferente: nos parênteses, especificamos o nome da função/estatística sem parênteses (mean), e depois da vírgula qualquer outro argumento à função mean (aqui na.rm=TRUE):\r\n\r\n\r\nflights %>% summarize(across(c(dep_time, dep_delay), \r\n                             mean, \r\n                             na.rm=TRUE))\r\n\r\n\r\n\r\n\r\n\r\n\r\nAssim calculamos a média das duas variáves dep_time e dep_delay, ou quaisquer variáveis que quisemos.\r\nTambém é possível pedir múltiplos resumos do mesmo conjunto de variáveis, inserindo as funções de resumo dentro de list():\r\n\r\n\r\nflights %>% summarize(across(c(dep_time, dep_delay), \r\n                             list(mean, \r\n                                  median), \r\n                             na.rm=TRUE))\r\n\r\n\r\nO resultado contêm quatro colunas - as colunas que terminam em _1 se referem à primeira função mean e _2 à median. Para deixar mais claro, basta ‘nomear’ as funções na lista antes do sinal de igual:\r\n\r\n\r\nflights %>% summarize(across(c(dep_time, dep_delay), \r\n                             list(media=mean, \r\n                                  mediana=median), \r\n                             na.rm=TRUE))\r\n\r\n\r\n\r\n\r\n\r\n\r\nE se quisermos um resumo de todas as colunas? Existe mais uma função de utilidade que podemos inserir dentro de across(); everything(), que, naturalmente, aplica o resumo a todas as colunas.\r\n\r\n\r\nflights %>% summarize(across(everything(), \r\n                             mean, \r\n                             na.rm=TRUE))\r\n\r\n\r\n\r\n\r\n\r\n\r\nSalvamos 18 linhas de código comparado com o uso de summarize para cada variável individualmente!\r\nNote que mean apenas funciona para variáveis numéricas; ele devolve NA para variáveis do tipo caractere ou factor.\r\nTransformações de Múltiplas Colunas (across())\r\nPodemos tentar o mesmo com mutate para mantermos a unidade de análise do banco de dados original, mas transformar cada variável com a mesma transformação. Por exemplo, na estatística frequentemente queremos padronizar cada variável, subtraindo a média e dividindo pelo desvio padrão. Esta função simples já existe, se chama scale. Vamos aplicar a todas as colunas do banco de dados flights:\r\n\r\n\r\nflights %>% mutate(across(everything(), \r\n                          scale))\r\n\r\n\r\nNão funcionou. Qual foi o erro? Aqui, a função scale apenas funciona com variáveis numéricas, e across() não é suficientemente flexível para pular as colunas que contém caracteres infelizmente. Agora temos duas alternativas. Uma é usar across() para selecionar as colunas numéricas manualmente antes de rodar mutate():\r\n\r\n\r\nflights %>% mutate(across(c(year, month, day, dep_time, sched_dep_time, dep_delay, arr_time, sched_arr_time, arr_delay, flight, air_time, distance, hour, minute), \r\n                          scale))\r\n\r\n\r\nDeu certo, mas um pouco chato para digitar. A segunda opção usa uma outra variedade de across() que permite especificar o tipo das variáveis. Combinamos três funções de utilidade, across(), where() e is.numeric: across() significa que queremos selectionar múltiplas colunas; where() significa que queremos selecionar um sub-conjunto de colunas de acordo com um critério, e is.numeric é o critério para identificar apenas as colunas númericas.\r\n\r\n\r\nflights %>% mutate(across(where(is.numeric), \r\n                          scale))\r\n\r\n\r\nVeja a beleza de programação mais eficiente - o mesmo resultado com menos digitação! Como interpretamos o código? “Pegue o banco de dados de flights, depois aplica uma transformação às variáveis onde a variável is.numeric (é númerica), e a transformação desejada é scale.”\r\n\r\nExercício 3: Resumos Avançados\r\nCalcule o total de distância dos voos que decolaram de cada aeroporto e inserir os cálculos na tabela original de flights como uma coluna nova.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin) %>% \r\n  mutate(dist_total=sum(distance,na.rm=T))\r\n\r\n\r\nCalcule a média do atraso médio de cada aeroporto de origem em cada mês\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin,month) %>%\r\n  summarize(media_dep_delay=mean(dep_delay,na.rm=T)) %>%\r\n  ungroup() %>% \r\n  summarize(media_media_dep_delay=mean(media_dep_delay,na.rm=T))\r\n\r\n\r\nQual a porcentagem dos voos em cada destino? Qual destino é o mais comum?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(dest) %>% \r\n  tally() %>%\r\n  mutate(Pct_dest=100*(n/sum(n))) %>%\r\n  arrange(-Pct_dest)\r\n\r\n\r\nQual a porcentagem do tempo de atraso por companhia aérea em cada aeroporto? Qual é a companhia aérea responsável pelo maior tempo atrasado no aeroporto de Newark (EWR)?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin, carrier) %>%\r\n  summarize(total_atraso=sum(dep_delay, na.rm=T)) %>%\r\n  group_by(origin) %>%\r\n  mutate(Pct_total_atraso=100*(total_atraso/sum(total_atraso,na.rm=T))) %>%\r\n  arrange(origin, -Pct_total_atraso)\r\n\r\n\r\nTransforme a ordem de grandeza de todas as variáveis dep_delay, arr_delay e air_time de minutos para horas. Escreva uma função nova para facilitar esta transformação em conjunto com across().\r\n\r\n\r\nMostrar Código\r\n\r\nmins_to_horas <- function(x){\r\n  return(x/60)\r\n}\r\n\r\nflights %>% mutate(across(c(dep_delay, arr_delay, air_time), mins_to_horas))\r\n\r\n\r\n\r\n\r\nVeja um resumo das funções principais até o final deste tutorial aqui\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:14:05-03:00"
    },
    {
      "path": "Graficos.html",
      "title": "Gráficos",
      "description": "Visualizando os nossos Dados\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nGráficos\r\nA Gramática de Gráficos\r\nEstéticas\r\nGeometrias\r\nControlando cores com ‘scales’\r\nPersonalização de Gráficos além de geometria\r\nGráficos interativos e animações\r\n\r\nGráficos\r\nJá aprendemos muito sobre a ‘gramática’ de manipulação de dados para produzir tibbles/tabelas conforme os requisitos da nossa análise. Existe uma gramática diferente, mas conectada, que usamos para produzir um gráfico. Note que, em contraste com outras formas de produzir gráficos, não desenhamos os elementos à mão ou individualmente - para produzir gráficos através de programação, temos que definir todos os elementos do gráfico baseado nas variáveis em nosso tibble.\r\nExiste uma forte ligação entre a gramática de manipulação de dados e a gramática de visualização: toda a informação para o nosso gráfico vem de um tibble. Cada linha em nosso tibble é uma ‘unidade’ a ser exibida no gráfico, e cada coluna em nosso tibble é uma variável que determina um aspecto visual específico do gráfico, incluindo posição, cor, tamanho e forma. Por isso, apenas podemos pensar em produzir um gráfico depois de organizar e transformar os nossos dados para um tibble de formato apropriado para a visualização.\r\nNeste tutorial vamos apresentar a estrutura do código para produzir gráficos a partir de alguns exemplos simples e propositalmente não cobriremos todas as (inúmeras) possibilidades de visualização.\r\nAntes de mais nada, temos que lembrar a classificação de tipos de dado, porque isso é crucial para determinar quais gráficos podemos produzir:\r\n\r\n\r\nTipo em R\r\nAtalho em tibble\r\nDiscreta\r\nNominal\r\nFactor ou Character\r\nfctr, chr\r\n\r\nOrdinal\r\nOrdered Factor\r\nfctr, chr\r\n\r\nInteiro\r\nInteger\r\nint\r\nContínua\r\n\r\nDouble/Numeric/Real\r\ndbl\r\nVamos distinguir principalmente entre variáveis discretas e variáveis contínuas. As discretas têm que ser mapeadas para elementos gráficos independentes - colunas, ou histogramas, formas e cores distintas - e as contínuas têm que ser mapeadas para elementos gráficos que variam gradualmente - densidades, tamanho e escalas de cores.\r\nA Gramática de Gráficos\r\nO nosso pacote de gráficos já foi aberto dentro de tidyverse, e se chama ggplot (‘gg’ para gramática de gráficos). A sintaxe de ggplot é nova e diferente, mas se integra perfeitamente ao nosso fluxo de trabalho, seguindo a nossa preparação de dados depois de mais um pipe. A conexão com elemento do gráfico se dá com o sinal positivo (+). É mais fácil mostrar com um exemplo:\r\n\r\n\r\nlibrary(\"tidyverse\")\r\nlibrary(\"tidylog\")\r\nlibrary(\"nycflights13\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nflights %>% filter(dest==\"DEN\") %>%\r\n  ggplot() + \r\n  geom_point(aes(x=dep_time, y=dep_delay), size=1)\r\n\r\n\r\n\r\nParabéns, você acabou de produzir o seu primeiro gráfico! O que você acha? Não é o mais bonito, mas é impressionante para um código de três linhas curtas. Mas provavelmente o código acima permanece um mistério. Vamos desagregar os componentes:\r\n\r\nComeçamos - como sempre - com o nosso banco de dados (tibble) relevante. Seguimos com qualquer transformação de dados desejada, aqui um filtro para o destino de Denver (‘DEN’). O último pipe passa o tibble resultante (apenas os voos para Denver) para o meio-ambiente de gráficos, o ggplot() (sem argumento). ggplot() é uma função que inicia um gráfico, mas na verdade não coloca nenhum conteúdo nele.\r\nAgora, uma observação importante: os nossos gráficos são compostos por várias ‘camadas’, que podemos juntar em linhas separadas. Adicionamos as camadas com o símbolo ‘+’ em vez de um pipe (‘%>%’). É fácil esquecer a diferença, mas é importante: um pipe (‘%>%’) passa os dados para transformação e o ‘+’ adiciona mais informação, mais camadas.\r\nPara entender a última linha de geom_point() temos que discutir dois componentes cruciais: Estéticas - mapeamentos de variáveis para elementos do gráfico - e Geometrias - o estilo visual do gráfico.\r\nEstéticas\r\nExistem centenas de elementos do nosso gráfico que podemos personalizar. Em breve vamos ver como customizar os títulos, os eixos, o fundo, a legenda etc. Agora, vamos focar nos elementos visuais de cada camada (cada geometria) de dados. Há várias opções, a disponibilidade delas depende de qual geometria estamos usando, mas é bom resumir as opções mais comuns:\r\n\r\n\r\nEstética\r\n\r\n\r\nDescrição\r\n\r\n\r\nx\r\n\r\n\r\nPosição em relação a eixo x\r\n\r\n\r\ny\r\n\r\n\r\nPosição em relação a eixo y\r\n\r\n\r\ncolour\r\n\r\n\r\nCor de ponto/linha/contorno de polígono\r\n\r\n\r\nfill\r\n\r\n\r\nCor de dentro de área/barra\r\n\r\n\r\nalpha\r\n\r\n\r\nTransparência\r\n\r\n\r\nshape\r\n\r\n\r\nForma da observação\r\n\r\n\r\nsize\r\n\r\n\r\nTamanho da observação\r\n\r\n\r\nlinetype\r\n\r\n\r\nSe a linha estiver preenchida, pontilhada ou tracejada\r\n\r\n\r\nlabel\r\n\r\n\r\nTexto\r\n\r\n\r\nEstéticas podem ser ligadas com as variáveis do nosso banco de dados. Por exemplo, se quisermos mostrar um ponto para cada voo, pode ser que o x reflete a hora de partida (a variável dep_time), o y reflete o atraso (dep_delay), o shape reflete o aeroporto de partida (origin), o size reflete a distância de viagem (distance), e o colour reflete a companhia aérea (carrier).\r\n\r\nHá duas opções para especificar as estéticas de uma camada, dependendo se queremos que as estéticas variem conforme com os nossos dados, ou sejam fixas e constantes para todas as observações.\r\nPara estéticas que variam com os nossos dados (ex. a cor depende da companhia aérea), definimos a estética com uma variável, e dentro da função aes().\r\n\r\n... geom_point(aes(x=dep_time, y=dep_delay, shape=origin, size=distance, colour=carrier))\r\n\r\nPara estéticas que não variam com os nossos dados (ex. o tamanho é fixo), definimos a estética com um valor único (uma constante) em vez de uma variável, e fora da função aes().\r\n\r\n... geom_point(size=10, alpha=0.7)\r\n\r\nClaro que podemos combinar as duas formas:\r\n\r\n... geom_point(aes(x=dep_time, y=dep_delay), size=1)\r\n\r\nGeometrias\r\nA parte mais difícil de preparar um gráfico é escolher a geometria apropriada. Claro que isto tem a ver com o estilo de gráfico que queremos, mas também depende do número e os tipos de variáveis que queremos apresentar. Todas as geometrias começam com geom_, e as opções mais comuns são as seguintes (lembrando que existem possibilidades infinitas):\r\n\r\n\r\nGeom\r\n\r\n\r\nVariáveis para Visualizar\r\n\r\n\r\nEstéticas comuns\r\n\r\n\r\nExemplo\r\n\r\n\r\ngeom_bar\r\n\r\n\r\nUma variável discreta (o número de observações por grupo)\r\n\r\n\r\nx\r\n\r\n\r\n\r\n\r\ngeom_histogram\r\n\r\n\r\nUma variável contínua\r\n\r\n\r\nx\r\n\r\n\r\n\r\n\r\ngeom_density\r\n\r\n\r\nUma variável contínua\r\n\r\n\r\nx\r\n\r\n\r\n\r\n\r\ngeom_point\r\n\r\n\r\nDuas variáveis contínuas\r\n\r\n\r\nx, y\r\n\r\n\r\n\r\n\r\ngeom_histogram\r\n\r\n\r\nUma variável contínua, e uma discreta\r\n\r\n\r\nx, fill\r\n\r\n\r\n\r\n\r\ngeom_density\r\n\r\n\r\nUma variável contínua, e uma discreta\r\n\r\n\r\nx, colour\r\n\r\n\r\n\r\n\r\ngeom_boxplot\r\n\r\n\r\nUma variável contínua, e uma discreta\r\n\r\n\r\nx, y\r\n\r\n\r\n\r\n\r\ngeom_col\r\n\r\n\r\nUma variável contínua, e uma discreta\r\n\r\n\r\nx, y\r\n\r\n\r\n\r\n\r\ngeom_line\r\n\r\n\r\nUma variável contínua, e uma discreta ordenada\r\n\r\n\r\nx, y, group\r\n\r\n\r\n\r\n\r\ngeom_point\r\n\r\n\r\nDuas variáveis contínuas e uma discreta\r\n\r\n\r\nx, y, colour/shape/size\r\n\r\n\r\n\r\n\r\nGeometria para uma variável discreta (o número de observações por grupo)\r\nVamos começar com o gráfico mais simples. Os nossos dados são divididos em grupos por uma variável discreta e queremos conhecer o número de observações (linhas) em cada grupo. Veja como apresentar essa informação em ggplot para o banco de dados de flights por origin:\r\n\r\n\r\nflights %>% ggplot() +\r\n  geom_bar(aes(x=origin))\r\n\r\n\r\n\r\nVamos olhar cada uma de suas partes.\r\nComecemos pela primeira linha. A principal função do código é, como era de se esperar, o nosso tibble, seguido por ggplot(). Note que não estamos fazendo uma atribuição, por enquanto, pois queremos apenas “imprimir” o gráfico, e não guardá-lo como objeto (algo perfeitamente possível!). ggplot() é uma função que inicia um gráfico, mas na verdade não coloca nenhum conteúdo nele.\r\nAgora, para adicionar uma geometria, colocamos um símbolo de “+” após fechar o parênteses da função ggplot e, convencionalmente na linha seguinte, utilizamos a função da geometria correspondente. Cada “+” nos permite adicionar mais uma camada em nosso gráfico. Mas qual camada? Nós definimos uma camada principalmente por sua geometria - o tipo de representação visual dos nossos dados que queremos. geom_bar indica que queremos uma geometria de barras, como um ‘bar chart’ em excel.\r\nA escolha da geometria depende do tipo de dados que você deseja visualizar de seu tibble. Aqui, analisamos os dados por origem, que é uma variável discreta com três valores (character ou factor), então usamos uma geometria que corresponda com dados discretos. Quando não queremos cruzar esta variável discreta com nenhuma outra variável, a única coisa que pode ser feito é contar e comparar o número de observações (voos) em cada grupo (origem).\r\nA lógica de um gráfico de barras é representar a contagem de frequência de cada categoria discreta, então faz sentido usar a geometria geom_bar. Vamos ver exemplos de outras geometrias que correspondam a outros dados abaixo.\r\nNa linha de código da geometria, as 3 letrinhas “aes” causam estranheza. “aes” é a abreviação de “aesthetics”. Aqui definiremos quais variáveis de nosso tibble farão parte do gráfico. Estamos trabalhando por enquanto com apenas uma variável, e cada grupo será representado separadamente ao longo do eixo horizontal, ou eixo “x”. Por esta razão preenchemos o parâmetro “x” da “aesthetics” e nada mais.\r\n\r\nHabilidade Básica de Programação: Apresentando Gráficos no relatório final\r\nAntes de mais nada, vamos ver como encaminhar os nossos gráficos para o relatório final (HTML, DOC ou PDF). Isto é a parte fácil. Deixamos o nosso gráfico em um chunk (sem salvar como objeto) e ele será inserido no relatório final na mesma localização, antes e depois de qualquer texto simples.\r\n```{r}\r\nflights %>% ggplot() +\r\n  geom_bar(aes(x=origin))\r\n```\r\nSe preferir, você pode salvar o seu gráfico como objeto, e depois digitar o nome do objeto em um chunk sozinho para gerar o mesmo efeito.\r\n```{r}\r\ngrafico <- flights %>% ggplot() +\r\n  geom_bar(aes(x=origin))\r\n```\r\n```{r}\r\ngrafico\r\n```\r\nExistem algumas opções de chunk que podemos usar para controlar a apresentação dos gráficos. Os mais importantes são fig.height e fig.width que nos permitem especificar o tamanho do gráfico final, em unidades de inches.\r\n```{r, fig.height=2, fig.width=2}\r\nflights %>% ggplot() +\r\n  geom_bar(aes(x=origin))\r\n```\r\n\r\nGráficos com uma variável contínua - Gráficos de histogramas\r\nVamos trocar rapidamente para gráficos de uma variável contínua, como a velocidade, alterando o valor de “x” dentro de aes(). (Não temos variáveis verdadeiramente contínuas no banco de flights - mesmo os horários são variáveis discretas por minuto, então vamos calcular velocidade no fluxo de processamento).\r\n\r\n\r\nflights <- flights %>% \r\n  mutate(velocidade=distance/air_time) \r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_bar(aes(x=velocidade))\r\n\r\n\r\n\r\nEste gráfico está quase em branco, por quê? Tentamos representar uma variável contínua (velocidade) com uma geometria construída para variáveis discretas (geom_bar). Como cada valor de velocidade é quase único, existe uma barra (minúscula) para cada indivíduo e o gráfico não faz sentido. Precisamos mudar o geometria: o equivalente de um gráfico de barras para variáveis únicas contínuas é uma histograma que agrega os valores em grupos (barras), então usamos geom_histogram.\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_histogram(aes(x=velocidade))\r\n\r\n\r\n\r\nFaz mais sentido? Espero que sim. Compare os dois códigos dos gráficos acima com calma e compreenda as diferenças. Note que é o tipo de variável que demanda a geometria a ser escolhida, e não o contrário.\r\nParâmetros fixos\r\nAs geometrias, cada uma com sua utilidade, também têm parâmetros que podem ser alterados. Por exemplo, as barras do histograma que acabamos de produzir tem uma largura fixa. Vamos aumentar sua largura - o binwidth - ou seja, vamos representar mais valores do eixo “x” em cada barra do histograma:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_histogram(aes(x=velocidade), binwidth=1)\r\n\r\n\r\n\r\nUma observação importante aqui: o binwidth é especificado fora do aes(). Por quê? Porque existe uma regra importante no ggplot: parâmetros que variem dependendo de nossos dados devem ficar dentro de aes(); parâmetros fixos que não dependam de nossos dados devem ficar fora do aes(). Então, em nosso código, temos dentro de aes() uma variável, velocidade, e fora de aes() um número fixo independente dos dados, 1.\r\nO gráfico está muito cinza. Se quisermos mudar algumas cores, onde vamos especificar novos parâmetros de cores? Enquanto as cores são fixas para todo o gráfico e não dependem de nossos dados, inserimos o parâmetro fora de aes(). O parâmetro de fill especifica o preenchimento da barra, e o colour a borda. Pode usar nomes de cores simples em inglês (vamos ver outras opções em breve).\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_histogram(aes(x=velocidade), binwidth=1, colour=\"black\", fill=\"orange\")\r\n\r\n\r\n\r\nMelhor, não? Em geral, os argumentos “colour” e “fill” servem as várias geometrias.\r\nCuriosidade: R aceita as duas grafias em inglês para a palavra cor, “colour” (britânico, e obviamente o mais correto e bonito!) e “color” (americano).\r\nGráficos com uma variável contínua - Gráficos de densidade\r\nUma alternativa mais elegante ao histograma são os gráficos de densidade. Vamos, assim, apenas alterar a geometria para a mesma variável, velocidade, e observar novamente sua distribuição. A lição é que, embora a geometria deva corresponder ao tipo de dados, existem várias geometrias que podem funcionar para um tipo de dado específico (histograma ou densidade, por exemplo).\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=velocidade))\r\n\r\n\r\n\r\nLindo, mas ainda cinza demais. Vamos adicionar cor à borda:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=velocidade), colour=\"blue\")\r\n\r\n\r\n\r\nMelhor (melhor?), mas ainda muito branco. Vamos adicionar cor ao interior da curva:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=velocidade), colour=\"blue\", fill=\"blue\")\r\n\r\n\r\n\r\nMuito pior. E se deixássemos a curva mais “transparente” com o parâmetro alpha?\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=velocidade), colour=\"blue\", fill=\"blue\", alpha=0.2)\r\n\r\n\r\n\r\nAgora sim melhorou. Mas nos falta uma referência para facilitar a leitura do gráfico. Por exemplo, seria legal adicionar uma linha vertical que indicasse onde está a média da distribuição. Vamos calcular a média da renda usando as nossas habilidades do tutorial de resumos estatísticos, e com a ajuda de pull para transformar o resultado de um tibble para um valor único:\r\n\r\n\r\nmedia_velocidade <- flights %>% summarize(media_velocidade=mean(velocidade,na.rm=T)) %>%\r\n  pull(media_velocidade)\r\n\r\n\r\nMas estamos tratando de curvas de densidade, não estamos? Nessa geometria não há possibilidade de representar valores com uma linha vertical. Vamos, então, adicionar uma nova camada e uma nova geometria, com uma estética própria, xintercept, que aceita a localização de uma linha vertical, e com novos dados (no caso, um valor único), ao gráfico que já havíamos construído:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=velocidade), colour=\"blue\", fill=\"blue\", alpha=0.2) +\r\n  geom_vline(aes(xintercept = media_velocidade))\r\n\r\n\r\n\r\nVeja que, com ggplot, podemos adicionar novas geometrias e dados sempre que precisarmos. Agora, temos duas camadas e duas geometrias.\r\nPara tornar o gráfico mais interessante, vamos alterar a forma e a cor da linha adicionada no gráfico anterior:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=velocidade), colour=\"blue\", fill=\"blue\", alpha=0.2) +\r\n  geom_vline(aes(xintercept = media_velocidade), linetype=\"dashed\", colour=\"red\")\r\n\r\n\r\n\r\n\r\nExercício 1: Gráficos de uma Variável\r\nPrepare um gráfico de barras mostrando o número de voos por mês.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% \r\n  ggplot() + \r\n  geom_bar(aes(x=month))\r\n\r\n\r\nPrepare um gráfico de barras mostrando o número de voos por companhia aérea (carrier) para o aeroporto de origem JFK.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"JFK\") %>%\r\n  ggplot() + \r\n  geom_bar(aes(x=carrier))\r\n\r\n\r\nPrepare um histograma mostrando a distribuição do número de voos por hora de partida (dep_time) para voos entre EWR e SFO (San Francisco).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"EWR\" & dest==\"SFO\") %>%\r\n  ggplot() + \r\n  geom_histogram(aes(x=dep_time))\r\n\r\n\r\nPrepare um gráfico de densidade mostrando a distribuição de duração (air_time) para voos entre JFK e LAX (Los Angeles).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"JFK\" & dest==\"LAX\") %>%\r\n  ggplot() + \r\n  geom_density(aes(x=air_time))\r\n\r\n\r\n\r\nGráficos com uma variável contínua e uma variável discreta\r\nVamos dar alguns passos para trás e retornar aos histogramas. Lembre-se que estávamos visualizando a distribuição de uma variável contínua. E se quisermos comparar a variável contínua entre subgrupos dos nossos dados? Por exemplo, visualizar o horário de partida, dep_time, por aeroporto de origem, origin? Precisamos filtrar os dados e fazer um gráfico separado para cada aeroporto?\r\nPoderíamos. Mas mais interessante é comparar as distribuições em um mesmo gráfico. Para fazer isso, precisamos saber como visualizar duas variáveis do nosso tibble ao mesmo tempo. Como estamos separando uma distribuição de uma variável contínua (dep_time) em três, a partir de uma segunda variável discreta (origin), precisamos adicionar essa nova variável à “aesthetics” (aes). Veja como:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_histogram(aes(x=dep_time, fill=origin))\r\n\r\n\r\n\r\nObserve que adicionamos o parâmetro “fill” à “aesthetics” (dentro do aes() porque ele depende de nossos dados). Isso significa que a variável origin separará as distribuições de velocidade em cores de preenchimento diferentes. Conseguem ver as três distribuições, uma acima da outra? Note que agora temos uma legenda.\r\nA sobreposição dos dois histogramas dificulta a visualização de todos os dados. Podemos ajustar como os dois conjuntos de dados são exibidos um em cima do outro com o argumento ‘position’. Por exemplo, com position=\"dodge\" podemos organizar os dados lado a lado:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_histogram(aes(x=dep_time, fill=origin), \r\n                 position = \"dodge\", binwidth=200)\r\n\r\n\r\n\r\nMelhor? Não sei, depende das suas preferências.\r\nVamos tentar algo semelhante com as curvas de densidade. Em vez de “fill”, vamos usar a variável origin no parâmetro colour dentro de aes e separar as distribuições por cores de borda:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=dep_time, colour=origin))\r\n\r\n\r\n\r\nAgora sim está melhor. Vamos adicionar o mesmo com “fill”:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=dep_time, fill=origin))\r\n\r\n\r\n\r\nNão ficou muito bom. Mas pode melhorar. Com o parâmetro “alpha”, podemos deixar as distribuições mais “transparentes” e observar as áreas nas quais se sobrepõe:\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=dep_time, fill=origin), alpha=0.5)\r\n\r\n\r\n\r\nFinalmente, podemos usar “fill” e “colour” juntos na “aesthetics”\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=dep_time, colour=origin, fill=origin), alpha=0.5)\r\n\r\n\r\n\r\nQue belezura de gráfico! A comparação de distribuições de uma variável contínua por uma variável discreta é uma das mais úteis em ciência, pois é exatamente a forma gráfica dos testes de hipóteses clássico quando temos dois grupos.\r\nGráficos com uma variável contínua e uma variável discreta - Gráficos de boxplot\r\nVamos repetir o gráfico acima, mas, em vez de descrever a distribuição da variável contínua ao longo de eixo x em termos da sua densidade, vamos descrever ela ao longo do eixo y com um boxplot que resume as estatísticas importantes da distribuição. O boxplot mostra a mediana no meio da caixa, o primeiro e terceiro quartis nos limites da caixa, e \\(1.5*IQR\\) (IQR é a diferença entre o terceiro e primeiro quartil) além da caixa com as linhas (whiskers).\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_boxplot(aes(x=origin, y=dep_time))\r\n\r\n\r\n\r\nGráficos com um valor único por uma variável discreta - Gráficos de coluna\r\nOs gráficos de histograma, densidade e boxplot geram gráficos baseado na distribuição de múltiplas observações por categoria discreta. Quando temos apenas um valor único por categoria discreta, usamos um gráfico de coluna. Normalmente isso exige o uso de group_by e summarize para mudar o tamanho de nosso banco de dados e a unidade de análise para ter uma linha por grupo.\r\nSempre temos que pensar no tibble que estamos encaminhando para o ggplot. O tibble de flights é uma tabela de todos os voos e não será apropriado para mostrar um valor por aeroporto - temos milhares de observações por aeroporto! Então a preparação de dados tem que produzir um tibble apropriado antes da visualização:\r\n\r\n\r\nflights %>% group_by(origin) %>% \r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nflights %>% group_by(origin) %>% \r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T)) %>% \r\n  ggplot() +\r\n  geom_col(aes(x=origin, y=dep_delay_media))\r\n\r\n\r\n\r\n\r\nObserve que existe uma diferença sútil entre geom_col e geom_bar: geom_col mostra o valor para o eixo y baseado nos valores numa coluna no seu tibble; geom_bar gera os valores para o eixo y baseado no número de observações em cada grupo de seu tibble. (Então geom_bar é realmente um atalho para data %>% group_by(group) %>%\r\ntally() %>% ggplot() + geom_col(aes(x=group, y=n))).\r\nGráficos de duas variáveis contínuas\r\nAté agora trabalhamos com distribuições de uma única variável ou com a distribuição conjunta de uma variável contínua por outra discreta (em outras palavras, separando a distribuição de uma variável em várias a partir de uma variável categórica).\r\nVamos ver agora como relacionar graficamente duas variáveis contínuas. O padrão é usarmos a geometria de gráfico de dispersão, que apresenta cada par de informações como uma coordenada no espaço bidimensional. Vamos ver um exemplo com distance (eixo horizontal) e air_time (eixo vertical) usando a geometria geom_point:\r\n(Note: Caso o seu computador seja lento, você pode pegar uma amostra aleatória de ex. 1000 linhas do banco de dados flights com sample_n(1000) antes de rodar os gráficos abaixo.)\r\n\r\n\r\nflights %>% sample_n(1000) %>% \r\n  ggplot() + \r\n  geom_point(aes(x = distance, y = air_time))\r\n\r\n\r\n\r\nVocê consegue ler este gráfico? Cada ponto representa um voo, ou seja, posiciona no espaço o par (distance, air_time) daquele voo. Naturalmente, há uma certa tendência nos dados: os voos mais distantes duram mais tempo.\r\nPara personalizar o gráfico, podemos ajustar o cor dos pontos, o tamanho deles, e a forma deles:\r\n\r\n\r\nflights %>% sample_n(1000) %>% \r\n  ggplot() + \r\n  geom_point(aes(x = distance, y = air_time), size=0.1, color=\"blue\", shape=2)\r\n\r\n\r\n\r\nSempre temos que experimentar várias vezes para achar uma formatação apropriada. A forma (shape) é um número que corresponde aos códigos oficiais - pode ver a lista deles na segunda página do cheatsheet do ggplot2, por exemplo.\r\nUma geometria suplementar com duas variáveis contínuas resume a relação entre as duas variáveis com modelos lineares e não lineares. A geometria geom_smooth cumpre esse papel.\r\nPara utilizá-la, precisamos definir qual é o método (parâmetro “method”) de modelar os dados. O mais convencional é representar a relação entre as variáveis como reta: um ‘linear model’ que é representado por ‘lm’. Veja o exemplo (ignore o parâmetro “se” por enquanto):\r\n\r\n\r\nflights %>% sample_n(1000) %>% \r\n  ggplot() + \r\n  geom_point(aes(x = distance, y =air_time), size=0.1) +\r\n  geom_smooth(aes(x = distance, y = air_time), method = \"lm\", se = FALSE)\r\n\r\n\r\n\r\nLegal, não? Se retirarmos o parâmetro “se” (standard error), ou voltarmos seu valor para o padrão “TRUE”, obteremos também o intervalo de confiança (95%) da reta que inserimos. (Diminuimos o n aqui para tornar o intervalo de confiança em cinza mais visível).\r\n\r\n\r\nflights %>% sample_n(50) %>% \r\n  ggplot() + \r\n  geom_point(aes(x = distance, y = air_time), size=0.1) +\r\n  geom_smooth(aes(x = distance, y = air_time), method = \"lm\")\r\n\r\n\r\n\r\nA alternativa não linear para representar a tendência dos dados mais utilizada com essa geometria é o método “loess” (local weighted regression). Veja o resultado, que não varia muito aqui devido a tendência bem linear nos dados:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time), size=0.1) +\r\n  geom_smooth(aes(x = distance, y = air_time), method = \"loess\")\r\n\r\n\r\n\r\n\r\nExercício 2: Gráficos de duas Variáveis\r\nPrepare um gráfico de densidade mostrando a distribuição da hora de partida de voos entre EWR e BOS (Boston) por companhia aérea (carrier).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"EWR\" & dest==\"BOS\") %>%\r\n  ggplot() +\r\n  geom_density(aes(x=dep_time, group=carrier, colour=carrier))\r\n\r\n\r\nPrepare um gráfico de colunas/barras (geom_col) mostrando a duração média (air_time) de voos de cada companhia aérea.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(carrier) %>%\r\n  summarize(duracao_media=mean(air_time, na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_col(aes(x=carrier, y=duracao_media))\r\n\r\n\r\nPrepare um gráfico de pontos mostrando a relação entre o atraso na partida (dep_delay) e o atraso na chegada (arr_delay) para os voos de JFK a MIA (Miama).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"JFK\" & dest==\"MIA\") %>%\r\n  ggplot() +\r\n  geom_point(aes(x=dep_delay, y=arr_delay))\r\n\r\n\r\nPrepare um gráfico de pontos mostrando a relação entre a duração (air_time) média e o atraso média (dep_delay) de cada companhia aérea.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(carrier) %>%\r\n  summarize(dep_delay_media=mean(dep_delay, na.rm=T),\r\n            duracao_media=mean(air_time, na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_point(aes(x=duracao_media, y=dep_delay_media))\r\n\r\n\r\nAdicione uma linha de tendência/regressão linear no gráfico da questão 4.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(carrier) %>%\r\n  summarize(dep_delay_media=mean(dep_delay, na.rm=T),\r\n            duracao_media=mean(air_time, na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_point(aes(x=duracao_media, y=dep_delay_media)) +\r\n  geom_smooth(aes(x=duracao_media, y=dep_delay_media), method=\"lm\")\r\n\r\n\r\n\r\nGráficos de três ou mais variáveis\r\nEm geral, estamos limitados por papel e telas bidimensionais para exibir apenas geometrias de duas variáveis. Mas existe um truque que podemos usar para mostrar mais informações: incluir os outros parâmetros de uma geometria, tais como cores, tamanhos e formas, dentro de aes segundo uma terceira variável em seu tibble.\r\nSe, por exemplo, queremos representar uma terceira variável contínua, podemos colocá-la como o tamanho dos pontos (raio do círculo). Por exemplo, num gráfico comparando o dep_time e dep_delay dos voos, podemos definir o tamanho dos pontos proporcionalmente à distância de cada voo:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = dep_time, y = dep_delay, size=distance))\r\n\r\n\r\n\r\nSe, em vez de alterar o tamanho dos pontos por uma variável numérica, quisermos alterar sua cor ou a forma dos pontos com base em uma variável categórica (aeroporto de origem, por exemplo), fazemos, respectivamente:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = dep_time, y = dep_delay, colour=origin))\r\n\r\n\r\n\r\nOu:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = dep_time, y = dep_delay, shape=origin))\r\n\r\n\r\n\r\nMúltiplos Gráficos (facet_grid)\r\nExiste mais um jeito de mostrar mais de duas variáveis - podemos criar vários gráficos organizados em uma grade sem ter que repetir nosso código toda vez. Como fazer isso? Adicionando um ‘facet’ no final do nosso fluxo de preparação do gráfico. O mais útil é facet_grid(), que adicionamos como qualquer outra camada. Dentro de facet_grid() podemos definir a variável discreta com que queremos separar os nossos dados e mostrar gráficos distintos. Especificamente, se quisermos que a divisão seja horizontal baseado na coluna categórica variável, usamos facet_grid(rows=vars(variável)), e se quisermos que a divisão seja vertical, usamos facet_grid(cols=vars(variável)). (O vars() aqui permite que separamos os gráficos por mais que uma variável se necessário).\r\nVeja um exemplo:\r\n\r\n\r\nflights %>% sample_n(1000) %>% \r\n  ggplot() + \r\n  geom_point(aes(x = dep_time, y = dep_delay)) + \r\n  facet_grid(cols=vars(origin))\r\n\r\n\r\n\r\nOu, organizado verticalmente:\r\n\r\n\r\nflights %>% sample_n(1000) %>% \r\n  ggplot() + \r\n  geom_point(aes(x = dep_time, y = dep_delay)) + \r\n  facet_grid(rows=vars(origin))\r\n\r\n\r\n\r\nPara separar gráficos em uma grade, com uma variável horizontalmente e outra verticalmente, é só especificar ambos rows e cols.\r\n\r\n\r\nflights %>% sample_n(1000) %>% \r\n  ggplot() + \r\n  geom_point(aes(x = dep_time, y = dep_delay)) + \r\n  facet_grid(rows=vars(month), cols=vars(origin))\r\n\r\n\r\n\r\n\r\nO facet_grid() mostra todas as combinações das variáveis de facet horizontal e vertical, mesmo que algumas combinações não existam nos dados. Isto é equivalente a função complete() - o gráfico para a combinação ausente vai aparecer vazio. Para mostrar apenas as combinações que existem nos dados (e perder a estrutura de grade), existe a função alternativa facet_wrap().\r\nO que mostra este gráfico? Cada elemento é um aeroporto de origem em um mês, e mostra a relação entre horário de partida e atraso neste mês e aeroporto.\r\nGráficos de Linha\r\nGráficos de linha exigem, em geral, um pouco mais de preparação de nossos dados. A variável x pode ser discreta ou contínua, mas precisa ser ordenada para que as linhas façam sentido. Precisamos organizar o tibble fora do ggplot e colocá-lo antes no pipe.\r\nPara criar um gráfico de linha vamos usar month (mês) como nossa variável ordenada e, portanto, precisamos resumir os dados por month. Vamos analisar o atraso média por mês. O primeiro passo é transformar a variável month em um factor ordenado. Em seguida, vamos calcular o atraso médio por mês.\r\nVeja a tabela que queremos produzir antes de visualizar:\r\n\r\n\r\nflights %>% \r\n  mutate(month=factor(month, levels=1:12, ordered=TRUE)) %>%\r\n  group_by(month) %>%\r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T))\r\n\r\n\r\n\r\n\r\n\r\n\r\nE agora que temos os nossos dados na estrutura apropriada, com a unidade de análise o mês e a variável de atraso médio disponível, podemos encaminhar os dados ao gráfico de linha, geom_line. geom_line exige um x, um y, e um group, este último para definir como juntar os pontos ao longo do tempo - neste exemplo temos apenas um grupo/uma linha então podemos deixar group=1.\r\n\r\n\r\nflights %>% \r\n  mutate(month=factor(month, levels=1:12, ordered=TRUE)) %>%\r\n  group_by(month) %>%\r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_line(aes(x=month, y=dep_delay_media), group=1)\r\n\r\n\r\n\r\nO que podemos fazer se quisermos uma linha separada para cada aeroporto de origem? Como sempre, primeiramente temos que preparar os dados na forma apropriada, agrupando por origin também no resumo de dados, e depois definir group=origin dentro de geom_line (e dentro de aes).\r\n\r\n\r\nflights %>% \r\n  mutate(month=factor(month, levels=1:12, ordered=TRUE)) %>%\r\n  group_by(month, origin) %>%\r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_line(aes(x=month, y=dep_delay_media, group=origin))\r\n\r\n\r\n\r\nNão temos jeito de distinguir as linhas aqui então é necessário também definir o colour da linha:\r\n\r\n\r\nflights %>% \r\n  mutate(month=factor(month, levels=1:12, ordered=TRUE)) %>%\r\n  group_by(month, origin) %>%\r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_line(aes(x=month, y=dep_delay_media, group=origin, colour=origin))\r\n\r\n\r\n\r\nPerfeito!\r\nOs gráficos de linha podem ser um pouco confusos no começo, então é legal ver como fica a estrutura da tabela que é criada antes do gráfico. Você imaginou como é a tabela do último gráfico?\r\n\r\n\r\nflights %>% \r\n  mutate(month=factor(month, levels=1:12, ordered=TRUE)) %>%\r\n  group_by(month, origin) %>%\r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T))\r\n\r\n\r\n\r\n\r\n\r\n\r\nGráficos de barras 100%\r\nPodemos aproveitar o mesmo tipo de estrutura da tabela que criamos para o gráfico de linhas para criar gráficos de barras 100%. Esse tipo de gráfico é útil para entender a participação de cada grupo no total. Por exemplo, vamos calcular a contribuição de cada aeroporto ao atraso total em cada mês. Depois, é só trocar geom_line para geom_col e ajustar as estéticas apropriadas. Especificamente, geom_col permite o argumento position (que já usamos com geom_histogram acima) para comparar as barras relativamente, em porcentagens, quando position=\"fill\":\r\n\r\n\r\n flights %>% \r\n   mutate(month=factor(month, levels=1:12, ordered=TRUE)) %>%\r\n   group_by(month, origin) %>%\r\n   summarize(dep_delay_total=sum(dep_delay,na.rm=T)) %>%\r\n   ggplot() +\r\n   geom_col(aes(x=month, y=dep_delay_total, fill=origin), position = \"fill\")\r\n\r\n\r\n\r\nMais geometrias\r\nExiste uma variedade de geometrias que podemos usar como camadas para visualizar os nossos dados.\r\nUma geometria muito útil é geom_text, que coloca como formas geométricas os textos mesmos. Por exemplo, nós podemos especificar um gráfico de dispersão onde os pontos refletem o nome do destino do voo, usando o parâmetro ‘label’.\r\n\r\n\r\nflights %>% sample_n(100) %>% \r\n  ggplot() + \r\n  geom_text(aes(x = dep_time, y = dep_delay, label=dest))\r\n\r\n\r\n\r\nOutra geometria útil é geom_tile que tem uma forte conexão com mapas “raster” que discutiremos mais adiante no curso. Especificamos variáveis x e y, e também uma variável de ‘fill’ que se aplica a cada célula de interseção de x e y. Por exemplo, podemos avaliar o atraso médio por aeroporto e mês.\r\n\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T)) %>% \r\n  ggplot() + \r\n  geom_tile(aes(x = origin, y = month, fill=dep_delay_media))\r\n\r\n\r\n\r\nEvite voar de JFK em julho!\r\nFinalmente, vamos ver como gerar um gráfico de pizza. A primeira observação é que um gráfico de pizza contém os mesmos dados que um gráfico de barras 100% (de porcentagem). Então a primeira tarefa é gerar a tabela apropriada para este tipo de gráfico. Precisamos de um geom_col, com position=\"fill\" para garantir que os valores somam 100%, e vamos deixar a estética x em branco porque queremos apenas uma barra.\r\n\r\n\r\nflights %>% group_by(origin) %>%\r\n  summarize(dep_delay_total=sum(dep_delay, na.rm=T)) %>%\r\n  ggplot() + \r\n  geom_col(aes(x=\"\", y=dep_delay_total, fill=origin), position=\"fill\")\r\n\r\n\r\n\r\nVeja o resultado. Com um pouco de imaginação, podemos interpretar esse resultado como um gráfico de pizza, onde cada ‘fatia’ colorida da barra equivale a uma ‘fatia’ de pizza. Para transformar o nosso gráfico em um círculo, precisamos entender mais um elemento da gramática de gráficos. Além de geometrias e estéticas, existem sistemas de coordenados. Normalmente, eles são invisíveis e não precisamos especificar nada porque as coordenadas são óbvias - uma grade definida horizontalmente por x e verticalmente por y, como usamos em todos os outros gráficos do tutorial atual. Mas existem outros sistemas de coordenadas, por exemplo o sistema de coordenadas ‘polares’, que divide a tela/papel em graus de um círculo. Se definirmos um sistema de coordenadas polares adicionando mais uma camada coord_polar(), e definimos o ángulo theta de cada fatia baseado na variável y (dep_delay), com coord_polar(theta=\"y\"), geramos um gráfico de pizza:\r\n\r\n\r\nflights %>% group_by(origin) %>%\r\n  summarize(dep_delay_total=sum(dep_delay, na.rm=T)) %>%\r\n  ggplot() + \r\n  geom_col(aes(x=\"\", y=dep_delay_total, fill=origin), position=\"fill\") +\r\n  coord_polar(theta=\"y\")\r\n\r\n\r\n\r\nMais uma linha e recebemos um gráfico completamente diferente visualmente, mas apresentando os mesmos dados.\r\nControlando cores com ‘scales’\r\nas partes mais envolventes dos gráficos são as cores. Mas também são as partes mais complexas. Temos que identificar exatamente qual parte do gráfico deve ser representado com qual cor, e especificar isso em termos sistemáticos. O mapeamento entre valores das nossas variáveis e cores específicas é feito em ggplot por scales (escalas). Scales são definidos em mais uma camada do nosso gráfico.\r\nPrecisamos tomar muito cuidado com o tipo de scale, que precisa corresponder ao tipo da nossa variável e também se estamos colorindo um ponto/linha (‘colour’) ou preenchendo uma área (‘fill’). Sempre use a tabela abaixo como guia:\r\nTipo de variável\r\nColor (ponto, linha)\r\nFill (área)\r\nContínuo\r\nscale_color_gradient(low=\"cor1\",high=\"cor2\")\r\nscale_fill_gradient(low=\"cor1\",high=\"cor2\")\r\nDiscreto\r\nscale_color_brewer(palette=\"pre-definido\")\r\nscale_fill_brewer(palette=\"pre-definido\")\r\nUm pouco complexo, sim, mas capaz de fornecer muita flexibilidade. Quais são as cores cor1 e cor2 nos exemplos acima? Podemos usar vários sistemas de referência de cores: nomes (‘blue’), rgb (3, 78, 252), hex (#034efc) etc. Todos funcionam.\r\nO problema é que não somos designers, e temos a tendência de escolher cores feias (eu escolho pelo menos…). É melhor consultar a guia no site Color Brewer e copiar-colar os códigos das cores desejadas.\r\nVamos para um exemplo. Primeiro, de uma variável contínua (dep_time) e uma estética de colour (de pontos). Lembre-se que os pontos ainda exigem uma posição então também precisamos definir o x e y. As cores padrão do ggplot aparecem assim:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=dep_time))\r\n\r\n\r\n\r\nVamos adicionar uma escala personalizada agora, usando cores de uma escala verde de Color Brewer:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=dep_time)) +\r\n  scale_color_gradient(low=\"#f7fcfd\", high=\"#238b45\")\r\n\r\n\r\n\r\nEntre as duas cores extremas, o R preenche uma escala contínua automaticamente. Bonito e simples!\r\nCom variáveis discretas, é mais difícil porque temos que especificar uma cor distinta para cada categoria possível. Uma alternativa é aproveitar uma ‘paleta’ pré-definida por especialistas. Por exemplo, para definir cores dos pontos para cada aeroporto podemos usar a paleta ‘Set2’ (encontrada na opção ‘qualitative’ de Color Brewer):\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  scale_color_brewer(palette=\"Set2\")\r\n\r\n\r\n\r\nTemos mais duas possibilidades para completar a tabela de escalas. Agora, com uma variável contínua e o parâmetro fill para colorir uma área:\r\n\r\n\r\nflights %>% group_by(origin, month) %>% \r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T)) %>% \r\n  ggplot() + \r\n  geom_tile(aes(x = origin, y = month, fill=dep_delay_media)) +\r\n  scale_fill_gradient(low=\"#f7fcfd\", high=\"#238b45\")\r\n\r\n\r\n\r\nFinalmente, vamos construir um exemplo com uma variável discreta (a companhia dominante em cada mês e aeroporto de origem) e o preenchimento de área:\r\n\r\n\r\nflights %>% group_by(origin, month, carrier) %>% \r\n  tally() %>% \r\n  group_by(origin, month) %>%\r\n  filter(n==max(n)) %>% \r\n  ggplot() + \r\n  geom_tile(aes(x = origin, y = month, fill=carrier)) +\r\n  scale_fill_brewer(palette=\"Set2\")\r\n\r\n\r\n\r\nPersonalização de Gráficos além de geometria\r\nFinalmente, podemos alterar diversos aspectos do nosso gráfico não relacionados aos dados, geometria ou estéticas. O procedimento para adicionar alterações em título, eixos, legenda, etc, é o mesmo que adicionando novas geometrias/camadas.\r\nEm primeiro lugar, vamos adicionar um título ao gráfico:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de voo, por aeroporto de Nova Iórque\")\r\n\r\n\r\n\r\nA seguir, vamos modificar os nomes dos rótulos dos eixos, com xlab() e ylab(). Por padrão o R utiliza os nomes das variáveis, mas obviamente isso nem sempre é claro ou apropriado para o gráfico final:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de voo, por aeroporto de Nova Iórque\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\")\r\n\r\n\r\n\r\nO posicionamento da legenda pode ser modificado:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de voo, por aeroporto do Nova Iorque\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\") + \r\n  theme(legend.position=\"bottom\")\r\n\r\n\r\n\r\nO nome da legenda precisa ser especificada na camada da escala de cores:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de voo, por aeroporto do Nova Iorque\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\") + \r\n  theme(legend.position=\"bottom\") +\r\n  scale_color_brewer(palette=\"Set2\", name=\"Aeroporto\")\r\n\r\n\r\n\r\nCom esforço, literalmente todos os elementos podem ser modificados, por exemplo o tamanho do texto nos eixos:\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de voo, por aeroporto do Nova Iorque\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\") +\r\n    theme(axis.text.x = element_text(size=4),\r\n          axis.text.y = element_text(size=4),\r\n          axis.title.x = element_text(size=4),\r\n          axis.title.y = element_text(size=4))\r\n\r\n\r\n\r\nO ggplot nos permite modificar basicamente todos os elementos de estilo do nosso gráfico mas, às vezes, são muitos detalhes. Para alterar o estilo do nosso gráfico, é mais fácil usar um tema (theme) pré-definido. Por exemplo, podemos usar theme_classic() para tirar o preenchimento e a grade do fundo.\r\n\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de voo, por aeroporto do Nova Iorque\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\") +\r\n  theme_classic()\r\n\r\n\r\n\r\nOs temas também podem ser usados para replicar estilos de outras fontes profissionais através, por exemplo, do pacote ggthemes. Abaixo criamos um gráfico usando o estilo da revista “The Economist” em uma linha única de código.\r\n\r\n\r\n# install.packages(\"ggthemes\")\r\nlibrary(ggthemes)\r\n\r\nflights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de voo, por aeroporto do Nova Iorque\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\") +\r\n  theme_economist()\r\n\r\n\r\n\r\n\r\nHabilidade Básica de Programação: Salvando Gráficos\r\nO fluxo de trabalho normal é que o nosso gráfico aparece no relatório final no lugar em que digitamos o código no script. Não precisamos salvar o nosso gráfico separadamente. Mas caso você queira salvar o seu gráfico como um arquivo de imagem, você pode usar o ggsave() que salva o último gráfico apresentado em R. O tipo de imagem é definido com a extensão do arquivo (.png, .jpg, .pdf etc.).\r\n\r\n\r\nflights %>% ggplot() +\r\n  geom_bar(aes(x=origin))\r\n\r\nggsave(\"flights_barplot.png\")\r\n\r\n\r\nO arquivo ‘flights_barplot.png’ será salvo na pasta do seu projeto atual.\r\n\r\nGráficos interativos e animações\r\nSe você estiver trabalhando com um relatório em HTML para um site online (e não um PDF), talvez queira tornar seu gráfico interativo para que os usuários possam explorar cada ponto de dados. Isso é fácil com o pacote plotly e o comando ggplotly. Gravamos nosso gráfico na mesma sintaxe de ggplot como um objeto e, em seguida, usamos ggplotly.\r\n\r\n\r\n#install.packages(\"plotly\")\r\nlibrary(plotly)\r\n\r\ngraf_1 <- flights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin)) +\r\n  ggtitle(\"Relação entre distância e duração de cada voo, por aeroporto do Nova Iorque em 2013\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\") +\r\n  theme_classic() \r\n\r\ngraf_1 %>%\r\n  ggplotly()\r\n\r\n\r\n\r\nExplore o gráfico acima com cursor.\r\nEste pacote também ajuda a transformar gráficos em animações. Podemos usar o mesmo fluxo de trabalho acima, e só precisamos especificar o parâmetro ‘frame’ na geometria para a variável que define cada momento em tempo da animação. Para ilustrar, vamos analisar o mesmo gráfico com uma animação por mês. Toque ‘play’ no gráfico produzido pelo código abaixo para ver a animação. Isto apenas funciona em relatórios de HTML.\r\n\r\n\r\ngraf_2 <- flights %>% sample_n(1000) %>% ggplot() + \r\n  geom_point(aes(x = distance, y = air_time, color=origin, frame=month)) +\r\n  ggtitle(\"Relação entre distância e duração de cada voo, por aeroporto do Nova Iorque em 2013\") +\r\n  xlab(\"Distância\") +\r\n  ylab(\"Duração\") +\r\n  theme_classic() \r\n\r\ngraf_2 %>%\r\n  ggplotly()\r\n\r\n\r\n\r\nEnfim, existem infinitas personalizações possíveis. Ninguém consegue lembrar todos os detalhes ou o código. É frequentemente necessário buscar online por ajuda ou ideias, porém pesquisar por ‘gráfico bonito’ não ajuda nada. Temos que usar a linguagem e a gramática de gráficos para encontrar o que estamos procurando, então é crucial entender o que significa uma geometria, uma estética, uma escala, etc.\r\nEm caso de dúvida, pode consultar o cheatsheet aqui. Um outro ponto de referência é a lista de tipos de gráficos com exemplos aqui.\r\n\r\n\r\nExercício 3: Gráficos Avançados\r\nComeçando com o mesmo gráfico de Exercício 2.3, prepare o gráfico de pontos mostrando a relação entre o atraso na partida (dep_delay) e o atraso na chegada (arr_delay) para os voos de JFK a MIA (Miami). Colora os pontos de acordo com a companhia aérea, e adicione títulos bem formatados nos eixos e para o gráfico inteiro.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"JFK\" & dest==\"MIA\") %>%\r\n  ggplot() +\r\n  geom_point(aes(x=dep_delay, y=arr_delay, colour=carrier)) +\r\n  ggtitle(\"Atrasos nos voos de JFK para Miama\") +\r\n  xlab(\"Atraso na partida\") +\r\n  ylab(\"Atraso na chegada\")\r\n\r\n\r\nAjuste o seu gráfico de questão 1 para que o cor do ponto reflete uma variável contínua, a hora de partida (dep_time), usando uma escala de cores apropriada.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"JFK\" & dest==\"MIA\") %>%\r\n  ggplot() +\r\n  geom_point(aes(x=dep_delay, y=arr_delay, colour=dep_time)) +\r\n  scale_colour_gradient(low=\"#efedf5\", high=\"#4a1486\", name=\"Horário\") +\r\n  ggtitle(\"Atrasos nos voos de JFK para Miama\") +\r\n  xlab(\"Atraso na partida\") +\r\n  ylab(\"Atraso na chegada\")\r\n\r\n\r\nPrepare um gráfico de linhas mostrando a distância total de viagem de todos os voos por mês, com uma linha para cada aeroporto de origem. Aplique uma escala de cores apropriada.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% mutate(month=factor(month, 1:12, ordered=TRUE)) %>% \r\n  group_by(month, origin) %>%\r\n  summarize(distancia_total=sum(distance, na.rm=T)) %>% \r\n  ggplot() + \r\n  geom_line(aes(x=month, y=distancia_total, group=origin, colour=origin)) +\r\n  scale_colour_brewer(palette=\"Set2\", name=\"Aeroporto\")\r\n\r\n\r\nPrepare vários gráficos de linha numa grade, cada um mostrando a relação entre a hora de partida (hour) e o atraso médio de partida em um aeroporto de origem para uma companhia aérea.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(hour, origin, carrier) %>%\r\n  summarize(dep_delay_media=mean(dep_delay,na.rm=T)) %>%\r\n  ggplot() + \r\n  geom_line(aes(x=hour, y=dep_delay_media)) +\r\n  facet_grid(rows=vars(carrier), cols=vars(origin))\r\n\r\n\r\n\r\n\r\n\r\nLeitura para Tutorial 7\r\nAntes da próxima aula, por favor leia R 4 Data Science, Capítulo 13\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:15:40-03:00"
    },
    {
      "path": "index.html",
      "title": "Análise de Dados, Programação e Visualização para as Ciências Sociais",
      "description": "Departamento de Ciência Política, Universidade de São Paulo\n",
      "author": [],
      "contents": "\r\n\r\nJonathan Phillips\r\nRafael N. Magalhães\r\n\r\nComo passamos de um banco de dados bruto para um relatório ou artigo publicável com estatísticas precisas,\r\ntabelas claras e gráficos convincentes? Existem diversas ferramentas poderosas para facilitar o processo de\r\nanálise de dados, pesquisa e publicação, mas elas podem parecer intimidadoras e complexas. Este curso\r\noferece aos estudantes de pós-graduação em ciências sociais uma iniciação acessível ao uso de software para coleta, limpeza, análise, comparação e visualização de dados.\r\nO foco do curso é o desenvolvimento da habilidade de programação para solução de problemas diversos\r\nrelacionados ao manejo de dados com fins de pesquisa. Note que este não é um curso de metodologia de\r\npesquisa ou estatística. No final do curso os alunos serão capazes de desenvolver um script para baixar e organizar os dados, calcular medidas relevantes, construir tabelas, gráficos e mapas, e gerar um relatório final para uso na sua dissertação/tese, tudo de forma verificável, reproduzível, transparente e documentada.\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:16:06-03:00"
    },
    {
      "path": "Introducao.html",
      "title": "Introdução",
      "description": "Gerar análises rápidas e ganhar confiança\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nPrincípios Cruciais na Análise de Dados\r\nMinha primeira análise\r\nFormatação de Texto em R Markdown\r\nModo Interativo vs. Modo Script\r\nData Frames como a Unidade Básica de Ciência de Dados\r\n\r\nPrincípios Cruciais na Análise de Dados\r\nEste curso é uma introdução a análise de dados, sobretudo para fins de pesquisa nas Ciências Sociais. No fluxo de trabalho mais comum, por exemplo na preparação de um relatório, tese, disertação ou artigo, queremos abrir um banco de dados, limpar e processar os dados, calcular estatísticas, produzir tabelas, gráficos, mapas, ou descrições, e apresentar os resultados num documento final. Através de tutoriais temáticos na linguagem de R, o curso orienta você em cada uma dessas tarefas.\r\nEm cada étapa da análise, salientamos os seguintes princípios que ajudam manter a integridade e confiabilidade da nossa análise:\r\nTransparência - Tudo a análise pode ser inspecionado para rastrear os origens de cada resultado e identificar erros\r\nSimplicidade - Digitamos o código de forma mais simples e claro possível para que fica fácil ler e corrigir\r\nReprodutibilidade - Os bancos de dados brutos e o script de análise podem ser compartilhados com uma colega que consegue executa a análise e produzir o resultado idêntico\r\nEntender os seus dados - A análise deve nos ajudar entender - e não esconder - o conteúdo dos nossos dados\r\nMinha primeira análise\r\nProgramação e análise de dados não acontecem como mostrado nos filmes. Em vez de digitar furiosamente comandos na hora, preparamos um ‘script’ com calma de antemão e só temos que ‘executar’ o nosso script quando tudo está pronto para gerar o nosso produto final.\r\nEm contraste com outras disciplinas, o nosso objetivo geralmente não é apenas executar algum código, mas produzir uma tabela, um gráfico, um relatório, um documento ou um site online. Se separarmos a nossa análise de dados do documento final, temos que copiar e colar as estatísticas, tabelas e gráficos. Nesse processo de copiar e colar sempre fazemos algo errado, ou esquecemos de atualizar alguns números e não outros, ou não podemos rastrear a origem de uma análíse quando queremos ajustá-la. Melhor juntar tudo e integrar a análise de dados com o(s) produto(s) final(is).\r\nComo podemos comunicar a nossa análise de forma profissional, integrada, documentada e reproduzível? Vamos usar o R Markdown: um tipo de script (arquivo) compatível com o RStudio e uma linguagem bem fácil e flexível para formatar documentos.\r\nAntes de criar o nosso script de R Markdown, vamos criar uma pasta no HD da máquina. Para deixar que a análise fique mais fácil no futuro todos os nossos documentos vão ficar nessa pasta. Ela é um ‘Projeto’ de RStudio e nela guardamos todos os nossos arquivos relevantes:\r\nDados brutos de fontes externas;\r\nScripts de análise;\r\nOutputs - relatórios, gráficos etc.\r\nCriamos o nosso projeto/pasta dentro do RStudio: Clique File -> New Project. Depois, “New Directory’ -> New Project e especifique o nome e a localização preferida para a pasta. Quando esse passo a passo é finalizado, a única coisa que muda no RStudio é que a aba/janela ‘Files’ mostra todos os arquivos em nossa pasta.\r\nAinda temos que gerar o nosso primeiro script de R Markdown: Clique File -> New File -> R Markdown. Escolha ‘documento’ nas opções à esquerda, digite um título e autor, e escolha o formato HTML para o produto (output) final (podemos mudar o formato depois se necessário). Salve o novo script na pasta do seu projeto (que deve abrir como opção padrão (default)).\r\nAo abrir o arquivo de RMarkdown haverá um conteúdo padrão como exemplo; pode apagar tudo exceto o cabeçalho/‘header’, que parece assim:\r\n\r\n---\r\ntitle: \"Exemplo\"\r\nauthor: \"Jonathan\"\r\ndate: \"26 de março 2022\"\r\noutput: html_document\r\n---\r\n\r\nFique à vontade alterar o título, autor e data como quiser. Depois do cabeçalho, você pode escrever qualquer coisa em texto normal que vai aparecer no documento final. É como trabalhar em Microsoft Word ou outro editor de texto. Para entender como funciona, escreva numa frase curta o seu motivo para cursar esta disciplina.\r\nAgora temos o nosso primeiro script, e queremos ‘compilar’ ou ‘executar’ o script para gerar o produto final. Em R isso se chama ‘Knit’ e aparece como um ícone azul acima do seu script. Clique em ‘Knit’ e o RStudio vai abrir um documento de formato HTML numa janela separada.\r\nParabéns! Você já produziu a sua primeira análise! Onde ela fica salva? Procure o documento com extensão HTML na mesma pasta do seu script, a pasta do projeto. Simples, não? Logo, vamos ver como a produzir outros formatos de documentos finais (eg. Word, PDF).\r\nPrimeira Programação\r\nAté agora o nosso documento é muito simples e não incorpora nenhuma análise técnica ou de programação. A melhor característica do R Markdown é que podemos juntar texto simples e programação no mesmo script. Apesar disso, existe uma separação forte e clara entre os dois: deixamos códigos de programação em lugares específicos e demarcados dentro do script - estes lugares se chamam ‘chunks’. Para inserir um chunk, clique no icone verde com um ‘C’ acima do seu script e em seguida ‘R’. No local do seu mouse vai aparecer uma caixa com fundo cinza onde podemos digitar o nosso código de programação:\r\n```{r}\r\n\r\n```\r\n(No futuro, pode ser mais rápido criar um chunk com Ctrl+Alt+i).\r\nO que inserimos aqui dentro? Em breve, centenas de linhas de código! Tudo que você escrever aqui será processado pela máquina do R e o resultado inserido no documento final.\r\nO R funciona como calculadora, então podemos digitar alguns cálculos dentro do chunk e ver os resultados no documento final:\r\n```{r}\r\n86*74\r\n```\r\n\r\n[1] 6364\r\n\r\nO R também permite o armazenamento de valores como ‘objetos’, descritos por um nome. No início do seu cálculo, digite um nome do seu objeto desejado, seguido por uma seta à esquerda ‘<-’, composta por ‘<’ e ‘-’, que significa atribuir o resultado do cálculo a direita ao objeto com nome na esquerda. O objeto calculo fica disponível para o restante do seu script, em todas as linhas e chunks abaixo. A lista de objetos disponíveis no seu ambiente fica na aba ‘Environment’ do RStudio.\r\n```{r}\r\ncalculo <- 86*74\r\n\r\ncalculo/4\r\n```\r\n\r\n[1] 1591\r\n\r\n\r\nHabilidade Básica de Programação: Atribuição, ‘<-’\r\nGuardamos dados/resultados para o futuro em objetos do R. A lista de objetos disponíveis fica na aba de ‘Environment’ do RStudio, e será limpa toda vez que fechamos o R, ou propositalmente limpamos o ‘Environment’. Para criar objetos, temos que atribuir o resultado de uma função/cálculo a um nome único.\r\nA flecha de atribuição, composto pelos dois símbolos ‘<’ e ‘-’ conecta o nome de objeto e o conteúdo para salvar dentro:\r\n\r\n\r\nnome_objeto <- 15*72\r\n\r\n\r\n\r\nQue ótimo! Já produzimos o nosso primeiro script de programação! Se compilarmos o script com ‘Knit’, você verá o documento final com o seu texto simples, o código e o resultado da execução do código.\r\nVamos tentar mais uma análise. Por exemplo, calculamos a área de um círculo de raio 20 com o chunk abaixo, usando a constante pi (que o R já tem salvo como objeto na memória):\r\n```{r}\r\nraio <- 20\r\narea <- pi * raio^2\r\n\r\narea\r\n```\r\n\r\n[1] 1256.637\r\n\r\nNote que temos que escrever o nome do objeto para que o resultado apareça no documento final. Se não, ele fica apenas salvo no objeto ‘area’ para uso no futuro e seu valor não aparece no nosso documento final de RMarkdown.\r\nComo um resumo, existem dois lugares em nosso script, e temos que lembrar qual tipo de conteúdo fica em cada um:\r\nDigite no corpo (fundo branco)\r\nDigite num ‘chunk’ (fundo cinza)\r\nTexto explicativo\r\nCódigo de R\r\nTítulos\r\nTabelas criadas com código de R\r\nEquações (na sintaxe do Latex)\r\nGráficos criadas com código de R\r\nFormatação de Texto em R Markdown\r\nComo tornamos o nosso texto mais interessante e organizado? Em contraste com o Microsoft Word, formatar textos em R Markdown não depende de clicar em botões - precisamos incluir caracteres/símbolos no script para indicar a formatação que queremos. Por exemplo, usamos um asterisco (’*’) antes e depois de uma palavra/frase que queremos destacar em itálicos.\r\n\r\n\r\n*Itálico*\r\n**Bold**\r\n# Cabeçalho de seção\r\n\r\n## Sub-cabeçalho\r\n`\r\n### Sub-Sub-cabeçalho\r\n[link](http://www.google.com)\r\n* Bullets[quatro espaços]    * Sub-Bullets\r\n1. Lista numerada[quatro espaços]    1. Sub-Lista numerada\r\n\r\n\r\nItálico\r\nBold\r\nCabeçalho de seção\r\nSub-cabeçalho\r\nSub-Sub-cabeçalho\r\nlink\r\nBullets\r\nSub-Bullets\r\n\r\nLista numerada\r\nSub-lista numerada\r\n\r\n\r\n\r\nPratique incluindo alguns cabeçalhos e formatações no seu documento, e compile com ‘Knit’ para verificar o resultado. Para mais detalhes veja O Cheatsheet do Rmarkdown.\r\nEquações\r\nPodemos escrever equações com a linguagem de Latex (que vamos aprender logo no futuro). Se quiser inserir uma equação dentro de uma frase (na mesma linha), use $equacao$, e para centralizar numa nova linha use $$equacao grande$$. A sintaxe é assim:\r\n$$\\alpha^2 + \\beta^2 = \\chi^2$$ \\[\\alpha^2 + \\beta^2 = \\chi^2\\]$$\\frac{\\sqrt{1}}{2} * \\frac{a}{2b} = \\frac{a}{4b}$$ \\[\\frac{\\sqrt{1}}{2} * \\frac{a}{2b} = \\frac{a}{4b}\\]\r\n$$\\sum_0^{10} x = ...$$ \\[\\sum_0^{10} x = ...\\]\r\nMais detalhes aqui.\r\n‘Código em linha’: Incluindo resultados do código dentro do texto\r\nAté agora, o nosso script tem dois componentes distintos: texto simples e chunks de código que geram resultados separados no documento final. Às vezes queremos integrar o código ao texto, para fazer referência ao resultado da nossa análise dentro do próprio texto/frase. Por exemplo, podemos querer inserir uma média ou o número de observações do nosso banco de dados dentro de uma frase na sua tese, não de forma manual ou de memória, mas como um valor exato, atualizado e calculado pelo nosso script.\r\nComo incluímos o resultado numérico area do cálculo acima dentro de uma frase em nosso texto (fora do chunk de código)? Podemos usar ‘código em linha’ (‘in-line code’) para exibir um valor simples no documento final. O formato é como o exemplo abaixo, usando o acento grave para começar e terminar, a letra r para mostrar que queremos um cálculo do R, e o nome do objeto que queremos inserir. Você se lembra que já criamos o objeto area acima com o resultado do cálculo da área do círculo? O resultado deve estar ainda disponível se o chunk fica acima.\r\n```{r}\r\nraio <- 20\r\narea <- pi * raio^2\r\n```\r\nA área de um círculo de raio 20 é `r area`.\r\nE o resultado:\r\nA área de um círculo de raio 20 é 1256.6370614.\r\nO resultado é totalmente integrada na frase para que ninguém saberá que você não fez o cálculo manualmente! Tente ‘Knit’ o seu documento de novo.\r\nModo Interativo vs. Modo Script\r\nAté agora, trabalhamos com scripts, arquivos .Rmd, e esse é o melhor jeito de organizar as nossas análises e deixá-las prontas e reproduzíveis para um outro pesquisador (ou você mesmo) no futuro.\r\nPorém, é bem difícil pensar no processamento de dados do início até o final sem interrogar os dados em cada passo do processo. Queremos verificar se cada linha de código gera o resultado esperado conforme vamos programando, e não apenas no documento final. Felizmente, o R nos permite trabalhar no modo interativo enquanto preparamos o nosso script. A ideia é que executamos o nosso código linha por linha, e avaliamos o resultado de cada linha para confirmar que o resultado faz sentido.\r\nIsso é indispensável, por exemplo, quando enfrentamos um erro na compilação do nosso script e precisamos diagnosticar o problema.\r\nHá dois jeitos de rodar uma linha de código no modo interativo:\r\n1. Digite o seu código diretamente na janela/aba de ‘Console’ do RStudio, e Enter para executar;\r\n2. Selecione a(s) linha(s) de código dentro do seu script (na verdade apenas precisa deixar o cursor na linha relevante) e toque ‘Run’ em R (botão acima do seu script, do lado direito) ou digite Ctrl+Enter.\r\nNa prática, a nossa recomendação é usar opção (2) quando precisa rodar uma linha de código que já existe no seu script, e opção (1) apenas quando precisa rodar temporariamente uma linha nova, por exemplo para ajudar a inspecionar um objeto.\r\nExperimente rodando o código abaixo em modo interativo:\r\n\r\n\r\nraio <- 20\r\narea <- pi * raio^2\r\n\r\narea\r\n\r\n\r\nO resultado é impresso na aba/janela de Console, e se usei opção (2), também abaixo do chunk que contém o código. Note que a execução do código por qualquer método gerou o objeto area na janela/aba de ‘Environment’ do RStudio. O Environment armazena todos os objetos que estão disponíveis em modo interativo.\r\nVamos descrobrir que a ordem de execução de linhas de código é absolutamente crucial para o resultado final. Em modo interativo sempre existe um risco de executar os códigos na ordem errada. É por isso que o modo de script é mais robusto e deixa a ordem da análise clara - ordem da sequência das linhas do script. Se você ficar confuso com quais operações já foram executadas, recomendamos limpar o seu Environment no RStudio clicando na imagem da vassoura na aba de Environment, e comece de novo desde o início.\r\nData Frames como a Unidade Básica de Ciência de Dados\r\nUma característica distintiva da linguagem de programação R é ter sido desenvolvida para a análise de dados. E quando pensamos em análise de dados, a protagonista do show é a base de dados ou, como conhecida na programação, data frame.\r\nPor esta razão, em vez de aprender como fazer aritmética, elaborar funções ou executar loops para repetir tarefas e outros aspectos básicos da linguagem, vamos começar olhando para o R como um software concorrente dos demais utilizados para análise de dados em ciências sociais, como SPSS, Stata, SAS, Python e companhia.\r\nAs principais características de um data frame são:\r\nCada coluna representa uma variável (ou característica) de um conjunto de observações;\r\nCada linha representa uma observação e contém os valores de cada variável para tal observação. Vejamos um exemplo:\r\nCandidato\r\nPartido\r\nVotos\r\nBeatriz\r\nPMDB\r\n350\r\nDanilo\r\nPSOL\r\n1598\r\nPedro\r\nPTB\r\n784\r\nDavi\r\nPSD\r\n580\r\nMateus\r\nPV\r\n2\r\nNote que em uma linha os elementos são de tipos diferentes: na primeira coluna há uma nome (texto), na segunda uma sigla de partido (texto, mas limitado a um conjunto de siglas) e na terceira votos (números inteiros).\r\nPor outro lado, em cada coluna há somente elementos de um tipo. Por exemplo, há apenas números inteiros na coluna votos. Colunas são variáveis e por isso aceitam registros de um único tipo, não podemos mesclar informações de tipos diferentes em uma mesma coluna (como texto e data).\r\nSe destacamos uma coluna do nosso data frame, temos um vetor. Por exemplo, a variável “Votos” pode ser apresentada da seguinte maneira: {350, 1598, 784, 580, 2}. Um data frame é um conjunto de variáveis (vetores) dispostos na vertical e combinados um ao lado do outro.\r\nData frame e vetores são objetos na linguagem R.\r\nVamos ver como o R representa vetores e data frames na tela. Antes disso, é preciso ‘abrir’ um data frame.\r\nPacotes para Mais Poder\r\nUma das características mais atrativas da linguagem R é o desenvolvimento de pacotes pela comunidade de usuários. Pacotes são conjuntos de funções (isto é comandos) e, por vezes, guardam também dados em diversos formatos.\r\nVamos carregar um pacote chamado nycflights13, que contém um conjunto de dados útil para fins didáticos. Existem dois passos para abrir um pacote em R:\r\nInstalação: Uma única vez por máquina (então rode uma vez em modo interativo, idealmente no Console. Se deixar no seu script lembra-se de colocar num comentário para que não seja executada cada vez que usamos ‘Knit’. Veja abaixo para mais detalhes):\r\ninstall.packages(\"nycflights13\")\r\nDisponibilização: Cada vez que rodamos o script em que precisamos do conteúdo do pacote (então deixe essa linha dentro do seu script, no início de preferência):\r\n```{r}\r\nlibrary(\"nycflights13\")\r\n```\r\n\r\nHabilidade Básica de Programação: Comentários\r\nO R vai processar tudo que está no seu script, linha por linha. A única exceção é quando uma linha começa com o símbolo # dentro de um chunk. Isso significa um ‘comentário’, que queremos notar uma coisa para documentar o que estamos fazendo numa linha de código e porque.\r\nComentários são essenciais para uma programação efetiva. Posso te garantir, você não vai lembrar o motivo para o seu código em alguns meses/anos. Melhor deixar tudo explícito hoje enquanto prepara o código.\r\nPode usar o atalho Ctrl+Shift+c para comentar a(s) linha(s) selecionada(a) ou a linha na qual o cursor estiver posicionado. (Observe que isso também funciona para texto simples).\r\n\r\n\r\n#Nota: O uso de comentário abaixo nos permite notar como foi instalado o pacote, sem rodar o código\r\n\r\n#install.packages(\"nycflights13\")\r\nlibrary(\"nycflights13\")\r\n\r\n\r\n\r\nExplorando os dados de flights\r\nO pacote nycflights13 contém um banco de dados chamado flights. É literalmente um banco de dados de todos os voos que partiram de Nova Iorque em 2013, e um ótimo exemplo para illustrar os poderes de R.\r\nLogo mais veremos como abrir conjuntos de dados de outras fontes (arquivos de texto, outros softwares, etc), mas já podemos começar a trabalhar com data frames usando flights.\r\nPrimeiro, queremos conhecer os dados para saber o que eles descrevem, então trabalhamos em modo interativo. Pode digitar o nome de banco de dados (o objeto) no console e executa-lo com Enter, ou digitar num chunk e executa-lo com ‘Run’ ou Ctrl+Enter:\r\n```{r}\r\nflights\r\n```\r\nOs dados aparecem numa tabela interativa abaixo do chunk em que eles foram abertos. Pode descer para ver mais observações ou passar para a direita para ver mais colunas.\r\n\r\n\r\nflights\r\n\r\n\r\n\r\nAntes de continuar, olhe a tabela de flights e responda às seguintes perguntas:\r\nQuantas observações existem no banco de dados?\r\nQuantas variáveis existem no banco de dados?\r\nO que representa cada observação no banco de dados?\r\nQuais variáveis existem nos dados?\r\nQual ‘tipo’ de dado cada variável contém?\r\nEstas são questões fundamentais que devem ser o seu ponto de partida para conhecer os seus dados, perguntas críticas para qualquer análise.\r\nO R ajuda a responder as perguntas de várias formas. O número de linhas e colunas está escrito ao final da tabela. Se queremos calcular o número de observações (linhas) e variáveis (colunas) usando um código, podemos pedir assim:\r\n\r\n\r\nnrow(flights)\r\nncol(flights)\r\n\r\n\r\nnrow significa o número de linhas, e ncol o número de colunas. Use Ctrl+Enter para rodar interativamente, e/ou deixe no script para que o número de linhas e colunas seja impresso no seu documento final. Isso é bastante útil quando, por exemplo, você quer relatar o número de observações no seu artigo - não precisa lembrar, o R vai calcular e atualizar automaticamente para você!\r\n\r\nHabilidade Básica de Programação: Funções e Parênteses\r\nQualquer operação ou transformação em R é uma função que aceita (pelo menos) um insumo (input) e gera um produto (output). Cada função deve ter um nome único (infelizmente, no entanto, duplicações são possíveis e problemáticas). Funções sempre vêm com parênteses depois, e especificamos os insumos nos parênteses, com múltiplos insumos separados por vírgula. Mesmo quando uma função não precisa de inputs, exige parênteses, por exemplo Sys.Date() devolve a data de hoje.\r\n\r\n\r\nfuncao(insumos)\r\n\r\n\r\n\r\n\r\nSys.Date()\r\n\r\n[1] \"2023-10-06\"\r\n\r\n\r\nComo sabemos o significado de algumas colunas com nomes ambíguos? Podemos acessar o help (documentação) do objeto para descobrir uma descrição do que há no data frame chamado flights:\r\n?flights\r\nOs detalhes aparecem na janela/aba ‘Help’. Você pode ler com calma antes de avançar. Se deixarmos o código de help no script, o R vai abrir a página de documentação cada vez que rodarmos o script (knit)! Então temos que operar no modo interativo: o melhor é digitar na aba de Console, ou apagar antes de continuar seu script.\r\nO help funciona para todas as funções de R: Abra o help da função nrow para entender melhor os detalhes da função.\r\nTipos de Dados\r\nE como podemos saber o tipo de dado de cada variável? Quando executamos o nome de um data frame e ele parece na tabela interativa abaixo de chunk, de novo o R ajuda - debaixo de cada coluna, existe uma descrição, por exemplo <int> ou <chr>. O que isso significa?\r\nSe você já fez um curso de estatística básica ou de métodos quantitativos deve se lembrar que as variáveis são classificadas da seguinte maneira:\r\n1- Discretas\r\nNominais, que são categorias (normalmente texto) não ordenadas\r\nOrdinais, que são categorias (normalmente texto) ordenadas\r\nInteiros, ou seja, o conjunto dos números inteiros\r\n2- Contínuas, números que podem assumir valores não inteiros\r\nEstas categorias se traduzem para os tipos de dados de R de acordo com a tabela abaixo:\r\n\r\n\r\nTipo em R\r\nAtalho em Tabela\r\nDiscreta\r\nNominal\r\nFator ou Caracter\r\nfctr, chr\r\n\r\nOrdinal\r\nFator ordenado\r\nfctr, chr\r\n\r\nInteiro\r\nInteiro\r\nint\r\nContínua\r\n\r\nDobro/Numérico/Real\r\ndbl\r\nExistem outros tipos também. Por enquanto, podemos deixar o R cuidar dos tipos de dados e não precisamos nos preocupar na geração/transformação de tipos de dados. Quais tipos de dados existem no banco de dados flights?\r\nCriando o nosso próprio data.frame\r\nNo próximo tutorial, vamos aprender como importar dados enormes de fontes externas. Na prática, quase todos os objetos com os quais vamos trabalhar são data.frames, e às vezes a informação contida neles é simples, então podemos criá-los na hora.\r\nUma pequena complicação: neste curso vamos trabalhar com uma variedade de data.frame em R um pouco mais sofisticada - um ‘tibble’. Um tibble é um data.frame, não tem diferença; só que um tibble é mais flexível e melhor formatado em R para facilitar a nossa análise. O banco de dados de flights é um tibble. Se você colocar o cursor em cima do nome de flights no ‘Environment’ (sem clicar) vai ver a informação sobre o tipo de objeto que ele é.\r\nPara usar um tibble, temos que aproveitar o pacote super-útil que se chama tidyverse. Primeiro, temos que instalar o pacote:\r\n\r\n\r\ninstall.packages(\"tidyverse\")\r\n\r\n\r\nLembre-se de rodar esta linha no Console, ou ‘comentar’ a instalação depois de executar porque só precisamos rodar uma vez por máquina.\r\nAgora que o pacote é instalado, é só chamar com library():\r\n\r\n\r\n#install.packages(\"tidyverse\")\r\nlibrary(\"tidyverse\")\r\n\r\n\r\nVamos ilustrar a criação de um data frame com um exemplo: flights contém apenas as siglas dos aeroportos - Imagine que queremos criar um lembrete dos nomes completos dos aeroportos. Em vez de escrever uma nota física ou anotar num caderno, vamos criar um tibble (um data.frame, uma tabela) em nosso script para documentar a relação entre as siglas e os nomes completos.\r\nAntes de criar um tibble, vamos começar criando um vetor simples apenas com as siglas. Um vetor é um conjunto de elementos, então usamos a função c() (de conjunto ou concatenate) para definir um vetor. Dentro dos parênteses, digitamos os elementos individuais em aspas. Assim:\r\n\r\n\r\nc(\"NWR\",\"JFK\",\"LGA\")\r\n\r\n\r\nO que acontece se rodarmos esta linha? Recebemos em resposta o mesmo vetor. Não ajuda muito só imprimir o que a gente acabou de digitar… queremos salvar o nosso vetor como um objeto. Então temos que salvar (usando a seta <-) para um objeto nomeado, ex.:\r\n\r\n\r\nsiglas_aeroportos <- c(\"NWR\",\"JFK\",\"LGA\")\r\n\r\n\r\nDa mesma maneira podemos gerar um segundo vetor com os nomes completos dos aeroportos na mesma ordem:\r\n\r\n\r\nnomes_aeroportos <- c(\"Newark\",\"John F Kennedy\",\"Laguardia\")\r\n\r\n\r\nE agora? O R guardou os dois vetores, mas ele não sabe que o primeiro elemento NWR de siglas_aeroportos é ligado com o primeiro elemento de nomes_aeroportos, e o segundo com o segundo etc. A beleza de um data.frame/tibble é que ele associa os elementos de vários vetores como observações ligadas.\r\nA função que nos permite gerar um tibble, supreendentemente, se chame tibble(). Nos parênteses, colocamos os nomes das variáveis, separadas por vírgulas, e depois o nome do vetor relevante.\r\n\r\n\r\ntabela_aeroportos <- tibble(Sigla=siglas_aeroportos,\r\n                            Nome=nomes_aeroportos)\r\n\r\n\r\nCaso seja mais simples/rápido, não tem problema pular a etapa de definir os vetores separadamente e anteriormente; podemos definir-los diretamente dentro do tibble; o resultado é igual:\r\n\r\n\r\ntabela_aeroportos <- tibble(Sigla=c(\"NWR\",\"JFK\",\"LGA\"),\r\n                            Nome=c(\"Newark\",\"John F Kennedy\",\"Laguardia\"))\r\n\r\n\r\n\r\nSigla\r\nNome\r\nNWR\r\nNewark\r\nJFK\r\nJohn F Kennedy\r\nLGA\r\nLaguardia\r\n\r\nAgora, podemos rodar o nome de tabela_aeroportos sempre que queremos lembrar, e aparece uma tabela bonita! Ou podemos incluir a tabela no documento final (veja a próxima seção). No futuro, vamos usar isso para várias uniões (joins) entre tibbles em análises mais complexas.\r\nInserindo Tabelas no Documento Final\r\nVoltando para o modo de gerar scripts para documentar a nossa análise, como os tibbles aparecem no nosso documento final?\r\nPodemos deixar o nome do tibble num chunk e compilar com Knit? Experimente!\r\n```{r}\r\ntabela_aeroportos\r\n```\r\n\r\n# A tibble: 3 × 2\r\n  Sigla Nome          \r\n  <chr> <chr>         \r\n1 NWR   Newark        \r\n2 JFK   John F Kennedy\r\n3 LGA   Laguardia     \r\n\r\nPodemos, sim, mas ele sai feio demais. Vamos ver várias opções no futuro, mas por enquanto podemos pedir para o Rmarkdown produzir tabelas mais bonitas especificando uma opção no cabeçalho do documento.\r\nVamos especificar o ‘output’ com a opção de ‘df_print: paged’, que é um tipo de formatação de tabela simples mas útil:\r\n\r\n---\r\ntitle: \"Examplo\"\r\nauthor: \"Jonathan\"\r\ndate: \"19 de fevereiro 2020\"\r\noutput:\r\n  html_document:\r\n    df_print: paged\r\n---\r\n\r\nTome cuidado com os espaços; o melhor é iniciar uma nova linha depois de ‘output:’ e o cursor já fica no lugar certo. E uma nova linha depois de ‘html_document:’. Se tiver problemas, pode copiar e colar do exemplo acima.\r\nAgora, se usamos o ‘Knit’ para compilar o nosso documento, a tabela sai mais bonita, facilitando a nossa análise:\r\n\r\n\r\n\r\n\r\nTente gerar uma tabela para o banco de dados de flights para experimentar a interatividade da tabela.\r\n```{r}\r\nflights\r\n```\r\n\r\n\r\n\r\n\r\nA opção de ‘df_print: paged’ funciona quando o formato do nosso documento final é HTML, gerando uma tabela interativa.\r\nDocumentos em Formato Word\r\nAté agora, só produzimos documentos em formato HTML. HTML tem a vantagem de ser simples, flexível e interativo, mas não é comum usar para relatórios. O Rmarkdown facilita a produção de documentos em vários formatos. Um outro é Microsoft Word. E não precisa mudar nada no seu código.\r\nClique na seta ao lado do ‘Knit’ em RStudio e depois ‘Knit to Word’. Deve aparecer um documento mais familiar em Word.\r\nÉ isso, já aprendemos como criar relatórios e análises reproduzíveis! Agora faça os exercícios abaixo com calma e pratique o que você tem aprendido.\r\n\r\nExercício 1\r\nComece um novo script de Rmarkdown e acesse o banco de dados gapminder no pacote dslabs. Estes dados descrevem estatísticas resumidas para países do mundo desde 1960.\r\n\r\n\r\nMostrar Código\r\n\r\n#install.packages(\"dslabs\")\r\nlibrary(\"dslabs\")\r\n\r\n\r\nProduza um mini-relatório com algumas frases curtas em HTML que descreva o banco de dados gapminder:\r\nNúmero de observações\r\nNúmero e nomes das variáveis\r\nO tipo de cada variável\r\nO que representa cada observação no banco de dados?\r\n\r\n\r\n\r\nMostrar Código\r\n\r\nnrow(gapminder)\r\nncol(gapminder)\r\n\r\n\r\nFaça com que as respostas 2(a) e 2(b) sejam calculadas automaticamente no relatório usando funções do R e código em linha para inserir as respostas numa frase.\r\nCalcule o valor do número de observações multiplicado pelo número de colunas\r\n\r\n\r\nMostrar Código\r\n\r\nnrow(gapminder)*ncol(gapminder)\r\n\r\n\r\nInclua uma tabela do banco de dados gapminder no relatório.\r\n\r\n\r\nMostrar Código\r\n\r\ngapminder\r\n\r\n\r\nVerifique que o seu relatório tem título, autor e data corretos, e comentários suficientes para explicar o que faz cada linha de código.\r\nTente compilar o seu script final para um documento de Word.\r\n\r\n\r\n\r\nExercício 2: Aprender juntos\r\nSe você conhece uma outra pessoa da turma, compare o seu script de Exercício 1 com o script deles. Quais são as diferenças? Quais delas importam? Como você pode melhorar o seu scipt? Ajuste o seu script para deixa-lo mais limpo e organizado.\r\n\r\n\r\n\r\nExercício 3: Encontre o erro em todos os códigos abaixo\r\n\r\n\r\nQ1)\r\nnrow[flights]\r\n\r\n\r\nMostrar Código\r\n\r\nnrow(flights)   \r\n# Funções exigem parênteses, não colchetes\r\n\r\n\r\n\r\n\r\nQ2)\r\nnrou(flights)\r\n\r\n\r\nMostrar Código\r\n\r\nnrow(flights)   \r\n# R não tem verificador de texto. Erros impedirão o código de rodar\r\n\r\n\r\n\r\n\r\nQ3)\r\nv1 <- (“pato”, “cachorro”,\r\n“minhoca”, “lagarto”)\r\n\r\n\r\nMostrar Código\r\n\r\nv1 <- c(\"pato\", \"cachorro\", \"minhoca\", \"lagarto\")  \r\n# Criar um vetor exige a função 'c()'\r\n\r\n\r\n\r\n\r\nQ4)\r\nv2 <- c(“1”, “2”, “3”, “4”)\r\nv2 + 42\r\n\r\n\r\nMostrar Código\r\n\r\nv2 <- c(1, 2, 3, 4)\r\nv2 + 42   \r\n# Não podemos somar um número a um caractere. \r\n# Se quisermos manter v2 como variável numérica, precisamos retirar as aspas.\r\n\r\n\r\n\r\n\r\nQ5)\r\nv1 <- c(“pato”, “cachorro”, “minhoca”, “lagarto”\r\n\r\n\r\nMostrar Código\r\n\r\nv1 <- c(\"pato\", \"cachorro\", \"minhoca\", \"lagarto\")\r\n# Quando esquecemos de fechar os parênteses, o R entende que ainda faltam argumentos na função, então não roda.\r\n\r\n\r\n\r\n\r\nQ6)\r\nv3 <- c(33 31 40 25 27 40)\r\n\r\n\r\nMostrar Código\r\n\r\nv3 <- c(33, 31, 40, 25, 27, 40)  \r\n# Seperamos argumentos e dados com vírgula\r\n\r\n\r\n\r\n\r\nQ7)\r\nv1 <- c(pato, cachorro, minhoca, lagarto)\r\n\r\n\r\nMostrar Código\r\n\r\nv1 <- c(\"pato\", \"cachorro\", \"minhoca\", \"lagarto\")  \r\n# Para o R entender que estamos tratando de palavras, precisamos usar aspas. Do contrário, o programa irá procurar objetos nomeados de pato, cachorro, etc. Como eles não existem nesse caso, não é possível formar o vetor\r\n\r\n\r\n\r\n\r\nQ8)\r\nv1 -> c(“pato”, “cachorro”, “minhoca”, “lagarto”)\r\n\r\n\r\nMostrar Código\r\n\r\nv1 <- c(\"pato\", \"cachorro\", \"minhoca\", \"lagarto\")  \r\n# A direção da seta indica onde queremos salvar os resultados\r\n\r\n\r\n\r\n\r\nQ9)\r\nv3 <- C(33, 31, 40, 25, 27, 40)\r\n\r\n\r\nMostrar Código\r\n\r\nv3 <- c(33, 31, 40, 25, 27, 40)  \r\n# R é 'case sensitive'. maiúsculo ou minúsculo é uma distinção importante.\r\n\r\n\r\n\r\n\r\nQ10)\r\nv1 <- c(“pato”, “cachorro”“,”minhoca”, “lagarto”)\r\n\r\n\r\nMostrar Código\r\n\r\nv1 <- c(\"pato\", \"cachorro\", \"minhoca\", \"lagarto\")  \r\n# Aspas andam sempre em pares. É preciso prestar atenção à ordem deles para não deixar o texto de interesse de fora\r\n\r\n\r\n\r\n\r\nQ11)\r\nv1 <- c(“pato”, “cachorro”, “minhoca”, “lagarto”)\r\nv4 <- c(33, 31, 40, 25, 27, 40)\r\nmyData <- tibble(v1, v4)\r\n\r\n\r\nMostrar Código\r\n\r\nv1 <- c(\"pato\", \"cachorro\", \"minhoca\", \"lagarto\",\"\",\"\")\r\nv4 <- c(33, 31, 40, 25, 27, 40)\r\nmyData <- tibble(v1, v4)\r\n# Tibbles precisam de vetores de tamanhos iguais. \r\n# Se não tivermos os dados para alguma observação, precisamos avisar que este valor está faltando, por isso as aspas vazias\r\n\r\n\r\n\r\n\r\nQ12)\r\nv1 <- c(“pato”, “cachorro”, “minhoca”, “lagarto”)\r\nv4 <- c(33, 31, 40, 25)\r\nmyData <- tibble(v1 = animal, v4 = idade)\r\n\r\n\r\nMostrar Código\r\n\r\nv1 <- c(\"pato\", \"cachorro\", \"minhoca\", \"lagarto\")\r\nv4 <- c(33, 31, 40, 25)\r\nmyData <- tibble(animal = v1, idade = v4)\r\n# Ao criar o tibble, o nome de variável na tabela fica em primeira lugar, seguida por '=' e finalmente o nome do vetor que pretende inserir na tabela.\r\n\r\n\r\n\r\n\r\n\r\nLeitura para Tutorial 2\r\nAntes da próxima aula, por favor leia R 4 Data Science, Capítulos 2, 4, 5, 6, 8, 9, 10 e 11\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:17:04-03:00"
    },
    {
      "path": "Juntando_Bancos.html",
      "title": "Juntando Bancos de Dados",
      "description": "Combinar os dados para a sua própria pesquisa\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nUnidades de Análise\r\nExemplos de Joins Simples (left_join)\r\nJuntando Bancos por Múltiplas Variáveis\r\nBancos e Dados Faltantes (right_join, inner_join, full_join, anti_join)\r\nNesting data (nest, unnest)\r\n\r\nUnidades de Análise\r\nA maioria de projetos exigem a combinação de dados de fontes diversas. É assim que criamos a nossa própria contribuição para a pesquisa. Por exemplo, para estudar o efeito de um programa de governo sobre a votação, preciseramos de pelo menos dois bancos de dados, um com os dados da localização do programa e outro sobre os resultados eleitorais. Como podemos juntar estes dois bancos para facilitar a nossa análise?\r\nPrimeiro, temos que entender os dois bancos:\r\n(i) qual é a unidade de análise de cada observaçao?;\r\n(ii) quais são os identificadores únicos (as variáveis ‘chaves’) em cada banco que identificam unicamente cada observação (evitando duplicações)?;\r\n(iii) quais são os identificadores comuns presentes em ambos os bancos que permitem cruzar as informações?\r\nNo exemplo acima, pode ser que o programa do governo foi executado em alguns municípios e não em outros, então o nosso banco varia por município, identificado unicamente com a variável do código municipal do IBGE. Por outro lado, imagine que temos os dados eleitorais resumidos por cada município com o a margem de vitória, então a unidade de análise é cada município, identificado pelo código municipal do IBGE também.\r\nQuando os nossos dois bancos têm a mesma unidade de análise (o municipio) e o mesmo identificador único (código IBGE), o indentificador comum é óbvio: é o código IBGE. Assim, a junção dos bancos é mais ou menos fácil - usamos as variáveis de identificador único e comum (código IBGE) para cruzar as informações e adicionar as colunas de um banco para o outro.\r\n\r\nIsto é a circunstância mais fácil para cruzar os dois bancos: a mesma unidade de análise, um identificador único e comum em cada banco, e dados completos.\r\nUnidades Diferentes\r\nImagine agora que o banco de dados do programa do governo varia por estado em vez do município, então ele tem apenas 27 observações, identificadas por sigla do estado (“AC” etc.). Neste caso em que a unidade de análise e as variáveis variam entre bancos, como é possível juntar os bancos? Primeiro, temos que decidir a unidade de análise desejada do banco de dados final - por estado ou por município? As duas são possíveis.\r\nEstratégia 1 (por estado): Agregando o banco com mais unidades: Se quissemos uma tabela final por estado, temos que agregar os dados eleitorais do nível municipal para o nível estadual com as ferramentas já conhecidas (%>% group_by(Estado) %>% summarize()). Isto exige uma decisão sobre como a agregar cada variável municipal para o estadual - a média, a soma, a mediana, o mínimo etc. Com os dois bancos no nível estadual, é fácil executar a junção, e o resultado será um banco de dados com dados eleitorais e do programa por cada estado.\r\n\r\nEstratégia 2 (por município): Duplicando os dados do banco com menos unidades: Se quissemos uma tabela final por município, temos que reconhecer que juntando os dois bancos vai duplicar os dados estaduais para cada município no estado. Por exemplo, a presença do programa indicado por código ‘1’ em “AC” será reptido para cada município de Acre. Isto faz sentido neste contexto, mas é crucial entender se o programa realmente foi executado assim.\r\n\r\nPorém, existe uma outra dificuldade com qualquer uma das duas estratégias - o identificador único de estados (“AC”) não é ígual ao identificador único dos municípios (“1200013”). Como o R vai saber como a cruzar observações de um banco com o outro? Ele precisa saber em qual estado fica cada município. Então nós temos que encontrar um jeito de adicionar uma nova coluna que indica o estado no Banco eleitoral (Banco B) para facilitar o cruzamento. Em termos gerais, precisamos de um identificador comum nos dois bancos.\r\nPode ser que os dados do estado de cada município já existem no banco, ou pode ser necessário fazer outro cruzamento para importá-los. Em nosso exemplo, a informação do estado está presente nos dois primeiros digitos do código de município, e podemos criar o identificador comum: Temos que separar os primeiros dois dígitos do código municipal que indicam o estado, e depois mapear os dígitos para a sigla. O resultado será uma nova variável, a sigla do estado, para cada município. Agora, temos a sigla do estado no mesmo formato nos dois banco de dados e eles são compatíveis para cruzar. Apenas no final dessa preparação é possível juntar os dois bancos.\r\nExemplos de Joins Simples (left_join)\r\nAté agora, só discutimos os passos preparatórios:\r\n(1) Decidir a unidade de análise do banco de dados final,\r\n(2) Se necessário, agregar os bancos de dados iniciais para a unidade de análise desejado,\r\n(3) Transformar as variáveis para que temos um identificador comum entre os banco de dados.\r\nO próximo passo é juntar os dois bancos. Vamos usar a função left_join(). Temos que definir três argumentos: Os nomes dos dois bancos de dados, e o conjunto de variáveis que compõem o identificador comum (a ‘chave’) que usaremos para realizar a junção. O R vai combinar as colunas das observações com o mesmo valor de identificador comum nos dois bancos e insira-as como uma linha na nova tabela.\r\nSempre começamos com o banco de dados que já tem a unidade de análise e número de linhas desejadas no banco de dados final, e encaminhamos este banco para a função left_join(). Dentro de left_join especificamos o segundo banco de dados, e a variável (ou as variáveis num vetor) do identificador comum.\r\n\r\n\r\nBanco_1 %>% left_join(Banco_2, \"Identificador Comum\")\r\n\r\n\r\nPara praticar, vamos abrir um outro banco de dados no pacote nycflights13, esta vez sobre os aviões mesmo, planes. A unidade de flights é um voo (uma partida de Nova Iorque) e à unidade de planes é um avião, que obviamente pode aparecer várias vezes em flights. A variável de identificar comum é tailnum, que é exclusivo para cada avião.\r\nPara ver um exemplo de cruzamento em que a unidade de análise é basicamente ígual - cada avião faz uma viagem só - vamos filtrar os voos para um dia e trajeto específico.\r\n\r\n\r\nlibrary(\"tidyverse\")\r\nlibrary(\"tidylog\")\r\nlibrary(\"nycflights13\")\r\n\r\n\r\n\r\n\r\nflights_JFK_ATL <- flights %>% filter(month==4 & day==22 & origin==\"JFK\" & dest==\"ATL\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nPode verificar que os cinco aviões (o tailnum) só aparecem uma vez na tabela acima. Agora, é fácil cruzar as duas tabelas com o identificador único e comum:\r\n\r\n\r\nflights_JFK_ATL %>% left_join(planes, by=\"tailnum\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nExplore a tabela. O resultado é como previsto: uma linha para cada voo, com os dados da avião nas colunas finais, mais para a direita. Simples.\r\nObserve que o pacote tidylog é de grande valor aqui. Ele resume os detalhes do join e imprimi-los no console. Assim, você pode verificar quantas observações existem nos dois bancos (‘matched rows’) e se haver dados faltantes no primeiro banco de dados (‘rows only in y’) e no segundo banco de dados (‘rows only in x’).\r\nMais geralmente, se nós não filtramos os voos anteriormente e temos aviões duplicados, temos que planejar com mais cuidado: Qual unidade de análise queremos na tabela final? Uma linha por voo, ou uma linha por avião?\r\nEstratégia 1: Agregando o banco com mais unidades: Uma opção é por avião, resumindo por exemplo o número de viagens de cada avião, que exige uma agregação do banco flights por tailnum:\r\n\r\n\r\nflights_por_aviao <- flights %>% \r\n  group_by(tailnum) %>%\r\n  tally()\r\n\r\n\r\nObserve que flights_por_aviao tem muito menos observações que flights, e a unidade de análise é cada avião, compatível com a unidade da tabela planes. Agora ,a junção é fácil, agora começando com planes:\r\n\r\n\r\nplanes_com_num_viagens <- planes %>% left_join(flights_por_aviao, by=\"tailnum\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nComo aparece o resultado final? O planes agora tem mais uma coluna, n, com o número de viagens de cada avião - poderoso, né? Note que o número de linhas no resultado é ígual ao número de linhas no banco de planes.\r\nEstratégia 2: Duplicando os dados do banco com menos unidades: A outra opção é gerar um novo tibble com cada observação um voo, e adicionando dados da avião ao tabela de flights. Dado que temos múltiplos voos para cada avião isso implica uma duplicação dos dados de avião cada vez que ele aparece no banco flights.\r\n\r\n\r\nflights_com_planes <- flights %>% left_join(planes, by=\"tailnum\")\r\n\r\n\r\nObserve que flights_com_planes tem o mesmo número de linhas que flights. Vamos filtrar e ordenar os nossos dados para ver que os dados do avião são repetidas cada vez que o avião fez uma viagem (por exemplo avião N11109 aparece quartro vezes):\r\n\r\n\r\nflights_com_planes %>% \r\n  filter(dest==\"GSO\") %>% \r\n  arrange(tailnum) %>%\r\n  select(tailnum, month, day, dep_time, manufacturer, year.x, year.y, model)\r\n\r\n\r\n\r\n\r\n\r\n\r\nObserve que geramos um problema pequeno quando juntamos os dois bancos: ambos os bancos originais contém uma variável se chama ‘year’. Dado que as variáveis têm que ter nomes únicos, o R renomeou as colunas ‘year.x’ e ‘year.y’. Isto é um pouco chato porque realmente não distingue informação diferente: o ano da viagem (year.x) e o ano da fabricação do voo (year.y). É sempre melhor renomear as variáveis antes da junção para evitar conflitos e descrever melhor as nossas variáveis, ou selecionar apenas as variáveis que você quer transportar de um banco de dados para o outro:\r\n\r\n\r\nplanes <- planes %>%\r\n  rename(\"year_fabricação\"=\"year\")\r\n\r\nflights_com_planes <- flights %>% left_join(planes, by=\"tailnum\")\r\n\r\n\r\nAgora, o nosso novo tibble, produto da junção, é pronto para analisar e visualizar como qualquer outro tibble que já vimos. Por exemplo, vamos resumir o número de voos por ano de fabricaçao da avião:\r\n\r\n\r\nflights_com_planes %>% \r\n  group_by(year_fabricação) %>%\r\n  tally() %>%\r\n  ggplot() +\r\n  geom_col(aes(x=year_fabricação, y=n))\r\n\r\n\r\n\r\nEspero que você não estava nos voos com avião da década 50…\r\nIdentificando Observações Faltantes\r\nAté agora, assumimos que os dois bancos contém dados completos: que cada avião que existe no banco de dados flights existe no banco de dados planes (não estamos faltando dados), e que cada avião no banco de dados planes existe no banco de dados flights (não temos aviões que existem mas não voaram). Entender se isso é verdade é importante para verificar se a junção deu certo.\r\nA função útil para identificar as observações que existem em um banco mas não no outro se chama anti_join. Ela segue exatamente o mesmo padrão que left_join(), mas o resultado não é um tibble combinado, é as observações do primeiro tibble que não aparecem no segundo.\r\n\r\n\r\nflights %>% anti_join(planes, by=\"tailnum\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nObserve que temos 52,606 observações em flights (a tabela acima se imprime os primeiros 10,000) que têm um tailnum que não existe em planes. Isso afeta, por exemplo, o nosso gráfico por ano de fabricação do voo, que falta estes voos. Pode ser crucial entender este viés para a sua análise.\r\nTambém é fácil availiar o inverso: se existam aviões que não voaram da Nova Iorque em 2013, invertindo os dois bancos de dados no anti_join().\r\n\r\n\r\nplanes %>% anti_join(flights, by=\"tailnum\") \r\n\r\n\r\n\r\n\r\n\r\n\r\nBoa notícia: todas as aviões de planes são presentes em flights.\r\n\r\nExercício 1: Juntando dois bancos\r\nCrie dois tibbles pequenos (com a função tibble()) como eles abaixo e juntar eles pela coluna ID.\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nMostrar Código\r\n\r\nt_combined <- t1 %>% left_join(t2, by=\"ID\")\r\n\r\n\r\nExecute um join dos bancos de dados flights e planes para apenas os voos de carrier United (UA) no dia 16 de setembro de 2013. Qual é o modelo (model) de avião mais comum destes voos?\r\n\r\n\r\nMostrar Código\r\n\r\nflights_specific <- flights %>% \r\n  filter(month==9 & day==16 & year==2013 & carrier==\"UA\")\r\n\r\nflights_specific_planes <- flights_specific %>% \r\n  left_join(planes, by=\"tailnum\")\r\n\r\nflights_specific_planes %>% group_by(model) %>% \r\n  tally() %>% \r\n  top_n(1, n)\r\n\r\n\r\nQuantos assentos (seats) totais foram instalados nos voos de JFK para Atlanta (ATL) em cada mês?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% left_join(planes, by=\"tailnum\") %>%\r\n  filter(origin==\"JFK\" & dest==\"ATL\") %>%\r\n  group_by(month) %>%\r\n  summarize(total_assentos=sum(seats, na.rm=T))\r\n\r\n\r\nQueremos um resumo do número de voos no ano de 2013 por companhia aérea. Mas o nosso banco de flights não contém o nome oficial das companhias. Execute um join entre os banco de dados flights e airlines para criar uma tabela resumida e clara.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(carrier) %>% \r\n  tally() %>%\r\n  left_join(airlines, by=\"carrier\") %>%\r\n  select(name, n)\r\n\r\n\r\n\r\nJuntando Bancos por Múltiplas Variáveis\r\nConsidere um outro banco de dados no pacote nycflights13, weather, que contém as condições climáticas em cada aeroporto por hora. Como sabemos o tempo para cada voo? Não é suficiente juntar por origin, obviamente porque o tempo varia por dia e hora e queremos as condições relevantes na hora da partida do voo. Então é necessário realizar a junção com as variáveis que identificam a unidade de análise comum entre os dois bancos: localização e hora.\r\nLocalização é fácil: origin existe nos dois bancos. Hora é mais complexo: para definir o momento exato temos que considerar year, month, day e hour. Idealmente queremos incluir ‘minute’ também que existe no banco flights, mas está faltando no banco de weather, então não é possível. Para incluir todas essas variáveis como identificadores comuns, é só incluir eles no argumento do left_join, usando um vector (c()) para designar todas as variáveis relevantes:\r\n\r\n\r\nflights_weather <- flights %>% left_join(weather, c(\"origin\", \"year\", \"month\", \"day\", \"hour\"))\r\n\r\n\r\nComo fica o resultado? Ele tem o mesmo número de linhas que flights e mais dez colunas para as condições clímaticas na hora e local correspondente.\r\nPor interesse, podemos identificar os voos sujeitos à maior velocidade de vento:\r\n\r\n\r\nflights_weather %>% ungroup() %>% \r\n  top_n(1, wind_speed)\r\n\r\n\r\n\r\n\r\n\r\n\r\nO que acontece se esquecemos de um identificador comum relevante? Por exemplo, sem origin?\r\n\r\n\r\nflights %>% left_join(weather, c(\"year\", \"month\", \"day\", \"hour\"))\r\n\r\n\r\nOpa, o nosso banco agora tem mais de uma milhão de linhas! Por que? Lembre-se que com um left_join começamos com o banco na esquerda e, para cada voo, buscamos as linhas no segundo banco (weather) com o mesmo year, month, day e hour. Por exemplo, o primeiro voo no banco de dados flights partiu na hora:\r\n\r\n\r\nflights %>% slice(1) %>% select(year, month, day, hour)\r\n\r\n\r\n\r\n\r\n\r\n\r\nQuantas observações no banco de dados de weather batem com estes critérios? Vamos ver:\r\n\r\n\r\nweather %>% filter(year==2013 & month==1 & day==1 & hour==5)\r\n\r\n\r\n\r\n\r\n\r\n\r\nTrês. Uma para cada aeroporto de origem, que esquecemos de incluir como identificador comum. Então quando pedimos para R juntar os dois bancos apenas pelas variáveis de year, month, day e hour, adicionamos três observações de tempo para cada voo, triplicando o tamanho do banco de dados resultante. O resultado é que cada voo aparece três vezes, cada um com dados diferentes de tempo, como mostrado na tabela abaixo. Duas das linhas são erradas porque são os dados de tempo de locais diferentes do aeroporto de partida.\r\n\r\n\r\nflights %>% left_join(weather, c(\"year\", \"month\", \"day\", \"hour\")) %>% \r\n  slice(1:3) %>%\r\n  select(year, month, day, hour, dep_time, carrier, flight, humid, wind_speed)\r\n\r\n\r\n\r\n\r\n\r\n\r\nA conclusão é simples: sempre inclua todas as variáveis que são identificadores comuns nos dois bancos de dados. Se a left_join() aumenta o número de linhas entre o seu primeiro banco e o resultado, isto significa que existe mais de uma observação no segundo banco com os mesmos valores de variáveis identificadores. É possível que você deseja este resultado, mas é incomum, então presta atenção.\r\nBancos e Dados Faltantes (right_join, inner_join, full_join, anti_join)\r\nA característica mais importante da função left_join() é que ela tenta ao máximo possível preservar a unidade de análise e número de linhas do primeiro banco na esquerda (left) da junção (o banco que encaminhamos antes do pipe). Assim, não podemos ‘perder’ observações por causa da junção, e se especificamos os identificadores comuns corretamente, não devemos acrescentar observações também.\r\nPorém, o resultado é um banco de dados com dados faltantes - NA - para cada observação que não teve um par no segundo banco de dados. Por exemplo, flights_com_planes cruzou os dados de voos com aqueles dos aviões, mas alguns valores de tailnum no banco de dados de flights não existiam no banco de dados planes. Por exemplo, veja quentos aviões não são conhecidos entre LGA e ORD:\r\n\r\n\r\nflights_com_planes %>% filter(origin==\"LGA\" & dest==\"ORD\") %>%\r\n  select(month, day, dep_time, type, model, seats)\r\n\r\n\r\n\r\n\r\n\r\n\r\nQue tal se quisemos um banco de dados mais ‘limpo’ no resultado da junção dos dois tibbles, tirando as observações que não tem um par no outro banco? Às vezes é útil e eficiente usar a função alternativa inner_join(). Ela funciona identicalmente que left_join() exceto que o resultado falta as observações para quais o identificador comum não existe nos dois bancos:\r\n\r\n\r\nflights %>% inner_join(planes, by=c(\"tailnum\"))\r\n\r\n\r\nQuantas observações existem no resultado? 284170, a diferença entre o número de observações em flights (336776) e os voos sem tailnum em planes, o resultado de anti_join que executamos acima (52606). É uma boa exercício verificar.\r\nFrequentemente, usando um inner_join gera um viés de seleção - não sabemos muito sobre as aviões faltandas, mas não podemos ignorar eles para uma análise quantitativa. Então sempre recomendamos um left_join() como a ferramenta padrão.\r\nPara mostrar situações mais complexas, vamos trabalhar com um outro banco de dados do pacote nycflights13, os dados de airports, que contém o seu nome completo, localização etc. O primeiro desafio aqui é que temos que decidir como a juntar os bancos? No flights temos duas colunas sobre aeroportos: origin e dest. Lembrando que origin é só os três aeroportos de Nova Iorque, juntando por origin vai gerar muita repetição. Então vamos importar os dados do aeroporto do destino, dest.\r\nO identificador único do tibble airports é faa, que usa o mesmo código official que dest, que é ótimo. Porém, os nomes de colunas são diferentes nos dois bancos: dest e faa. Como resolvemos a diferença? Há várias possibilidades, mas sugerimos renomear a coluna de um banco antes de executar a junção para evitar problemas. Dado que as variáveis refletem exatamente o mesmo conteúdo, faz sentido que eles teriam nome ígual:\r\n\r\n\r\nairports <- airports %>% \r\n  rename(dest=faa)\r\n\r\nflights %>% left_join(airports, by=c(\"dest\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\nOutro ponto para reconhecer é que estamos adicionando muitas novas colunas de airports ao flights que pode poluir a nossa análise/apresentação. As vezes é melhor selecionar as colunas de interesse no segundo banco antes de realizar a junção. Por exemplo, se apenas quisemos o nome completo do aeroporto:\r\n\r\n\r\nflights %>% left_join(airports %>% select(dest, name), \r\n                      by=c(\"dest\"))\r\n\r\n\r\nVoltando a questão de dados faltantes, há mais uma maneira em que os airports são difíceis para juntar: Em contraste com os dados de planes, airports inclui aeroportos que não foram destinos dos voos de flights. Então ambos os anti_joins mostram observações faltantes:\r\n\r\n\r\nflights %>% anti_join(airports, by=c(\"dest\"))\r\nairports %>% anti_join(flights, by=c(\"dest\"))\r\n\r\n\r\nLembre-se que o nosso left_join preservou todos os dados de flights e incorporou (como colunas novas) os dados de apenas os aeroportos que são presentes na coluna dest. Ou seja, o left em left_join preserva os dados do tibble na esquerda (o primeiro tibble no código).\r\nNão precisa ser assim: existe também um right_join que preserva os dados do tibble na direita, incluindo todas as observações da direita e apenas eles da esquerda que tem um par na direita. Com o nosso exemplo de flights e airports:\r\n\r\n\r\nflights %>% right_join(airports, by=c(\"dest\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\nVeja que o número de observações diminuiu para 330,531, porque tiramos os voos de flights para as quais não tem dados sobre aeroportos.\r\nPreservando as observações de airports com right_join() também significa que qualquer aeroporto sem voo aparece no resultado, mas com muitos NA para as colunas que pertencem aos dados de flights que faltamos. São os aeroportos que não foram destinos dos voos da Nova Iorque, por exemple ‘04G’, ‘Lansdowne Airport’:\r\n\r\n\r\nflights %>% right_join(airports, by=c(\"dest\")) %>%\r\n  filter(is.na(year)) %>%\r\n  select(year, month, day, flight, dest, name)\r\n\r\n\r\n\r\n\r\n\r\n\r\nUma dica: na maioria de situações, é mais fácil trabalhar com left_join() para evitar confusão.\r\nFinalmente, é possível realizar um tipo de junção que preserva as observações de ambos os bancos de dados. Isto sempre vai gerar o maior banco de dados possível, pois mantemos todas as observações do primeiro banco de dados, e também todas do segundo banco, mesmo se eles não tenham par no outro banco. A função se chama full_join()\r\n\r\n\r\nflights %>% full_join(airports, by=c(\"dest\"))\r\n\r\n\r\nQuantas observações agora? 338,133, acima de 336,776 no flights pela quantidade de aeroportos faltando em flights, 1,357 (da anti_join acima).\r\nResumindo, existem cinco tipos de joins que produzem resultados differentes:\r\n\r\n\r\nTipo\r\n\r\n\r\nResultado\r\n\r\n\r\nleft_join\r\n\r\n\r\nPreservando todas as observações de Banco 1 com as colunas adicionais de Banco 2\r\n\r\n\r\nright_join\r\n\r\n\r\nPreservando todas as observações de Banco 2 com as colunas adicionais de Banco 1\r\n\r\n\r\ninner_join\r\n\r\n\r\nPreservando apenas as observações presentes em ambos os Bancos\r\n\r\n\r\nfull_join\r\n\r\n\r\nPreservando todas as observações dos dois bancos\r\n\r\n\r\nanti_join\r\n\r\n\r\nIdentificar as observações em Banco 1 ausentes em Banco 2\r\n\r\n\r\n\r\nExercício 2: Joins com Dados Faltantes\r\nCrie dois tibbles pequenos (com a função tibble()) como eles abaixo e juntar eles pelos identificadores comuns usando left_join().\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nUtilizando os dados criados em (1), agora queremos dois bancos de dados:\r\nUm limpo que contém apenas as observações com dados completos para ambos valor e população. Use um join apropriado, e o identificador comum, para criar este banco de dados.\r\n\r\n\r\nMostrar Código\r\n\r\nt1 %>% inner_join(t2, by=c(\"ID\", \"Ano\"))\r\n\r\n\r\nUm ‘completo’ que contém todas as observações mesmo que não existe par no outro banco. Use um join apropriado, e o identificador comum, para criar este banco de dados.\r\n\r\n\r\nMostrar Código\r\n\r\nt1 %>% full_join(t2, by=c(\"ID\", \"Ano\"))\r\n\r\n\r\nUsando os banco de dados flights e weather, identifique a precipitatação (precip) média no momento de partido dos voos de LGA em cada dia de dezembro.\r\n\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% left_join(weather, by=c(\"origin\", \"year\", \"month\", \"day\", \"hour\")) %>%\r\n  filter(month==12 & origin==\"LGA\") %>%\r\n  group_by(day) %>%\r\n  summarize(precip_media=mean(precip, na.rm=T))\r\n\r\n\r\nPara quantos voos em cada dia de dezembro em LGA faltamos dados de tempo?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(month==12 & origin==\"LGA\") %>%\r\nanti_join(weather, by=c(\"origin\", \"year\", \"month\", \"day\", \"hour\")) %>% \r\n  group_by(day) %>%\r\n  tally()\r\n\r\n\r\nPara quantos horas em cada dia de dezembro em LGA temos dados sobre o tempo mas não temos nenhum voo?\r\n\r\n\r\nMostrar Código\r\n\r\nweather %>% filter(month==12 & origin==\"LGA\") %>%\r\nanti_join(flights, by=c(\"origin\", \"year\", \"month\", \"day\", \"hour\"))%>% \r\n  group_by(day) %>%\r\n  tally()\r\n\r\n\r\nAgora vamos investigar se a visibilidade afeta o número de partidas por hora.\r\nUsando um join apropriado, gere um banco de dados que inclui a visibilidade em cada hora do ano e o número de voos que decolaram nesta hora.\r\n\r\n\r\nMostrar Código\r\n\r\nnum_voos_per_hora <- flights %>% group_by(year, month, day, hour, origin) %>% \r\n  tally()\r\n\r\nweather_num_voos_per_hora <- weather %>% left_join(num_voos_per_hora, \r\n                                                 by=c(\"origin\", \"year\", \"month\",\r\n                                                      \"day\", \"hour\")) \r\n\r\n\r\nResuma o seu banco de dados criado em (4a) para estimar a média do número de voos por hora por valor da variável visibilidade. Mostre os resultados num gráfico de pontos.\r\n\r\n\r\nMostrar Código\r\n\r\nweather_num_voos_per_hora %>% \r\n  group_by(visib) %>%\r\n  summarize(mean_n=mean(n,na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_point(aes(x=visib, y=mean_n))\r\n\r\n\r\n\r\nNesting data (nest, unnest)\r\nAgora vamos mudar direção e discutir um tópico menos ‘essencial’ mas bastante intuitivo e pedagógico que deve te ajudar entender e organizar os seus dados. Até agora, vejamos dois jeitos de ‘agrupar’ dados parecidos: (i) com variáveis discretas/categórica e o uso de group_by() para definir o escopo da transformação/resumo de dados, e (ii) em tibbles diferentes (como flights e airports, usando left_join para juntar os dados).\r\nExiste uma terceira opção que fica no meio do caminho entre os dois: Podemos colocar tibbles separados dentro de um tibble ‘superior’, e identificar o conteúdo de cada mini-tibble com uma variável discreta. Um pouco estranho, mas fará muito sentido em breve. O mais fácil é ver um exemplo do processo que se chama nesting.\r\n\r\n\r\nflights_nested <- flights %>% group_by(origin) %>%\r\n  nest()\r\n\r\n\r\n\r\n\r\n\r\n\r\nA lógica do código é usar a mesma linguagem de agrupamento, group_by(), para agrupar por aeroporto de origem, e depois usar a função nest() (sem argumentos) para ‘colapsar’ o resto do tibble por aeroporto de origem na coluna de data. Isso gera um mini-tibble novo para cada aeroporto, que fica na linha apropriada e identificada pela coluna origin no novo tibble.\r\nPara acessar os dados apenas de ‘EWR’ agora, é só filtrar para a coluna e linha apropriada e vejamos que é uma tabela inteira:\r\n\r\n\r\nflights_nested %>% filter(origin==\"EWR\") %>%\r\n  pull(data)\r\n\r\nflights_nested\r\n\r\n\r\n\r\n\r\n\r\n\r\nNesting é ainda mais útil com mais variáveis de agrupamento:\r\n\r\n\r\nflights_nested <- flights %>% group_by(origin, carrier) %>%\r\n  nest() %>%\r\n  arrange(carrier, origin)\r\n\r\nflights_nested\r\n\r\n\r\n\r\n\r\n\r\n\r\nAgora temos um tibble com 35 observações em que a unidade de análise é cada companhia aérea em cada aeroporto, e a coluna ‘data’ contém um tibble dos voos da companhia aérea e aeroporto de origem correspondente. Para voltar ao tibble original, é só aplicar unnest.\r\n\r\n\r\nflights_nested %>% unnest()\r\n\r\n\r\nPor que o ‘nesting’ é valioso? Todas as operações de programação podem ser feitos sem nesting, mas o valor é deixar mais claro a estrutura e o conteúdo dos nossos dados. Podemos trabalhar explicitamente com a unidade de análise relevante, e esconder a montanha de dados internos. No futuro vamos aprender como a aplicar funções para cada tibble na coluna de ‘data’, que facilita também a repetição de funções complexas por grupo.\r\nMais um exemplo, combinando nest com left_join, deixando claro que a unidade de análise é cada avião, evitando a duplicação dos dados dos aviões para cada linha, e colapsando as viagens de cada avião na sua própria mini-tibble numa coluna dedicada:\r\n\r\n\r\nflights %>% group_by(tailnum) %>%\r\n  nest() %>%\r\n  left_join(planes, by=c(\"tailnum\")) %>%\r\n  rename(\"viagens\"=\"data\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nExercício 3: Dados Nested\r\nCrie um tibble nested em que a unidade de análise é cada combinação de origem e destino, e numa outra coluna em mini-tibbles ficam todos os detalhes dos voos entre aquele origem e destino.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin, dest) %>% nest()\r\n\r\n\r\nCrie um tibble nested que resume o banco de dados flights por aeroporto de origem, mês, dia e hora. Use um join para juntar os dados de weather para cada aeroporto e hora.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin, month, day, hour) %>% \r\n  nest() %>%\r\n  left_join(weather, by=c(\"origin\", \"month\", \"day\", \"hour\"))\r\n\r\n\r\n\r\n\r\n\r\nLeitura para Tutorial 8\r\nAntes da próxima aula, por favor leia Exemplo de Análise Espacial no Site R-Spatial\r\n\r\n\r\n\r\nDesafio 3\r\nO Desafio 3 teste a sua capacidade de juntar bancos de dados e gerar gráficos apropriados e claros.\r\nO prazo para entregar Desafio 3 por email com título “[FLS6397] - D3” à minha conta é 23/06/2022, antes da aula. Por favor entregue (i) o arquivo .Rmd, e (ii) o arquivo .html.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:18:32-03:00"
    },
    {
      "path": "Limpando_Dados.html",
      "title": "Organizando e Limpando Dados",
      "description": "Construindo o seu Banco de Dados para Análise\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nDividindo e Unificando Variáveis\r\nRecodificação de Variáveis\r\nOrdenando os nossos dados\r\nFactors\r\nIdentificando Casos/Valores Únicos (distinct)\r\n\r\nDividindo e Unificando Variáveis\r\nDividir Variáveis (separate)\r\nNós recebemos um banco de dados que combina dois pedaços de informação em uma variável único. Por exemplo, juntando mês e ano num formato combinado, ex. “jan2013” Para filtrar, manipular ou calcular baseado no mês ou ano individualmente, é sempre melhor organizar os dados em variáveis separadas para cada pedaço de informação. Isto é um princípio de análise dados: cada variável merece a sua própria coluna.\r\nPara dividir uma variável (coluna) em duas, usamos o verbo separate(). Os argumentos da função são: (i) o nome da coluna que queremos dividir, (ii) os nomes das duas colunas novas, e (iii) como/onde queremos separar a coluna em duas. Pode verificar estes argumentos usando o help, ?separate. O (i) é fácil. No (ii) temos que especificar dois nomes, um para cada nova coluna, então não esqueça de usar o c(), ex. c(\"mes\",\"ano\") para indicar que você queria um vetor com mais de um elemento.\r\nO (iii) é o mais poderoso e complicado: Existem dois jeitos de separar uma variável em duas - por posição, ou por caractere. Vamos ver por posição primeiro, que indica que a variável tem um padrão fixo definido pelo número de caracteres entre os dois componentes. Ex. “jan2013” pode sempre ser separado depois do terceiro caractere, então usamos um separador de ‘3’.\r\nVamos mostrar com uma tabela pequena como uma variável de mês-ano pode ser dividido por posição:\r\n\r\n\r\nex_separate <- tibble(ID=1:3,\r\n                      Mes_Ano=c(\"jan2013\",\"mar2009\",\"out2015\"))\r\n\r\nex_separate %>% separate(Mes_Ano, c(\"Mes\",\"Ano\"), 3)\r\n\r\n\r\n\r\n\r\n\r\n\r\nFunciona, sim? Observe que o separate tira a variável original do tibble; se quiser manter, tem que adicionar o argumento remove=FALSE dentro do separate.\r\nÀs vezes o fornecedor de dados não é tão generoso com a padronização das variáveis. Como, por exemplo, dividimos os dados abaixo?\r\n\r\n\r\nex_separate_2 <- tibble(ID=1:3,\r\n                      Mes_Ano=c(\"janeiro_2013\",\"marco_2009\",\"outobro_2015\"))\r\n\r\n\r\nNão podemos usar posição dado que o tamanho do mês varia. Mas podemos pedir para o R buscar dentro do string de texto para o caractere específico que divide o mês e o ano: ’_’. O separate aceita este caractere em vez de número de posição:\r\n\r\n\r\nex_separate_2 %>% separate(Mes_Ano, c(\"Mes\",\"Ano\"), \"_\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nMuito poderoso! Veremos em uma aula futura como trabalhar mais com estes strings de texto complicados.\r\nUnificar Variáveis (unite)\r\nPodemos fazer o inverso e unificar duas variáveis para uma? Sim, é fácil, mas temos que justificar o porquê. Normalmente faz mais sentido deixar os pedaços de informação distintos em variáveis separadas. Pode ser que por motivos de apresentação queremos unificar duas variáveis em uma. Por exemplo, para juntar nome e sobrenome em uma coluna para um relatório. Veja abaixo o uso de unite() para devolver as nossas colunas de mês e ano para mes_ano. Os argumentos são basicamente os mesmos que separate(), sem o terceiro elemento do separador:\r\n\r\n\r\nex_separate_3 <- ex_separate_2 %>% separate(Mes_Ano, c(\"Mes\",\"Ano\"), \"_\")\r\n\r\nex_separate_3 %>% unite(\"Mes_Ano\", c(Mes,Ano))\r\n\r\n\r\n\r\n\r\n\r\n\r\nObserve que unite() insere um ’_’ entre os componentes por padrão; podemos especificar o nosso caractere preferido (ou nenhum) com mais um argumento na função, por exemplo sep=\", \".\r\n\r\n\r\nex_separate_3 %>% unite(\"Mes_Ano\", c(Mes,Ano), sep=\", \")\r\n\r\n\r\n\r\nHabilidade Básica de Programação: Aspas ou sem Aspas?\r\nVocê já observou que estamos nos referindo às variáveis em duas formas diferentes? Às vezes com aspas \"Variável\", e às vezes sem aspas Variável. Como sabemos qual a usar? É um tópico um pouco chato, mas importante.\r\nUsamos sem aspas quando referimos a um objeto que já existe em nosso Environment, ou uma coluna já existente num tibble. Usamos com aspas quando referimos a um nome novo que estamos gerando naquele momento.\r\nEntão em separate são as duas novas colunas que exigem de aspas, enquanto no unite é a coluna única e nova que exige aspas.\r\nAo trabalhar com caracteres específicos dentro de uma variável/tabela, sempre temos que usar aspas.\r\nO R é meio tolerante e tenta ajudar em alguns casos se usamos o formato errado. Mas é importante evitar erros e confusões se possível.\r\n\r\nRecodificação de Variáveis\r\nRecodificação de variáveis é uma habilidade fundamental na preparação de um banco de dados. Vamos ver várias opções para recodificação, mas começamos com o mais flexível. Imagine-se que queremos corrigir alguns dos erros na tabela abaixo:\r\n\r\n\r\nex_recodificar <- tibble(ID=1:3,\r\n                        Mes=c(\"janeiro\",\"february\",\"outubro\"),\r\n                        Ano=c(2013, 2009, 2015))\r\n\r\n\r\n\r\n\r\n\r\n\r\nQueremos renomear ‘february’ ‘fevereiro’ para corrigir o erro de um gringo ignorante. Como? Temos duas tarefas: (i) identificar o caso relevante (e apenas o caso relevante), e (ii) especificar o novo valor. Em geral, quando queremos criar ou modificar uma variável trabalhamos dentro de um mutate(), mas o mutate costuma mudar todos os valores na variável. Aqui, queremos sobreescrever a variável ‘Mes’ com nova informação apenas no caso de ‘february’. Para isso, combinamos mutate() com case_when(), que controla os detalhes de modificação no mutate.\r\ncase_when() funciona com um sintáxe específica: Estabelecemos várias condições (do mesmo tipo que usamos no filter()), e depois de cada uma usamos ‘~’ e em seguida o novo valor para substituir quando esta condição se aplica. Por exemplo, em nosso caso queremos a condição Mes==\"february\" e o novo valor \"fevereiro\". Então precisamos de Mes==\"february\"~\"fevereiro\".\r\n\r\n\r\nex_recodificar %>% mutate(Mes=case_when(Mes==\"february\"~\"fevereiro\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\nQual o resultado? Mudamos o valor para “fevereiro”, está correto, mas apagamos os valores dos outros dois meses. O mutate() realmente muda a coluna inteira, então as condições no case_when() precisam ser completas para todos os valores na nova coluna. Felizmente, existe um atalho para preservar os valores originais caso a condição anterior não seja satisfeita: Usamos uma condição que é sempre satisfeita: a condição literalmente TRUE, e um novo valor que não muda nada; o nome da variável original. Então:\r\n\r\n\r\nex_recodificar %>% mutate(Mes=case_when(Mes==\"february\"~\"fevereiro\",\r\n                                        TRUE~Mes))\r\n\r\n\r\n\r\n\r\n\r\n\r\nAgora está correto. A sintáxe é um pouco específica então não se preocupe se receber uma mensagem de erro, volte para verificar se tem um ~ depois de cada condição, e uma vírgula entre cada recodificação. Também lembre-se que as condições precisam de dois sinais de igual.\r\nVamos recodificar a variável ‘Ano’ usando a mesma lógica, mas agora queremos gerar uma variável binária que identifica todas as observações depois de 2010. Também não queremos sobreescrever a variável original, queremos uma nova variável:\r\n\r\n\r\nex_recodificar %>% mutate(Depois_2010=case_when(Ano>2010~1,\r\n                                                Ano<=2010~0))\r\n\r\n\r\n\r\n\r\n\r\n\r\nÉ importante que as duas condições aqui cubram todos os valores de ‘Ano’ possível.\r\nNote que o case_when() é flexível demais: Podemos usar muitas condições, fazer referência a todas as variáveis na condição, e pegar os dados de todas as variáveis para definir o novo valor. Para ilustrar, veja o exemplo bobagem abaixo:\r\n\r\n\r\nex_recodificar %>% mutate(Nova_Variavel=case_when(Ano>=2014~\"Sim\",\r\n                                                  Ano<2014 & Mes==\"janeiro\"~Mes,\r\n                                                  Ano<2014 & Mes==\"february\"~\"Não\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\nTome cuidado na construção das condições: Idealmente elas devem ser completas e também mutualmente excludentes. Se não, a ordem das condições importa e pode gerar resultados inesperados.\r\n\r\n\r\nExercício 1: Limpando Dados\r\nUsando o banco de dados de flights no pacote nycflights13, responda as seguintes perguntas:\r\nCrie uma data completa numa variável única, com o formato “day-month-year”.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% unite(\"Data\", day, month, year, sep=\"-\")\r\n\r\n\r\nDivida a variável time_hour em duas: uma variável de data e a outra variável de hora.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% separate(time_hour, c(\"data\",\"hora\"), sep=\" \")\r\n\r\n\r\nRecodifique a variável dep_delay para uma variável binária, que seja 1 quando tem atraso, e 0 quando não tem atraso (valores negativos significam decolagens antes do horário previsto).\r\n\r\n\r\nMostrar Código\r\n\r\nflights <- flights %>% \r\n  mutate(dep_delay= case_when( dep_delay>0~1,\r\n                                       dep_delay<=0~0))\r\n\r\n\r\nA companhia aérea US Airways (código ‘US’) se fundiu com American Airlines (código ‘AA’). Recodifique voos de US Airways como voos de American Airlines.\r\n\r\n\r\nMostrar Código\r\n\r\nflights <- flights %>% mutate(carrier=case_when(carrier==\"US\"~\"AA\",\r\n                                     TRUE~carrier))\r\n\r\n\r\n\r\n\r\nOrdenando os nossos dados\r\nAté agora, ignoramos a ordem das observações em nosso banco de dados. A ordem importa por dois motivos. Primeiro, para apresentação de tabelas mais organizadas no documento final. Segundo, para facilitar funções específicas quando as nossas observações têm uma ordem natural.\r\nOrdenar: Arrange\r\nO verbo para ordenar os dados é Arrange(), e podemos especificar uma sequência de variáveis para ser usadas na ordenação. Vamos começar com uns dados desordenados:\r\n\r\n\r\nex_arrange <- tibble(ID=1:10,\r\n                     Ano=c(2008, 2005, 2009, 2006, 2006, 2007, 2008, 2005, 2008, 2005),\r\n                     Mes=c(\"Abril\",\"Novembro\",\"Julho\",\"Março\",\"Novembro\",\"Fevereiro\",\r\n                           \"Junho\",\"Novembro\",\"Janeiro\",\"Outubro\"),\r\n                     Valor=c(750,800,300,500,850,450,600,450,700,350))\r\n\r\n\r\n\r\n\r\n\r\n\r\nSe quisermos as observações em ordem de ano e valor (ignorando mês por enquanto porque vamos explorar isso em mais detalhe abaixo):\r\n\r\n\r\nex_arrange %>% arrange(Ano, Valor)\r\n\r\n\r\n\r\n\r\n\r\n\r\nO resultado é que os dados são ordenados por Ano primeiramente, e dentro de cada Ano, por Valor.\r\nSe quisermos as observações em ordem decrescente, usamos um menos (‘-’) para inverter a ordem, por exemplo, em ordem decrescente de valor:\r\n\r\n\r\nex_arrange %>% arrange(-Valor)\r\n\r\n\r\n\r\n\r\n\r\n\r\nFiltrar para os Maiores/Menores: top_n e top_frac\r\nUm tipo de filter() específico é quando queremos as maiores/menores observações de acordo com uma variável. Se não for um limite absoluto (ex. acima de 140), mas acima de um limite relativo (ex. os cinco maiores), precisamos fazer um ranquemanto e depois filtrar baseado nesse ranqueamento. É possível calcular isso manualmente, mas a maneira mais fácil é usar a função top_n(). Ela exige dois argumentos: o número de observações desejadas, e a variável na qual queremos aplicar o filtro.\r\n\r\n\r\nex_arrange %>% top_n(5, Valor)\r\n\r\n\r\n\r\n\r\n\r\n\r\nPara os menores valores, usamos um menos (‘-’) na frente do número de observações.\r\n\r\n\r\nex_arrange %>% top_n(-5, Valor)\r\n\r\n\r\n\r\n\r\n\r\n\r\nExiste uma função bem parecida que devolve a proporção de observações desejada: top_frac(). Para os maiores 30% de observações, usamos o argumento de 0.3.\r\n\r\n\r\nex_arrange %>% top_frac(0.3, Valor)\r\n\r\n\r\n\r\n\r\n\r\n\r\nDados de Time-Series: lag e lead\r\nCom os nossos dados ordenados, podemos implementar várias técnicas de análise de Time Series (séries temporais). Por exemplo, podemos calcular, para cada observação, o valor de uma variável no período anterior usando lag(). Note que é essencial que os nossos dados já estão ordenados cronologicamente com arrange() antes de executar o lag. Dado que estamos construindo uma nova variável, também é necessário usar lag dentro de mutate:\r\n\r\n\r\nex_arrange %>% arrange(Ano) %>% \r\n  mutate(Valor_anterior=lag(Valor))\r\n\r\n\r\n\r\n\r\n\r\n\r\nUma dificuldade com esta operação é que não existe um valor anterior para a primeira observação - veja que o R insere um NA para o primeiro valor de Valor_anterior. Isso é inevitável, exceto se temos dados mais antigos.\r\nOutra dificuldade é que ainda estamos ignorando a variável mês, então temos janeiro depois de junho em 2008 - não se preocupe, vamos tratar disso em breve.\r\nCom lag, é fácil calcular a diferença entre ‘Valor’ e ‘Valor_anterior’ para focar em mudanças ao longo do tempo na variável:\r\n\r\n\r\nex_arrange %>% arrange(Ano) %>% \r\n  mutate(Valor_anterior=lag(Valor),\r\n         Valor_diferenca=Valor-Valor_anterior)\r\n\r\n\r\n\r\n\r\n\r\n\r\nA operação de lead() é equivalente, mas traz o valor subsequente.\r\n\r\n\r\nex_arrange %>% arrange(Ano) %>% \r\n  mutate(Valor_posterior=lead(Valor))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nExercício 2: Ordenação\r\nUse de novo o banco de dados flights:\r\nOrdene o banco de dados da menor à maior duração (air_time), incluindo apenas os voos com destino de Anchorage (ANC).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(dest==\"ANC\") %>%\r\n  arrange(air_time)\r\n\r\n\r\nIdentifique o voo mais atrasado (dep_delay) entre LaGuardia (LGA) e Atlanta (ATL). Quão atrasado foi o voo?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin==\"LGA\" & dest==\"ATL\") %>%\r\n  top_n(1,dep_delay)\r\n\r\n\r\nCalcule a velocidade de cada voo, e selecione os três voos mais rápidos. Eles partiram de qual aeroporto para qual destino?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% \r\n  mutate(velocidade = distance/\r\n                     air_time) %>% \r\n  top_n(3, velocidade) %>%\r\n  select(velocidade, origin, dest)\r\n\r\n\r\nPara os voos com destino em Anchorage (ANC), verifique que eles são ordenados cronologicamente (por year, month, day, e dep_time) e gera uma nova variável com a duração (air_time) do voo anterior. Agora, compare a duração de cada voo com a duração do voo anterior.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(dest==\"ANC\") %>%\r\n  arrange(year, month, day, dep_time) %>% \r\n  mutate(air_time_anterior=lag(air_time),\r\n         air_time_anterior_dif=air_time-air_time_anterior)\r\n\r\n\r\n\r\n\r\nFactors\r\nAlém de números, caracteres e lógicos (TRUE/FALSE), o tipo de dado mais útil para análise de dados é um ‘factor’. Factors são variáveis que podem assumir um número de valores limitados e pré-definidos (normalmente strings de texto). Pense em variáveis categóricas, nominais, ordinais etc. Factors nos ajudam a evitar erros e refletir a estrutura correta das nossas variáveis, mas elas exigem uma disciplina e um cuidado por nosso lado.\r\nPor exemplo, lembre-se do problema quando o nosso banco de dados incluiu “february” em vez de “fevereiro”? Este problema é impossível com uma variável do tipo factor, pois definimos do início os valores aceitáveis num formato padrão - os ‘levels’ do factor. Vamos recriar o tibble ‘ex_arrange’ de acima, mas agora especificamos o mês como uma variável factor, com os ‘levels’ permitidos pela natureza da variável:\r\n\r\n\r\nex_arrange <- tibble(ID=1:10,\r\n                     Ano=c(2008, 2005, 2009, 2006, 2006, 2007, 2008, 2005, 2008, 2005),\r\n                     Mes=factor(c(\"Abril\",\"Novembro\",\"Julho\",\"Março\",\"Novembro\",\"February\",\"Junho\",\"Novembro\",\"Janeiro\",\"Outubro\"),\r\n                                levels=c(\"Janeiro\",\"Fevereiro\",\"Março\",\"Abril\",\"Maio\",\r\n                                         \"Junho\",\"Julho\",\"Agosto\",\"Setembro\",\"Outubro\",\r\n                                         \"Novembro\",\"Dezembro\")),\r\n                     Valor=c(750,800,300,500,850,450,600,450,700,350))\r\n\r\n\r\n\r\n\r\n\r\n\r\nBem mais trabalhoso, não?? Mas vale a pena: veja a tabela que isso produziu - em lugar de “February” o R colocou NA porque “February” não está na lista de levels que delimitamos no argumento ‘levels’. Isso impede que a nossa variável tome valores impossíveis, deixando a nossa análise subsequente mais confiável. Lembre-se de incluir todos os valores possíveis nos ‘levels’ para evitar problemas futuros. Por exemplo temos ‘Maio’ na lista de levels mesmo que ele não exista nos dados atuais.\r\nO código acima mostra como criar variáveis de tipo factor num novo banco de dados. É comum já termos um banco de dados com uma variável de tipo caractere, e querermos transformá-la em factor. Vamos criar o mesmo banco de dados de novo, mas sem especificar o mês como factor, e depois aplicar a transformação dentro de mutate.\r\n\r\n\r\nex_arrange <- tibble(ID=1:10,\r\n                     Ano=c(2008, 2005, 2009, 2006, 2006, 2007, 2008, 2005, 2008, 2005),\r\n                     Mes=c(\"Abril\",\"Novembro\",\"Julho\",\"Março\",\"Novembro\",\"February\",\"Junho\",\"Novembro\",\"Janeiro\",\"Outubro\"),\r\n                     Valor=c(750,800,300,500,850,450,600,450,700,350))\r\n\r\n\r\n\r\n\r\nex_arrange <- ex_arrange %>% mutate(Mes=factor(Mes))\r\n\r\n\r\nNote que aqui não temos que especificar os ‘levels’ do factor - o R usa os valores atuais para preencher os levels. Podemos fazer assim, mas lembre-se que os levels não incluem todos os meses, o que pode gerar problemas no futuro se quisermos adicionar mais dados.\r\nPara permitir todos os doze meses desde o início, temos que especificar os levels explicitamente:\r\n\r\n\r\nex_arrange <- tibble(ID=1:10,\r\n                     Ano=c(2008, 2005, 2009, 2006, 2006, 2007, 2008, 2005, 2008, 2005),\r\n                     Mes=c(\"Abril\",\"Novembro\",\"Julho\",\"Março\",\"Novembro\",\"February\",\"Junho\",\"Novembro\",\"Janeiro\",\"Outubro\"),\r\n                     Valor=c(750,800,300,500,850,450,600,450,700,350))\r\n\r\nex_arrange <- ex_arrange %>% \r\n  mutate(Mes=factor(Mes,\r\n                    levels=c(\"Janeiro\",\"Fevereiro\",\"Março\",\"Abril\",\"Maio\",\"Junho\",\r\n                             \"Julho\",\"Agosto\",\"Setembro\",\"Outubro\",\"Novembro\",\r\n                             \"Dezembro\")))\r\n\r\n\r\nFactors Ordenados\r\nExistem mais duas vantagens em trabalhar com Factors. Primeiro, é que podemos especificar uma ordem para a variável mesmo para variáveis que contém caracteres. Meses, por exemplo,\r\nsão ordenados, mas não conseguimos usar na seção anterior para ordenação porque o R não entende automaticamente a ordem de “Janeiro”,“Fevereiro”. Na verdade, o R entendo que a ordem de caracteres é alfabética, que não faz sentido para a variável de mês. Dentro de factor, podemos especificar ordered=TRUE para definir a ordem dos valores na sequência que eles aparecem no vetor levels():\r\n\r\n\r\nex_arrange <- tibble(ID=1:10,\r\n                     Ano=c(2008, 2005, 2009, 2006, 2006, 2007, 2008, 2005, 2008, 2005),\r\n                     Mes=factor(c(\"Abril\",\"Novembro\",\"Julho\",\"Março\",\"Novembro\",\"Fevereiro\",\"Junho\",\"Novembro\",\"Janeiro\",\"Outubro\"),\r\n                                levels=c(\"Janeiro\",\"Fevereiro\",\"Março\",\"Abril\",\"Maio\",\r\n                                         \"Junho\",\"Julho\",\"Agosto\",\"Setembro\",\"Outubro\",\r\n                                         \"Novembro\",\"Dezembro\"),\r\n                                ordered=T),\r\n                     Valor=c(750,800,300,500,850,450,600,450,700,350))\r\n\r\n\r\nAgora, podemos ordenar os dados por Ano e Mês:\r\n\r\n\r\nex_arrange %>% arrange(Ano, Mes)\r\n\r\n\r\n\r\n\r\n\r\n\r\nCompletando Bancos de Dados Parciais: complete\r\nA segunda vantagem de trabalhar com factors é que um factor deixa fácil preencher os valores ausentes da variável. Por exemplo, os nossos cálculos de lag, lead e diferença acima não fazem muito sentido - comparamos por exemplo o valor de Junho com o valor de Abril, pulando Maio porque ele não aparece no banco de dados originais. Então o nosso cálculo de lag é inconsistente; um lag de um mês em alguns casos, dois meses em outros, 9 meses em outros. Um cálculo consistente e confiável tem que refletir os dados ausentes explicitamente.\r\nPodemos criar uma sequência completa facilmente se as variáveis originais foram criados corretamente como factors: Usamos o verbo complete() para preencher as variáveis:\r\n\r\n\r\nex_arrange %>% complete(Ano, Mes)\r\n\r\n\r\n\r\n\r\n\r\n\r\nVeja o resultado: Temos os 12 meses para cada um dos cinco anos, um banco de dados completo (e uma linha duplicada para Novembro 2005). A maioria dos valores são desconhecidos, NA, porque não aparecem no banco de dados original, mas tudo bem, pelo menos entendemos onde temos dados e onde não, e não criamos lags e leads enganosos.\r\nNote para o futuro que é possível especificar o valor que o complete usa para preencher observações ausentes. Por exemplo, pode ser que o ‘valor’ nos dados reflita vendas e que saibamos que não houve vendas nos meses ausentes do banco de dados. Neste caso, faz sentido preencher as observações dos outros meses com zero usando o argumento fill:\r\n\r\n\r\nex_arrange %>% complete(Ano, Mes, fill=list(Valor=0))\r\n\r\n\r\n\r\n\r\n\r\n\r\nEsta capacidade também ajudará muito na construção de gráficos em tutoriais futuros: Valores podem desaparecer da legenda, e cores podem ficar inconsistentes entre gráficos se não mantivermos estáveis os levels do factor, então é importante aprender como a trabalhar com eles do início.\r\n\r\nHabilidade Básica de Programação: Dados Ausentes, NA\r\nMuitos problemas e erros são gerados pelo tratamento inapropriado de dados ausentes. Vamos revisar isto várias vezes, mas por enquanto temos que reconhecer que NA é um pedaço de informação importante que não podemos ignorar. Jogar fora os dados ausentes significa perder muitas observações potenciais, o que pode gerar um viés de seleção em nossa análise. Então é sempre importante deixar os NAs explícitos.\r\nPor outro lado, um NA é ambíguo e pode significar duas coisas diferentes:\r\n(i) Um NA ‘estrutural’ que é impossível medir. Por exemplo, o PIB do Estado do Tocantins em 1970 (o estado foi criado apenas em 1988).\r\n(ii) Um NA que podia ter sido medido, mas por algum motivo não foi. Por exemplo, faltamos dados de 2014 porque os arquivos foram perdidos em um incêndio.\r\nO tipo de NA vai afetar a nossa interpretação e tratamento de dados.\r\nTrabalhando com dados NA exige algumas regras específicas. Para testar se um valor é NA, não podemos usar o padrão x==\"NA\". Temos que usar is.na(x), uma função dedicada para testar se um valor é NA ou não.\r\nSe quisemos criar valores NA, temos que usar uma versão apropriada para o tipo de dado da variável: existe NA_character_, NA_real_ e NA_integer_. Para subtituir NA com outro valor, use a função replace_na(). Todos são demonstrados no exemplo abaixo.\r\n\r\n\r\nex_arrange %>% complete(Ano, Mes, fill=list(Valor=0)) %>%\r\n  mutate(ID_NA=case_when(is.na(ID)~1,\r\n                         TRUE~0),\r\n         Valor=case_when(Valor==0~NA_real_,\r\n                          TRUE~Valor),\r\n         ID=replace_na(ID, 999))\r\n\r\n\r\n\r\nRecodificação de levels de Factors\r\nUm desafio em trabalhar com Factors é que eles exigem funções específicas para recodificação dos seus levels. Existe um pacote inteiro para isso, que se chama forcats e é parte do tidyverse.\r\nExistem três funções super-úteis para trabalhar com factors, todas que começam com fct_, e usamos todas dentro de um mutate(), dado que estamos mexendo com uma coluna que já existe.\r\nPrimeiro, quando queremos renomear os levels de um factor, usamos fct_recode. Por exemplo:\r\n\r\n\r\nex_arrange %>% mutate(Mes=fct_recode(Mes,\r\n                                     \"abril\"=\"Abril\",\r\n                                     \"junho\"=\"Junho\"))\r\n\r\n\r\n\r\n\r\n\r\n\r\nSegundo, quando queremos ajustar a ordem de um factor ordenado, usamos fct_relevel. Por exemplo, para inverter a ordem do mês:\r\n\r\n\r\nex_arrange %>% mutate(Mes=fct_relevel(Mes,\r\n                                     c(\"Dezembro\",\"Novembro\",\"Outubro\",\"Setembro\",\r\n                                       \"Agosto\",\"Julho\",\"Junho\",\"Maio\",\"Abril\",\r\n                                       \"Março\",\"Fevereiro\",\"Janeiro\"))) %>%\r\n  arrange(Ano, Mes)\r\n\r\n\r\n\r\n\r\n\r\n\r\nTerceiro, quando queremos reestruturar/simplificar o factor para menos níveis, usamos fct_collapse. Por exemplo, podemos juntar os primeiros três meses e descrever como o primeiro quarto do ano, ‘Q1’:\r\n\r\n\r\nex_arrange %>% mutate(Mes=fct_collapse(Mes,\"Q1\"=c(\"Janeiro\",\"Fevereiro\",\"Março\")))\r\n\r\n\r\n\r\n\r\n\r\n\r\nMais detalhes no cheatsheet de forcats aqui.\r\n\r\n\r\nExercício 3: Factors\r\nUsando os dados de flights de novo:\r\nTransforme a variável origin para um factor (não-ordenado).\r\n\r\n\r\nMostrar Código\r\n\r\nflights <- flights %>% mutate(origin=factor(origin))\r\n\r\n\r\nSalve o resultado de (1) e tente-se usar o novo banco de dados para recodificar o aeroporto de origem “EWR” para “Newark” usando case_when dentro de mutate. É possível?\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% mutate(origin=case_when(origin==\"EWR\"~\"Newark\",\r\n                                    TRUE~origin))\r\n\r\n\r\nUsando as funções dedicadas do pacote forcats, recodifique o factor origin para os nomes completos dos aeroportos (Newark, John F Kennedy e LaGuardia).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% mutate(origin = fct_recode( origin,  \r\n                                     \"Newark\"=\"EWR\", \r\n                                     \"John F Kennedy\"=\"JFK\", \r\n                                    \"LaGuardia\"=\"LGA\"))\r\n\r\n\r\nTransforme a variável month para um factor ordenado.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% mutate(month=factor(month, levels=1:12, ordered=T))\r\n\r\n\r\n\r\n\r\nIdentificando Casos/Valores Únicos (distinct)\r\nQuais valores existem em nosso banco de dados? Em uma variável de 1.000 linhas, quais valores únicos existem? As nossas observações são duplicadas?\r\nComeçando com um tibble, podemos pedir os valores/casos únicos que existem no banco de dados usando o verbo distinct(). Nos parênteses, especificamos quais variáveis queremos avaliar. Se especificarmos uma variável, recebemos todos os valores que existem no banco de dados para esta variável:\r\n\r\n\r\nflights %>% distinct(origin)\r\n\r\n\r\n\r\n\r\n\r\n\r\nCom mais de uma variável, identificamos os conjuntos que existem no banco de dados. Por exemplo, imaginar que queremos saber quais companhias aéreas voam de quais aeroportos (com a ajuda de arrange para organizar o resultado):\r\n\r\n\r\nflights %>% distinct(origin, carrier) %>%\r\n  arrange(origin, carrier)\r\n\r\n\r\n\r\n\r\n\r\n\r\nFinalmente, distinct nos ajuda a entender melhor a unidade de análise no banco de dados, e a presença de observações/informações duplicadas que podem indicar erros ou contaminar análises subsequentes. Por exemplo, em teoria deve ser impossível ter mais de um voo no mesmo horário, com o mesmo número da mesma companhia, da mesma origem ao mesmo destino. Podemos confirmar isso observando que o número de linhas na seguinte operação é igual ao número de linhas no banco de dados inteiro:\r\n\r\n\r\nflights %>% distinct(year, month, day, dep_time, carrier, flight, origin, dest)\r\n\r\n\r\nOs aviões são também identificados por um número de cauda (tailnum), e imaginando que o tailnum seja único para cada avião, parece razoável assumir que o mesmo avião não está voando no mesmo horário mais que uma vez:\r\n\r\n\r\nflights %>% distinct(year, month, day, dep_time, tailnum)\r\n\r\n\r\nRepare, o número de linhas aqui é 334.067, menos do 336.776 no banco de dados inteiro. Isso significa que temos mais que um tailnum decolando no mesmo horário…Estranho. É crucial saber isso para informar as nossas análises. Com mais investigação, entenderemos que a diferença é produzida pela presença de observações de dep_time e tailnum que são NA, desconhecidos, e portanto aparecem como duplicados.\r\n\r\nLeitura para Tutorial 4\r\nAntes da próxima aula, por favor leia R 4 Data Science, Capítulos 17, 18 e 19-19.3\r\n\r\n\r\n\r\nDesafio 1\r\nÉ mais ou menos fácil seguir um tutorial passo a passo. O teste real do nosso entendimento é quando temos que trabalhar com um novo banco de dados sem instrução. O Desafio 1 teste a sua capacidade de abrir, manipular e limpar um banco de dados para produzir um relatório bonito e claro em HTML.\r\nO prazo para entregar Desafio 1 por email à minha conta é 19/05/2022. Por favor entregue (i) o arquivo .Rmd, e (ii) o arquivo .html.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:19:11-03:00"
    },
    {
      "path": "Mapas.html",
      "title": "Mapas e Análises Espaciais",
      "author": [],
      "contents": "\r\n\r\nContents\r\nDados Espaciais\r\nTrabalhando com Polígonos\r\nAperfeiçoando a Visualização dos mapas\r\nGeoreferenciamento\r\nJoins Não-Espaciais\r\nJoins Espaciais\r\nRasters\r\n\r\nDados Espaciais\r\nDados espaciais são dados organizados por localização e permitem novos tipos de análise e visualização. Explorar mapas em R nos permite praticar e estender muitas das ferramentas que aprendemos nas últimas semanas - manipulação de dados, joins e gráficos.\r\nO que diferencia dados espaciais de outros tipos de dados? Dados espaciais contém variáveis que identificam a localização de cada ponto no mundo, como a latitude e a longitude: 13 \\(^\\circ\\) 26’ 22” N, 17 \\(^\\circ\\) 8’ 21” E. Estes valores nos permitem localizar um ponto no mundo, comparar com outros pontos, e visualizar os pontos num mapa de duas dimensões.\r\nLembre-se do nosso tibble de airports do tutorial passado? Ele contém a localização dos aeroportos nos Estados Unidos nas colunas ‘lat’ e ‘lon’. Como podemos analisar estes dados espaciais?\r\n\r\n\r\nlibrary(\"tidyverse\")\r\nlibrary(\"tidylog\")\r\nlibrary(\"nycflights13\")\r\n\r\n\r\n\r\n\r\nairports\r\n\r\n\r\n\r\n\r\n\r\n\r\nPara analisar estes dados como dados espaciais precisamos dizer ao R quais são as variáveis de localização. Isto exige uma nova biblioteca: sf, acrônimo para ‘simple features’, o nosso objeto espacial. Também recomendo instalar mais dois pacotes:\r\n\r\n\r\n#install.packages(\"sf\")\r\n#install.packages(\"lwgeom\")\r\n#install.packages(\"rgdal\")\r\n\r\nlibrary(\"sf\")\r\n\r\n\r\nO sf traz mais poder para os nossos tibbles, permitindo eles entenderem dados espaciais. Para facilitar, todas as nossas operações com dados espaciais começam com st_ (e não sf…absurdamente). Só temos que indicar para o R quais variáveis do tibble original são a longitude e a latitude das observações, usando a função st_as_sf(). O argumento coords= aceita um vetor com os nomes das duas colunas, longitude e latitude (nesta ordem, pois longitude é o eixo X e latitude é o eixo Y - se pensarmos nas coordenadas como pontos cartesianos).\r\n\r\n\r\nairports_test <- airports %>% st_as_sf(coords=c(\"lon\",\"lat\"))\r\n\r\n\r\nComo fica o nosso tibble airports_test agora? Abra o tibble para ver. Parece quase igual…e isso é importante - dados espaciais não são muito diferentes de outros dados; eles ainda ficam armazenados num tibble. Cada observação tem várias colunas de dados não-espaciais (‘faa’, ‘name’ etc.). Mas agora há uma nova coluna também, geometry. Ela codifica os dados de longitude e latitude num formato mais complexo que facilita operações e visualizações espaciais. Veja que o valor de cada observação da geometry é o par longitude-latitude e o tipo de dado espacial é um ponto, <POINT>, (vamos ver alternativas em breve).\r\n\r\n\r\nairports_test\r\n\r\nSimple feature collection with 1458 features and 6 fields\r\nGeometry type: POINT\r\nDimension:     XY\r\nBounding box:  xmin: -176.646 ymin: 19.72137 xmax: 174.1136 ymax: 72.27083\r\nCRS:           NA\r\n# A tibble: 1,458 × 7\r\n   faa   name          alt    tz dst   tzone             geometry\r\n   <chr> <chr>       <dbl> <dbl> <chr> <chr>              <POINT>\r\n 1 04G   Lansdowne …  1044    -5 A     Amer… (-80.61958 41.13047)\r\n 2 06A   Moton Fiel…   264    -6 A     Amer… (-85.68003 32.46057)\r\n 3 06C   Schaumburg…   801    -6 A     Amer… (-88.10124 41.98934)\r\n 4 06N   Randall Ai…   523    -5 A     Amer… (-74.39156 41.43191)\r\n 5 09J   Jekyll Isl…    11    -5 A     Amer… (-81.42778 31.07447)\r\n 6 0A9   Elizabetht…  1593    -5 A     Amer… (-82.17342 36.37122)\r\n 7 0G6   Williams C…   730    -5 A     Amer… (-84.50678 41.46731)\r\n 8 0G7   Finger Lak…   492    -5 A     Amer… (-76.78123 42.88356)\r\n 9 0P2   Shoestring…  1000    -5 U     Amer… (-76.64719 39.79482)\r\n10 0S9   Jefferson …   108    -8 A     Amer… (-122.8106 48.05381)\r\n# ℹ 1,448 more rows\r\n\r\nVerifique o tipo do objeto airports_test:\r\n\r\n\r\nclass(airports_test)\r\n\r\n[1] \"sf\"         \"tbl_df\"     \"tbl\"        \"data.frame\"\r\n\r\nTemos vários resultados aqui - é um objeto ‘simple features’, mas também um tbl (tibble) e data.frame! Isso significa que podemos aplicar todas as funções do tidyverse com dados espaciais também.\r\nO que podemos fazer com o nosso tibble de airports_test extra-poderoso e espacialmente-habilitada? Muitas coisas, e vamos ver as possibilidades abaixo, mas por enquanto, vamos visualizar os nossos dados num mapa simples. A nossa gramática de gráficos ggplot() facilita a visualização de dados espaciais no formato bem conhecido, com uma geometria específica: geom_sf(), e graças a muito trabalho de pessoas desconhecidas, não precisamos especificar nenhum argumento:\r\n\r\n\r\nairports_test %>% ggplot() +\r\n  geom_sf()\r\n\r\n\r\n\r\nÉ isso mesmo. você já criou o seu primeiro mapa, parabéns! O que está acontecendo no seu gráfico, você consegue interpretar? Veja que o eixo x mostra os valores de longitude, e o eixo y os valores de latitude. Aparece um ponto (a ‘geometria’) em cada lugar apropriado. Na esquerda (no oeste) do mapa os pontos geram a forma dos Estados Unidos, com alguns pontos espalhados no leste.\r\nA beleza de trabalhar com dados espaciais em nosso formato padrão de um tibble é que podemos aplicar todas as nossas ferramentas normais para transformar e preparar os dados. Por exemplo, vamos limitar o escopo dos dados para os fusos horários (o timezone, tz) dos Estados Unidos continental (e tirando alguns aeroportos específicos mal-codificados).\r\n\r\n\r\nairports_test <- airports_test %>% filter(tz<0 & !(faa %in% c(\"EEN\", \"SYA\")))\r\n\r\nairports_test %>% \r\n  ggplot() +\r\n  geom_sf()\r\n\r\n\r\nFaz mais sentido agora, certo?\r\nSistemas de Coordenadas\r\nO mapa que geramos acima é apenas uma das milhares de formas de apresentar os mesmos lugares num mapa. E todos são igualmente corretos. E todos são igualmente incorretos. Não existe uma representação única e correta de dados espaciais na sua tela.\r\nPor quê? Porque o mundo não é plano. E representar locais que existem numa esfera (na verdade, uma esferóide oblato) em papel ou na sua tela em duas dimensões não tem uma solução única. Existem milhares de possibilidades de como transformar um objeto de três dimensões para duas, e esse processo sempre gera algum tipo de distorção. Algumas das transformações têm nomes conhecidos, como ‘Mercator’ ou ‘Robinson’, cada um representando um ‘sistema de coordenadas’ (CRS, Coordinate Reference System).\r\nO CRS pode parecer complicado, mas não se preocupe, não precisamos entender os detalhes. Só temos que verificar três coisas:\r\n1. Saber o CRS dos nossos dados brutos. Mesmo que o padrão seja salvar dados espaciais com longitude e latitude, às vezes, eles se apresentam em outro formato. É comum também haver outros detalhes para especificar para interpretar a longitude e a latitude, como quão ‘esmagada’ é o mundo de uma esfera perfeita.\r\nEntão deveríamos ter gerado o banco espacial de airports especificando o CRS dos dados no arquivo, com o argumento de CRS:\r\n\r\n\r\n\r\n\r\n\r\nairports <- airports %>% st_as_sf(coords=c(\"lon\",\"lat\"), \r\n                                  crs=4326) %>% \r\n  filter(tz<0 & !(faa %in% c(\"EEN\", \"SYA\")))\r\n\r\n\r\nPor que ‘4326’? Idealmente, deveríamos confirmar com o fornecedor dos dados o CRS em que eles foram salvos. Aqui, como a longitude e a latitude parecem estar em graus (entre -180 e 180) é provável que devemos usar o sistema “WGS84” (um sistema de coordenadas geográficas (não projetadas)). Um atalho para especificar o WGS84 é usar o numero 4326 (tecnicamente, o número ‘epsg’) no argumento crs. Para verificar outros atalhos para sistemas de coordenados, pode aproveitar do site http://epsg.io/.\r\nAbre o airports e vai aparecer uma linha de CRS agora na descrição acima da tabela:\r\n\r\n\r\nairports\r\n\r\nSimple feature collection with 1454 features and 6 fields\r\nGeometry type: POINT\r\nDimension:     XY\r\nBounding box:  xmin: -176.646 ymin: 19.72137 xmax: -67.01269 ymax: 71.28545\r\nGeodetic CRS:  WGS 84\r\n# A tibble: 1,454 × 7\r\n   faa   name          alt    tz dst   tzone             geometry\r\n * <chr> <chr>       <dbl> <dbl> <chr> <chr>          <POINT [°]>\r\n 1 04G   Lansdowne …  1044    -5 A     Amer… (-80.61958 41.13047)\r\n 2 06A   Moton Fiel…   264    -6 A     Amer… (-85.68003 32.46057)\r\n 3 06C   Schaumburg…   801    -6 A     Amer… (-88.10124 41.98934)\r\n 4 06N   Randall Ai…   523    -5 A     Amer… (-74.39156 41.43191)\r\n 5 09J   Jekyll Isl…    11    -5 A     Amer… (-81.42778 31.07447)\r\n 6 0A9   Elizabetht…  1593    -5 A     Amer… (-82.17342 36.37122)\r\n 7 0G6   Williams C…   730    -5 A     Amer… (-84.50678 41.46731)\r\n 8 0G7   Finger Lak…   492    -5 A     Amer… (-76.78123 42.88356)\r\n 9 0P2   Shoestring…  1000    -5 U     Amer… (-76.64719 39.79482)\r\n10 0S9   Jefferson …   108    -8 A     Amer… (-122.8106 48.05381)\r\n# ℹ 1,444 more rows\r\n\r\n2. Escolher o CRS em que queremos visualizar os nossos dados. Quando chamamos geom_sf, ele usa o CRS definido em nosso tibble. Mas em qualquer momento podemos transformar o CRS atual para um alternativo, por exemplo um CRS que melhor representa um lugar específico no mundo. Usamos st_transform() em nosso pipe de trabalho para alterar o CRS, especificando o novo número da projeção desejada.\r\nPor exemplo, a projeção Mercator tem número 3857:\r\n\r\n\r\nairports %>% st_transform(3857) %>%\r\n  ggplot() +\r\n  geom_sf()\r\n\r\n\r\n\r\nUma projeçõ focada nos Estados Unidos, 3751:\r\n\r\n\r\nairports %>% st_transform(3751) %>%\r\n  ggplot() +\r\n  geom_sf()\r\n\r\n\r\n\r\n3. Que todas as camadas da nossa análise/visualização usem a mesma projeção. Na mesma forma que não podemos comparar kilometros e milhas diretamente, seria errado comparar dados em CRS diferentes. O mesmo local vai aparece em posições diferentes. Temos que usar st_transform() para padronizar camadas múltiplas antes de visualização.\r\nCalculando Distâncias\r\nO CRS é especialmente relevante quando precisamos calcular distâncias de observações espaciais. O CRS 4326 é geográfico (sem projeção, em três dimensões) então a unidade de distância segue a curvatura do mundo, e reflete o ‘Great Circle Distance’.\r\nEm contraste, quando usamos st_transform() e apontamos um CRS diferente e projetado, os locais ficam num plano de duas dimensões e as medidas de distância são linhas retas, ‘Euclidean Distance’.\r\nHá muitas possibilidades para calcular distâncias, mas vamos usar uma função simples para calcular a distância entre todos os aeroportos, st_distance(). Ela não precisa de nenhum argumento, mas vamos pegar uma amostra aleatória de 10 aeroportos primeiramente para não sobrecarregar os nossos computadores e deixar o resultado mais simples de interpretar:\r\nDependendo do seu sistema, pode ser necessário instalar o pacote lwgeom antes de usar st_distance(). Se o R reclamar para rodar o código aqui, use install.packages(\"lwgeom\") e library(\"lwgeom\").\r\n\r\n\r\nairports %>% sample_n(10) %>% \r\n  st_distance()\r\n\r\n\r\n\r\nUnits: [m]\r\n           [,1]      [,2]    [,3]      [,4]    [,5]      [,6]    [,7]\r\n [1,]       0.0  554538.1 4798793 1913888.0 1205965 2318248.7 1563995\r\n [2,]  554538.1       0.0 4763157 2355346.3 1758205 2714593.3 1031577\r\n [3,] 4798792.7 4763157.1       0 6328121.1 4920272 6802931.2 4476927\r\n [4,] 1913888.0 2355346.3 6328121       0.0 1418429  475124.5 3367940\r\n [5,] 1205964.8 1758205.3 4920272 1418429.2       0 1892554.9 2730290\r\n [6,] 2318248.7 2714593.3 6802931  475124.5 1892555       0.0 3698379\r\n [7,] 1563995.0 1031577.2 4476927 3367940.0 2730290 3698378.8       0\r\n [8,]  393819.1  792451.8 5178362 1568659.5 1160062 1949778.2 1820289\r\n [9,] 1073067.8  878276.7 3886690 2969039.7 1961064 3387124.4 1039313\r\n[10,] 2200222.7 2752509.7 5600410 1283901.3 1050086 1629985.1 3756376\r\n           [,8]      [,9]   [,10]\r\n [1,]  393819.1 1073067.8 2200223\r\n [2,]  792451.8  878276.7 2752510\r\n [3,] 5178362.4 3886689.9 5600410\r\n [4,] 1568659.5 2969039.7 1283901\r\n [5,] 1160062.2 1961064.5 1050086\r\n [6,] 1949778.2 3387124.4 1629985\r\n [7,] 1820288.6 1039313.3 3756376\r\n [8,]       0.0 1459591.2 2043639\r\n [9,] 1459591.2       0.0 3009856\r\n[10,] 2043639.0 3009855.7       0\r\n\r\nO resultado é uma ‘matriz’ (um tibble com apenas números), com a unidade da mensuração em metros, especificada no início (‘Units: [m]’). Como lemos o resultado? Entre os aeroportos 1 e 2 há uma distância de 554.538,1 metros, ou 555km. (Se quiser, pode transformar a matriz em um tibble com ...%>% as_tibble()).\r\nObserve que usando uma projeção diferente gera um resultado diferente, de 702.038,3 metros:\r\n\r\n\r\nset.seed(3)\r\nairports %>% st_transform(3751) %>% \r\n  sample_n(10) %>% \r\n  st_distance()\r\n\r\n\r\n\r\nUnits: [m]\r\n           1         2       3         4       5         6       7\r\n1        0.0  702038.3 5213125 2842651.6 1598134 3614011.7 1893157\r\n2   702038.3       0.0 5114472 3430466.2 2288940 4146583.9 1228230\r\n3  5213124.6 5114472.3       0 7585593.3 5442296 8456120.2 4673834\r\n4  2842651.6 3430466.2 7585593       0.0 2165714  873406.6 4653090\r\n5  1598134.1 2288940.5 5442296 2165714.2       0 3038716.4 3393833\r\n6  3614011.7 4146583.9 8456120  873406.6 3038716       0.0 5346662\r\n7  1893157.1 1228230.3 4673834 4653089.6 3393833 5346662.4       0\r\n8   520013.0 1029592.3 5722683 2402063.8 1577330 3137347.2 2256405\r\n9  1302056.7 1046320.4 4068152 4108065.6 2443465 4903992.9 1188353\r\n10 3066120.6 3766750.3 6400684 2073004.6 1502381 2772431.3 4895375\r\n         8       9      10\r\n1   520013 1302057 3066121\r\n2  1029592 1046320 3766750\r\n3  5722683 4068152 6400684\r\n4  2402064 4108066 2073005\r\n5  1577330 2443465 1502381\r\n6  3137347 4903993 2772431\r\n7  2256405 1188353 4895375\r\n8        0 1812885 2929667\r\n9  1812885       0 3925697\r\n10 2929667 3925697       0\r\n\r\nPara calcular a distância de apenas um aeroporto para os outros, temos que separar um aeroporto de origem, por exemplo o JFK em Nova Iorque. Observe que agora podemos inserir o nosso cálculo espacial de st_distance dentro da função mutate que usamos para gerar novas colunas. Para indicar que queremos calcular a distância entre todos os aeroportos e JFK, usamos um ponto . para se referir ao banco de dados inicial na esquerda do pipe, e o objeto JFK, respectivamente. Qual é o resultado? É o tibble espacial de airports com a distância para JFK em uma nova coluna, pronto para mais análise! Pode verificar no tibble quanto é a distância de JFK a JFK?\r\n\r\n\r\nJFK <- airports %>% filter(faa==\"JFK\")\r\n\r\nairports %>% mutate(distancia_para_JFK=st_distance(., JFK))\r\n\r\n\r\n\r\nExercício 1: Mapas de Pontos\r\nCrie um objeto de simple features (sf) com os seguintes dados. Os valores de longitude e latitude são brutos em CRS 4326.\r\n\r\n\r\ncidades <- tibble(Cidade=c(\"Paris\", \"London\", \"Istanbul\", \"Madrid\", \"Berlin\"),\r\n                  Pais=c(\"France\", \"United Kingdom\", \"Turkey\", \"Spain\", \"Germany\"),\r\n                   População=c(12006868, 11984435, 11400000, 6633278, 5142247),\r\n                   Long=c(2.352552, -0.128285, 28.976636, -3.708597, 13.402067),\r\n                   Lat=c(48.857708, 51.507237, 41.007992, 40.411673, 52.520133))\r\n\r\n\r\n\r\n\r\nCidade\r\n\r\n\r\nPais\r\n\r\n\r\nPopulação\r\n\r\n\r\nLong\r\n\r\n\r\nLat\r\n\r\n\r\nParis\r\n\r\n\r\nFrance\r\n\r\n\r\n12006868\r\n\r\n\r\n2.352552\r\n\r\n\r\n48.85771\r\n\r\n\r\nLondon\r\n\r\n\r\nUnited Kingdom\r\n\r\n\r\n11984435\r\n\r\n\r\n-0.128285\r\n\r\n\r\n51.50724\r\n\r\n\r\nIstanbul\r\n\r\n\r\nTurkey\r\n\r\n\r\n11400000\r\n\r\n\r\n28.976636\r\n\r\n\r\n41.00799\r\n\r\n\r\nMadrid\r\n\r\n\r\nSpain\r\n\r\n\r\n6633278\r\n\r\n\r\n-3.708597\r\n\r\n\r\n40.41167\r\n\r\n\r\nBerlin\r\n\r\n\r\nGermany\r\n\r\n\r\n5142247\r\n\r\n\r\n13.402067\r\n\r\n\r\n52.52013\r\n\r\n\r\n\r\n\r\nMostrar Código\r\n\r\ncidades <- cidades %>% st_as_sf(coords=c(\"Long\",\"Lat\"), \r\n                                  crs=4326, \r\n                                  remove=F)\r\n\r\n\r\nElabore um mapa simples para visualizar os seus dados com ggplot(), com uma cor diferente para cada ponto baseado na variável População.\r\n\r\n\r\nMostrar Código\r\n\r\ncidades %>% ggplot() +\r\n  geom_sf(aes(colour=População)) +\r\n  theme_minimal()\r\n\r\n\r\nQuando estiver criando o seu objeto sf, pode usar o argumento remove=FALSE para preservar as colunas de longitude e latitude explicitamente. Use essas duas colunas para adicionar mais uma camada de geometria (geom_text()) que imprime os rótulos dos nomes das cidades ao seu mapa.\r\n\r\n\r\nMostrar Código\r\n\r\ncidades %>% \r\n  ggplot() +\r\n  geom_sf(aes(colour=População)) +\r\n  geom_text(aes(x=Long, y=(Lat-0.5), label=Cidade)) +\r\n  theme_minimal()\r\n\r\n\r\nTire os rótulos dos nomes das cidades e transforme os seus dados para a projeção com CRS 23035, e apresente um novo mapa.\r\n\r\n\r\nMostrar Código\r\n\r\ncidades %>% st_transform(23035) %>% \r\n  ggplot() +\r\n  geom_sf(aes(colour=População)) +\r\n  theme_minimal()\r\n\r\n\r\nCalcule a matriz da distância euclidiana entre as cidades.\r\n\r\n\r\nMostrar Código\r\n\r\ncidades %>% st_transform(23035) %>% \r\n  st_distance() %>% \r\n  as_tibble()\r\n\r\n\r\n\r\nTrabalhando com Polígonos\r\nÁreas administrativas são geralmente representadas como polígonos em mapas. Em geral, obtemos esses polígonos como ‘shapefiles’ produzidos por uma agência oficial. Podemos abrir qualquer tipo de shapefile (pontos, linhas ou polígonos) com a função st_read. Vamos abrir um shapefile (simplificado) dos estados dos Estados Unidos, do link aqui. Baixe o arquivo e abre com st_read:\r\n\r\n\r\nstates <- st_read(\"states.shp\")\r\n\r\n\r\n\r\n\r\n\r\nAbra o nosso objeto states para ver o conteúdo:\r\n\r\n\r\nstates\r\n\r\nSimple feature collection with 51 features and 5 fields\r\nGeometry type: MULTIPOLYGON\r\nDimension:     XY\r\nBounding box:  xmin: -178.2176 ymin: 18.92179 xmax: -66.96927 ymax: 71.40624\r\nGeodetic CRS:  NAD83\r\nFirst 10 features:\r\n     STATE_NAME DRAWSEQ STATE_FIPS         SUB_REGION STATE_ABBR\r\n1        Hawaii       1         15            Pacific         HI\r\n2    Washington       2         53            Pacific         WA\r\n3       Montana       3         30           Mountain         MT\r\n4         Maine       4         23        New England         ME\r\n5  North Dakota       5         38 West North Central         ND\r\n6  South Dakota       6         46 West North Central         SD\r\n7       Wyoming       7         56           Mountain         WY\r\n8     Wisconsin       8         55 East North Central         WI\r\n9         Idaho       9         16           Mountain         ID\r\n10      Vermont      10         50        New England         VT\r\n                         geometry\r\n1  MULTIPOLYGON (((-160.0738 2...\r\n2  MULTIPOLYGON (((-122.402 48...\r\n3  MULTIPOLYGON (((-111.4754 4...\r\n4  MULTIPOLYGON (((-69.77728 4...\r\n5  MULTIPOLYGON (((-98.73044 4...\r\n6  MULTIPOLYGON (((-102.7884 4...\r\n7  MULTIPOLYGON (((-104.0536 4...\r\n8  MULTIPOLYGON (((-87.74856 4...\r\n9  MULTIPOLYGON (((-117.0263 4...\r\n10 MULTIPOLYGON (((-73.25806 4...\r\n\r\nÉ um tibble do tipo ‘sf’ também! Observe que o ‘geometry type’ agora é ‘MULTIPOLYGON’, e que ele tem um CRS de NAD83, diferente dos nossos pontos de aeropotos. Temos 51 áreas, uma para cada estado (mais o DF), e uma coluna de ‘geometria’.\r\nComo podemos visualizar este mapa? Exatamente do mesmo modo que antes (pode demorar para abrir):\r\n\r\n\r\nstates %>% ggplot() +\r\n  geom_sf()\r\n\r\n\r\n\r\nE se quisermos visualizar ambos os polígonos e os pontos dos aeroportos no mesmo mapa, juntos? Respeitando a nossa regra (3) da lista acima, é essencial padronizar os CRS pata a mesma projeção em todas as camadas. Então vamos transformar a projeção de states para o CRS 4326, o mesmo de airports. Sempre que você for trabalhar com diversos dados geográficos a primeira coisa a fazer é padronizar o CRS, para que seja possível visualizar as duas camadas no mesmo mapa e para fazer operações espaciais, como o cálculo da distância.\r\nPara adicionar a camada de aeroportos, é só especificar mais uma camada de geom_sf() com o argumento opcional de data=airports no início. (Isto é uma estratégia geral para adicionar camadas de mais de um banco de dados num gráfico).\r\n\r\n\r\nstates %>% st_transform(4326) %>%\r\n  ggplot() +\r\n  geom_sf() +\r\n  geom_sf(data=airports)\r\n\r\n\r\n\r\nPerfeito! Todos os pontos cabem dentro das bordas do país.\r\nAperfeiçoando a Visualização dos mapas\r\nAlterar a apresentação dos nossos mapas depende das mesmas habilidades como todos os outros gráficos de ggplot. Vamos adicionar um título, alterar o tamanho dos pontos, e o cor das bordas:\r\n\r\n\r\nstates %>% st_transform(4326) %>%\r\n  ggplot() +\r\n  geom_sf(colour=\"#756bb1\") +\r\n  geom_sf(data=airports, size=0.5) +\r\n  ggtitle(\"Mapa de Aeroportos e Estados nos EUA\")\r\n\r\n\r\n\r\nPodemos também alterar a cor da área dos estados dependendo do seu SUB_REGION, com uma escala apropriada, e a cor dos aeroportos dependendo da sua altitude, com uma escala apropriada.\r\n\r\n\r\nstates %>% st_transform(4326) %>%\r\n  ggplot() +\r\n  geom_sf(aes(fill=SUB_REGION), colour=\"#756bb1\", alpha=0.2) +\r\n  scale_fill_brewer(palette=\"Set2\") +\r\n  geom_sf(data=airports, aes(colour=alt), size=0.5) +\r\n  scale_colour_gradient(low=\"#00441b\", high=\"#ef3b2c\") +\r\n  ggtitle(\"Mapa de Aeroportos e Estados nos EUA\")\r\n\r\n\r\n\r\nCom mapas, é frequentemente útil tirar o fundo, os eixos, e os rótulos com theme_minimal():\r\n\r\n\r\nstates %>% st_transform(4326) %>%\r\n  ggplot() +\r\n  geom_sf(aes(fill=SUB_REGION), colour=\"#756bb1\", alpha=0.2) +\r\n  scale_fill_brewer(palette=\"Set2\") +\r\n  geom_sf(data=airports, aes(colour=alt), size=0.5) +\r\n  scale_colour_gradient(low=\"#00441b\", high=\"#ef3b2c\") +\r\n  ggtitle(\"Mapa de Aeroportos e Estados nos EUA\") +\r\n  theme_minimal()\r\n\r\n\r\n\r\nGeoreferenciamento\r\nAté agora, os nossos dados espaciais já chegaram quase pronto para usar. O que podemos fazer se não tivermos dados espaciais? Temos que criá-los. Podemos usar um aplicativo de celular para capturar dados com GPS, ou podemos ‘georeferenciar’ descrições de lugares, como endereços.\r\nPor exemplo, vamos criar um tibble simples com alguns endereços, e usar a função geocode_OSM do pacote tmaptools para converter o endereço em coordenadas de longitude e latitude. A função usa o banco de dados do Open Street Maps. (Note que a função exige usar o $ de R base para especificar a coluna relevante).\r\n\r\n\r\nlibrary(tmaptools)\r\n\r\nLugares <- tibble(ID=c(1,2),\r\n       Endereço=c(\"Av. Prof. Luciano Gualberto, 298-460 - Butanta, Sao Paulo, Brazil\",\r\n                 \"Av. Paulista, 1578 - Bela Vista, Sao Paulo, Brazil\"))\r\n\r\nLugares <- geocode_OSM(Lugares$Endereço, projection=4326, as.sf=T)\r\n\r\n\r\nNote que especificamos o CRS (o projection) em que queremos receber os dados, para que ele seja padronizado com as nossas outras camadas. E usamos as.sf=T para que o resultado já é um tibble de simple features pronto para analisar/visualizar.\r\nMapas Interativos\r\nComo podemos verificar o local dos nossos endereços? É mais fácil com o contexto geográfico, como em google maps, e com um mapa interativo. Geralmente, em relatórios, mapas estáticos são mais apropriados, mas às vezes é útil explorar os nossos dados espaciais interativamente, ou em documentos de HTML. Para isso, usamos a função mapview() no pacote do mesmo nome. É fácil:\r\n\r\n\r\nlibrary(mapview)\r\n\r\nLugares %>% mapview()\r\n\r\n\r\n\r\n\r\nExercício 2: Mapas mais Completos\r\n\r\n\r\n\r\n\r\n\r\n\r\nAbra o shapefile dos países da Europa no link aqui. Elabore um mapa simples usando a projeção 23035\r\n\r\n\r\nMostrar Código\r\n\r\nEurope %>% st_transform(23035) %>% ggplot() +\r\n  geom_sf()\r\n\r\n\r\nAdicione os dados das cidades do Exercício 1 ao seu mapa da Europa de Questão 1 e formate o mapa com um tema, título etc. apropriado.\r\n\r\n\r\nMostrar Código\r\n\r\nEurope  %>% st_transform(23035) %>% ggplot() +\r\n  geom_sf() +\r\n  geom_sf(data=cidades  %>% st_transform(23035), \r\n          colour=\"blue\", size=2) +\r\n  ggtitle(\"Cidades Maiores da Europe\") +\r\n  theme_minimal()\r\n\r\n\r\nDesenvolvendo o mesmo mapa, para cada país da Europa, elabore a visualização da população nacional (variável POP_EST) no mapa, com uma escala e legenda apropriada.\r\n\r\n\r\nMostrar Código\r\n\r\nEurope  %>% st_transform(23035) %>% ggplot() +\r\n  geom_sf(aes(fill=POP_EST)) +\r\n  geom_sf(data=cidades  %>% st_transform(23035), \r\n          colour=\"blue\", size=2) +\r\n  ggtitle(\"Cidades Maiores da Europe\") +\r\n  theme_minimal() +\r\n  scale_fill_gradient(low=\"#e5f5f9\", high=\"#00441b\")\r\n\r\n\r\nQueremos adicionar a próxima cidade na lista, Milão, mas não sabemos a longitude e a latitude da cidade. Georeferencie o endereço de “Piazza del Duomo, 20122 Milano, Italy”, e (em vez de juntar com o banco de dados de cidades), adicione os resultados como mais uma camada do seu mapa de Questão 3 com a mesma formatação da camada do resto das cidades.\r\n\r\n\r\nMostrar Código\r\n\r\nMilan <- geocode_OSM(\"Piazza del Duomo, 20122 Milano, Italy\", projection=4326, as.sf=T)\r\n\r\nEurope  %>% st_transform(23035) %>% ggplot() +\r\n  geom_sf(aes(fill=POP_EST)) +\r\n  geom_sf(data=cidades  %>% st_transform(23035), \r\n          colour=\"blue\", size=2) +\r\n  geom_sf(data=Milan %>% st_transform(23035), colour=\"blue\", size=2) +\r\n  ggtitle(\"Cidades Maiores da Europe\") +\r\n  theme_minimal() +\r\n  scale_fill_gradient(low=\"#e5f5f9\", high=\"#00441b\")\r\n\r\n\r\n\r\nJoins Não-Espaciais\r\nObserve que os nossos dados espaciais vêm com uma tabela, e normalmente com um identificador único para cada observação (unidade espacial). Isto abre uma oportunidade - se temos dados não-espaciais que queremos mapear, é fácil torná-los espacial - é só juntar o banco não-espacial com o banco espacial usando o identificador comum, exatamente como discutimos no tutorial anterior. Na prática é muito mais comum pegar um shapefile genêrico de polígonos/pontos, e cruzar com um banco de dados não-espacial.\r\nPor exemplo, queremos mapear o número de voos de Nova Iorque que chegam em cada aeroporto de destino em 2013. Com apenas o banco de dados flights isso seria impossível. Mas em combinação com o nosso banco de airports espacial, é rápido. Primeiro, qual é a unidade espacial de análise que desejamos? É cada aeroporto de destino, então temos que agregar/resumir o banco de dados de flights para cada destino. Por enquanto, pode ser apenas o número de voos:\r\n\r\n\r\nflights_por_dest <- flights %>% group_by(dest) %>% \r\n  tally()\r\n\r\n\r\nSegundo, vamos isolar o identificador comum, neste caso o código de aeroporto destino, dest em um banco, faa no outro, e rodar o left_join() como normal. Uma dica - lembre que left_join() preserva a estrutura e atributos do objeto na esquerda. Dado que queremos o resultado do nosso join manter o seu status espacial (de ‘sf’), é sempre uma boa ideia colocar o objeto espacial na esquerda de left_join() (antes do pipe).\r\n\r\n\r\n\r\n\r\n\r\nairports_flights <- airports %>% rename(\"dest\"=\"faa\") %>%\r\n  left_join(flights_por_dest, by=\"dest\")\r\n\r\n\r\nAgora, a coluna ‘n’ está disponível no tibble airports_flights para visualização:\r\n\r\n\r\nairports_flights %>% ggplot() +\r\n  geom_sf(aes(colour=n))\r\n\r\n\r\n\r\nSó temos poucos dos aeroportos no banco de dados flights, então pode ser melhor usar um inner_join() para tirar os aeroportos ausentes:\r\n\r\n\r\nairports %>% rename(dest=faa) %>%\r\n  inner_join(flights_por_dest, by=\"dest\") %>% \r\n  ggplot() +\r\n  geom_sf(aes(colour=n))\r\n\r\n\r\n\r\nJoins Espaciais\r\nO mundo espacial abre um novo tipo de join entre diversos bancos de dados - joins espaciais que são definidos pela localização semelhante e não por uma chave comum nas tabelas de dados. Existe diversos tipos de joins espaciais mas vamos focar sobre um join entre uma camada de polígonos e uma camada de pontos.\r\nEspecificamente, queremos saber quantos aeroportos (pontos) existem em cada estado (polígono). A função para um join espacial é st_join. Como sempre, a regra crucial é que as duas camadas espaciais têm que ter o mesmo CRS, então vamos usar st_transform para padronizar as duas para 4326.\r\n\r\n\r\nstates <- states %>% st_transform(4326)\r\n\r\nairports_states <- airports  %>% \r\n  st_join(states)\r\n\r\n\r\nAgora, o objeto airports_states contém todos as aeroportos, com colunas adicionais para os detalhes do estado em que o aeroporto fica (geograficamente). Como não haviam estes dados anteriormente, vamos visualizar os aeroportos por ‘SUB_REGION’, uma variável que apenas existia no banco de states, como exemplo:\r\n\r\n\r\nairports_states %>% ggplot() + \r\n  geom_sf(aes(colour=SUB_REGION))\r\n\r\n\r\n\r\nQual tipo de unidade espacial é cada observação em airports_states? É um ponto, um aeroporto. Por que não um polígono, como os estados que usamos no st_join? Porque o st_join também faça por padrão um join à esquerda, como left_join, então ele preserva os atributos do objeto na esquerda, neste caso os pontos dos aeroportos.\r\nSe quisermos juntar os dados por estado e manter a geometria dos polígonos dos estados, apenas temos que inverter a ordem dos objetos no st_join:\r\n\r\n\r\nstates_airports <- states %>% \r\n  st_join(airports)\r\n\r\n\r\nAgora, o objeto ‘states_airports’ contém os dados de cada estado e colunas adicionais com dados dos aeroportos que ficam (geograficamente) no estado. Obviamente há vários aeroportos por estado, então cada estado está duplicado em diversas observaçoes. Inspecione as colunas da direita de states_airports para ver que cada observação é um aeroporto diferente.\r\nMas o mesmo polígono do estado duplicado muitas vezes para cada aeroporto não ajuda nada - temos que agregar os nossos dados por estado para deixar um polígono por estado. Por exemplo, para calcular o número de aeroportos por estado, e visualizar o resultado:\r\n\r\n\r\nstates_num_airports <- states_airports %>% group_by(STATE_NAME) %>% \r\n  tally() \r\n\r\nstates_num_airports %>%\r\n  ggplot() +\r\n  geom_sf(aes(fill=n))\r\n\r\n\r\n\r\nOs joins espaciais ampliam a nossa criatividade, abrindo comparações novas. Há muitas possibilidades, mas o básico é sempre aquilo que descrevemos aqui.\r\nOutras Operações Espaciais\r\nExistem diversas operações espaciais para facilitar análises específicas. O livro aqui, sobretudo capítulos 4 e 5 e o cheatsheet de sf mostram as possibilidades. Por enquanto, vamos ver apenas uma operação que transforma polígonos em pontos. Usamos uma função simples e dedicada, st_centroid(), que calcula o ponto central de cada polígono:\r\n\r\n\r\nstates_centroid <- states %>% st_centroid()\r\n\r\nstates_centroid %>% ggplot() +\r\n  geom_sf()\r\n\r\n\r\n\r\nObserve na coluna ‘geometry’ que o nosso objeto sf de polígonos agora se transformou em pontos, com um ponto central para cada estado.\r\n\r\nExercício 3: Joins para Mapas\r\nJunte os dois bancos de Cidades e Países Europeus usando o nome do país. O resultado deve ser os pontos das cidades. (Uma das nossas tabelas tem que ser um tibble simples (não sf), então use a função st_drop_geometry() para voltar a uma tabela simples). Mostre num mapa a população dos países de cada cidade.\r\n\r\n\r\nMostrar Código\r\n\r\ncidades_pais <- cidades %>% \r\n  left_join(Europe %>% rename(Pais=NAME) %>% \r\n              st_drop_geometry(), by=\"Pais\")\r\n\r\ncidades_pais %>%\r\n  ggplot() +\r\n  geom_sf(aes(fill=POP_EST)) +\r\n  theme_minimal()\r\n\r\n\r\nJunte os dois bancos de cidades e países Europeus usando um join espacial. O resultado deve ser os pontos das cidades. Reproduza o mapa de Questão 1.\r\n\r\n\r\nMostrar Código\r\n\r\ncidades_pais_espacial <- cidades %>%\r\n  st_join(Europe %>% st_transform(4326))\r\n\r\ncidades_pais_espacial %>%\r\n  ggplot() +\r\n  geom_sf(aes(fill=População)) +\r\n  theme_minimal()\r\n\r\n\r\nJunte os dois bancos de cidades e países Europeus usando o nome do país. Agora (diferentemente de 1), o resultado deve ser os polígonos dos países. Mostre num mapa a população das cidades metropolitanas.\r\n\r\n\r\nMostrar Código\r\n\r\npais_cidades <- Europe %>% rename(Pais=NAME) %>% \r\n  left_join(cidades %>% st_drop_geometry(), by=\"Pais\")\r\n\r\npais_cidades %>%\r\n  ggplot() +\r\n  geom_sf(aes(fill=População)) +\r\n  theme_minimal()\r\n\r\n\r\nJunte os dois bancos de cidades e países Europeus usando um join espacial. Agora (diferentemente de 2), o resultado deve ser os polígonos dos países. Reproduza o mapa de Questão 3. Existe algum problema?\r\n\r\n\r\nMostrar Código\r\n\r\npais_cidades_espacial <- Europe %>% st_transform(4326) %>%\r\n  st_join(cidades)\r\n\r\npais_cidades_espacial %>%\r\n  ggplot() +\r\n  geom_sf(aes(fill=População)) +\r\n  theme_minimal()\r\n\r\n\r\n\r\nRasters\r\nExiste um outro formato para dados espaciais que não é baseado em formas geométricas (polígonos, pontos e linhas), mas em uma grade regular com valores específicos em cada célula x, y - isto é um ‘raster’ e para trabalhar com ele usamos o pacote ‘raster’. Vamos usar o código abaixo para abrir um arquivo raster de densidade populacional no Camboja do link aqui, que é simplesmente uma imagem com extensão .tif.\r\n\r\n\r\n#install.packages(\"raster\")\r\nlibrary(raster)\r\ncambodia <- raster(\"Apoio/khm_popdenr_landscan_2011.tif\")\r\n\r\n\r\nPara visualizar o nosso raster, precisamos transformar ele em um data.frame simples (não em um tibble infelizmente) e usar o ggplot com a geometria de geom_tile. Não se preocupe com as detalhes, mas experimente com o código abaixo:\r\n\r\n\r\ncambodia %>% as(\"SpatialPixelsDataFrame\") %>% \r\n  as.data.frame() %>% \r\n  ggplot() + \r\n  geom_tile(aes(x=x,y=y,fill=khm_popdenr_landscan_2011))\r\n\r\n\r\n\r\nEste mapa parece bem chato porque os dados são altamente ‘skewed’, com grandes outliers de populaçao muito densa apenas na capital. Frequentemente com rasters é útil transformá-los em uma escala de log para visualizar, com a opção de trans=\"log\" em nossa camada de escala. Vamos também limpar o fundo e adicionar uma escala de cores.\r\n\r\n\r\ncambodia %>% as(\"SpatialPixelsDataFrame\") %>% \r\n  as.data.frame() %>% \r\n  ggplot() + \r\n  geom_tile(aes(x=x,y=y,fill=khm_popdenr_landscan_2011)) +\r\n  theme_minimal() +\r\n  scale_fill_gradient(low=\"white\",high=\"red\",na.value=\"white\", trans=\"log\")\r\n\r\n\r\n\r\nNeste mapa há como ver os vários centros urbanos e as ruas principais. Um mapa profissional e detalhado em poucas linhas de código!\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:21:27-03:00"
    },
    {
      "path": "Programa.html",
      "title": "FLS 6397 - Introdução à Análise de Dados, Programação e Visualização para as Ciências Sociais",
      "description": "Um curso do Departamento da Ciência Política, Universidade de São Paulo\n",
      "author": [],
      "contents": "\r\n1. Informações básicas\r\nPrimeiro Semestre, 2022\r\nDCP - FFLCH - USP, Laboratório 18\r\nSexta-feiras, 9h - 13h\r\nJonathan Phillips e Rafael Magalhães\r\n2. Apresentação\r\nComo passamos de um banco de dados bruto para um relatório ou artigo publicado com estatísticas precisas, tabelas claras e gráficos convincentes? Existem diversas ferramentas poderosas para facilitar o processo de análise de dados, a pesquisa e a publicação, mas elas podem parecer intimidadores e complexos. Este curso oferece aos estudantes de pós-graduação em ciências sociais uma iniciação accessível ao uso de software para a coleta, limpeza, análise, comparação e visualização de dados.\r\nO foco do curso é o desenvolvimento da habilidade de programação para solução de problemas diversos relacionados ao manejo de dados com fins de pesquisa. Note-se que não é um curso de metodologia de pesquisa ou estatística. No final do curso alunos serão capazes de desenvolver um script que baixar os dados, organizar-los, calcular medidas relevantes, construir tabelas, gráficos e mapas, e gerar um relatório final para uso na sua dissertação/tese, tudo em uma forma verificável, reproduzível, transparente e documentado.\r\n3. Software\r\nAdotamos o uso de língua de R no curso como uma língua aberta, com muito suporte disponível online e uma ferramenta bem usado nas ciências sociais. Nota que o treinamento em R permite uma transição muito mais fácil para outras línguas no futuro, e as princípios de programação e tratamento de dados são bem transferíveis.\r\n4. Estrutura do curso\r\nAulas, leituras e materiais\r\nAs aulas serão compostas por breves apresentações dos tópicos e por longos laboratórios, com tutoriais para auto-aprendizado e acompanhamento dos instrutores e assistentes. Espera-se que a turma pratique exaustivamente, dentro e fora de sala de aula, as técnicas aprendidas.\r\nAtividades e tempo de dedicação\r\nAo longo do curso as participantes deverão solucionar desafios correspondentes aos tópicos, usando bancos de dados comuns nas ciências sociais. Exemplos de desafios: (1) organizar automaticamente dados eleitorais a partir do repositório de dados do TSE; (2) elaborar um mapa com dados municipais a partir do DATASUS. Os desafios exigirão dedicação extra-classe e são parte fundamental do curso.\r\nNo final do curso as estudantes deverão elaborar um projeto individual relacionado a sua própria pesquisa/interesses.\r\nEntre aulas, tutoriais, leituras e desafios, espera-se que cada aluna ou aluno dedique de 8h a 12h por semana à disciplina.\r\nAvaliação\r\nA avaliação é composta pela entrega dos desafios, do projeto final individual e da participação. A atribuição de nota para os desafios e projetos entregues priorizará o esforço e engenhosidade apresentados (leia-se “código com erros, mas bem elaborado”) em detrimento da finalização do desafio (leia-se “código funcionando plenamente”) como forma de encorajar estudantes iniciantes.\r\nEntrega de Desafios (40%)\r\nProjeto Final (40%)\r\nParticipação Ativa e Respeitosa (20%)\r\n5. Requisitos\r\nNão é necessário nenhum conhecimento prévio de programação, pacotes estatísticos ou manejo de conjuntos de dados. O curso é recomendado para tanto alunas e alunos que já têm alguma noção quanto para estudantes que morrem de medo de computadores. O objetivo é criar um ambiente confortável para o aprendizado de técnicas programação, independentemente da habilidade das inscritas, e seguindo todos os passos desde a preparação do ambiente de computação até a apresentação de resultados.\r\nÉ recomendado que as participantes já tenham concluído ou esteja cursando algum curso de métodos de pesquisa (de qualquer abordagem) ou de análise de dados, seja do programa ou da IPSA-USP Summer School. É um curso adequado para estudantes em qualquer etapa do mestrado ou doutorado, desde que tenham disponibilidade para realizar as atividades extra-classe.\r\nEstudantes do DCP-USP que podem se matricular regularmente não serão aceitas como ouvintes.\r\n6. Tópicos\r\nIntrodução ao curso, R e Rmarkdown\r\nAbrindo e manipulando bancos de dados\r\nOrganização e limpeza de dados\r\nCalculando estatísticas resumidas\r\nConstruindo tabelas\r\nVisualização de dados e a gramática de gráficos\r\nJuntando bancos de dados\r\nMapas e análises espaciais\r\nTestes estatísticos e modelos de regressão\r\nProduzindo relatórios reproduzíveis com Git e Latex\r\nFunções e repetição\r\nMineração de Textos\r\n7. Instruções Preparatórias\r\nAntes de começar o curso, por favor segue os passos seguintes. Precisamos instalar duas ferramentas. Primeiro, a linguagem de programação: ‘R’. E segundo, um programa/editor/interface que nos ajuda digitar e organizar a nossa análise: ‘RStudio’.\r\nPara Baixar ‘R’ para Windows: segue o link https://cran.r-project.org/bin/windows/base/, clique no primeiro link, e executar. Para outros sistemas, veja https://cran.r-project.org/bin/\r\nBaixar ‘RStudio’ aqui no link apropriado para o seu sistema e executar: https://rstudio.com/products/rstudio/download/#download\r\nObserve que você nunca precisa abrir ‘R’ diretamente. Tudo pode ser feito em RStudio.\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:21:44-03:00"
    },
    {
      "path": "Projeto.html",
      "title": "Projeto Final",
      "author": [],
      "contents": "\r\nProjeto Final\r\nO prazo para submissão do projeto final é o dia 7 de agosto de 2022 para o email do professor.\r\nO projeto final é a sua oportunidade para aplicar tudo que você aprendeu na disciplina para os seus próprios dados e pergunta de pesquisa. Não precisa ser um projeto finalizado, e é sempre melhor escolher um tópico simples - o erro mais comum é ser ambicioso demais e tentar incorporar demais dados ou análises. Mas também recomendamos que você prepara algo que será útil para a sua própria pesquisa, pois a oportunidade de explorar dados é uma ótima maneira de se tornar um especialista em seu tópico.\r\nA tarefa é:\r\nGerar um relatório reproduzível em R\r\nExplicar brevemente os objetivos da análise\r\nAbrir pelo menos um banco de dados externo, ou montar um banco de dados original\r\nManipular, transformar e limpar os dados para atender os objetivos\r\nIncorporar pelo menos duas estatísticas resumidas no relatório final em In-line código\r\nGerar pelo menos uma tabela bem formatada no relatório final\r\nGerar pelo menos dois gráficos ou mapas bem formatados no relatório final\r\nOrganizar e comentar o seu script para que seja claro o efeito de cada chunk e cada operação\r\nConfigurar os parâmetros dos chunks para gerar um relatório limpo e claro\r\nSubmeter o seu script, e o documento final (HMTL/PDF)\r\nO critério de avaliação será a aplicação dos princípios e técnicas discutidos na disciplina, priorizando a clareza e organização do script e as boas práticas da ciência de dados e a programação, e não a sofisticação da análise ou o argumento substantivo do relatório final.\r\nExemplos de Projetos Finais em anos anteriores\r\nAnalisar despesas eleitorais dos candidatos\r\nAnálise de dados de IPTU\r\nRastreando mudanças na discussão de temas nos jornais online\r\nMapeamento de eventos políticos no Estado de São Paulo\r\nAnálise de participação de mulheres\r\nAvaliação da condição de saúde de pacientes com mutações genéticas\r\nDescrição da trajetória de inflação\r\nMensuração de desigualdades no uso de transporte público\r\nEm caso que você precisa ideais para um banco de dados\r\nPara dados sobre Brasil, https://basedosdados.org/\r\nPara dados sobre ciência política, www.poliscidata.com ou www.github.com/erikgahner/PolData\r\nDados do Banco Mundial, data.worldbank.org\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:22:00-03:00"
    },
    {
      "path": "Recursos.html",
      "title": "Recursos",
      "description": "Links úteis para livros, tutoriais e ideais",
      "author": [],
      "contents": "\r\nLivros\r\n1. R for Data Science\r\n2. Hands-On Programming with R\r\n3. ggplot2: Elegant graphics for data analysis\r\n4. Advanced R\r\n5. Wikibook R Programming\r\n6. Lista de 150 livros online sobre R (!)\r\nCheat Sheets\r\n1. Manípulo de Dados\r\n2. Importação de Dados\r\n3. R Markdown\r\n4. Visualização (ggplot2)\r\n5. Mapas (sf)\r\n6. Latex\r\n7. Strings\r\n8. Outros\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:22:19-03:00"
    },
    {
      "path": "Regressoes.html",
      "title": "Testes Estatísticos e Regressões",
      "author": [],
      "contents": "\r\n\r\nContents\r\nIntrodução\r\nTestes de Normalidade\r\nTestes de Médias\r\nTestes de Correlação\r\nRegressões Simples\r\nModelos Alternativos\r\n\r\nIntrodução\r\nNão se preocupe se você não esteja treinado em métodos quantitativos - não discutimos os detalhes de estatística aqui. Mas é comum aplicar um teste simples ou uma regressão aos nossos dados para avaliar alguma hipótese, e sabendo como fazer isto é um bom treinamento para construir fluxos de análise mais complexos para outros objetivos também.\r\nOs pontos cruciais de testes estatísticos são os seguintes:\r\nTemos dados de pelo menos uma variável e queremos avaliar se um ‘fato’ (uma hipótese nula) sobre estes dados é verdade/se comprova.\r\nEntão comparamos os nossos dados reais com uma distribuição de referência assumindo que este fato/hipótese nula é verdade.\r\nAvaliamos a força dos nossos dados - isto é, da evidência disponível - levando em conta a quantidade de observações que temos para extrair informação. Resumimos a força da evidência com um ‘valor p’, que estima o quão provável seria observar os nossos dados reais se o fato - nossa hipótese nula - realmente for verdade.\r\nUm valor p bem baixo significa que seria muito bizarro observar os nossos dados se o fato seja verdade, então parece mais provável que o fatonão seja verdade.\r\n\r\nPodemos ilustrar com um exemplo: suponha que você é um funcionário do governo e quer avaliar o desempenho de um grupo de alunos participando num programa de apoio, comparando com não-participantes. Mas as notas dos alunos também variam por muitos motivos que não têm nada a ver com o programa. A nota média dos participantes é 72, e dos não-participantes 70. Isso é uma diferença real, ou apenas uma variação aleatória? A hipótese nula que precisamos avaliar é que as duas médias são iguais, e o teste é uma comparação dos dados com a distribuição de valores apropriada - a distribuição ‘t’ neste caso. Observe que a conclusão depende da quantidade e variabilidade dos nossos dados - com 40 alunos em cada grupo, não é uma diferença estatisticamente significativa (ex. um valor p de 0.37), mas com 400 alunos em cada grupo, é diferente (ex. um valor p de 0.002, assumindo um desvio padrão de notas de 10, e um limiar de significância de 0.05).\r\nNo R, as funções de testes estatísticos e regressões são mais diversas e menos padronizadas que as funções que já discutimos no resto do curso. Assim, é crucial entender o classe/tipo de objeto que a função espera, e o resultado que ela produz. A nossa tarefa é usar o nosso pipe para preparar os dados no classe/formato apropriado.\r\nTestes de Normalidade\r\nO nosso primeiro teste é um teste de como os nossos dados são distribuidos. Dados contínuos frequentemente formam uma distribuição ‘normal’ quando temos um número razoável de observações (a linha preta no gráfico abaixo). Podemos avaliar o fato/hipótese nula que os nossos dados são distribuido de forma ‘normal’ com um teste que se chama o teste Shapiro-Wilk. Ele compara os nossos dados com uma distribuição normal perfeita e avalia o quão longe da normal são os nossos dados.\r\n\r\n\r\n\r\nUsamos o teste Shapiro-Wilk através da função shapiro.test() e ela espera um vetor dos valores da variável que queremos testar. Então temos que isolar um vetor (não um tibble) para encaminhar usando a função pull(). Vamos avaliar se os atrasos dos vôos (dep_delay) são distribuidos normalmente:\r\n\r\n\r\nflights %>% \r\n  pull(dep_delay) %>% \r\n  shapiro.test()\r\n\r\n\r\nAh, o R pediu que limitamos os nossos dados para um máximo de 5000 para simplificar o teste. Tudo bem, vamos pegar uma amostra aleatória de 3000 observações:\r\n\r\n\r\nteste_normalidade <- flights %>% sample_n(3000) %>% \r\n  pull(dep_delay) %>% \r\n  shapiro.test()\r\n\r\nteste_normalidade\r\n\r\n\r\n    Shapiro-Wilk normality test\r\n\r\ndata:  .\r\nW = 0.50308, p-value < 2.2e-16\r\n\r\nÓtimo - veja o resultado do teste: Há um estatístico de teste ‘W’ e um valor ‘p’ para avaliar a significância do teste. O valor ‘p’ é bem pequeno aqui, indicando que tem pouco chance que os nossos dados são normais.\r\n\r\nHabilidade Básica de Programação: Números Científicos\r\nÀs vezes parece que os nossos números foram corrompidos, sobretudo com testes estatísticos: Qual espécie de número é “2.2e-6”??\r\nÉ um número, sim, um número muito grande ou muito pequeno que o R escolha mostra no formato ‘científico’. “2.2e-6” indica o número de dígitos pelo qual temos que mexer o ponto decimal (a vírgula) para chegar no valor final. Aqui é 6 espaços, igual a 0,0000022. Se for “2.2e+6”, seria 2200000,0.\r\nVocê não precisa fazer nada com os seus dados, o valor é salvo como um número completo com todos os seus dígitos. A diferença é só na apresentação do valor na tela.\r\nMas é verdade que às vezes preferimos valores mais fáceis para interpretar. Uma dica para encorajar o R não usar o formato científico é inserir o seguinte código no início do seu script:\r\n\r\n\r\noptions(scipen=999)\r\n\r\n\r\n\r\n\r\nDá para verificar que a distribuição de atrasos não parece normal com um gráfico de densidade. Em vez de uma distribuição simétrica, temos uma cauda longa no lado direito.\r\n\r\n\r\nflights %>% \r\n  ggplot() +\r\n  geom_density(aes(x=dep_delay)) +\r\n  xlim(0,100)\r\n\r\n\r\n\r\nQual foi o tipo de objeto criado pela shapiro.test()?\r\n\r\n\r\nclass(teste_normalidade)\r\n\r\n[1] \"htest\"\r\n\r\nÉ do tipo ‘htest’, que é um formato proprietário que é muito difícil incorporar em nosso texto, ou em uma tabela. Por exemplo, eu quero inserir no meu relatório final a frase “O teste Shapiro-Wilk de normalidade da variável dep_delay tem valor ‘p’ de [X]”. Como eu posso inserir o valor de ‘X’ da teste com in-line código?\r\nPode ser muito chato se preciseramos fazer de forma manual. Porém, felizmente, existe uma outra biblioteca/função dedicada a ajudar nessa situação, simplificando e padronizando os resultados de testes estatísticos. Qual é o objeto com quem estamos mais acostumados a trabalhar? É o tibble, lembre que quase tudo foi um tibble! Esse é a magia da biblioteca broom e a função tidy - ela transforme os resultados de testes estatísticos em um tibble:\r\n\r\n\r\n#install.packages(\"broom\")\r\nlibrary(broom)\r\n\r\nteste_normalidade <- flights %>% sample_n(3000) %>% \r\n  pull(dep_delay) %>% \r\n  shapiro.test() %>% \r\n  tidy()\r\n\r\n\r\n\r\n\r\nteste_normalidade\r\n\r\n\r\n\r\n\r\n\r\n\r\nMuito melhor! Agora temos todos os detalhes do teste num tibble, e é fácil extrair os valores desejados, por exemplo:\r\nO teste Shapiro-Wilk de normalidade da variável dep_delay tem valor ‘p’ de `r teste_normalidade %>% pull(p.value) %>% round(3)`.\r\nO teste Shapiro-Wilk de normalidade da variável dep_delay tem valor ‘p’ de 0.\r\nObserve que usamos round(3) no final do fluxo para arredondar os valores numéricos.\r\nNós podemos usar tidy depois da maioria de testes estatísticos, e também regressões, para simplificar a apresentação dos resultados.\r\nTestes de Médias\r\nUma outra família de testes estatísticos é testes de médias, amplamante conhecidos como ‘t-tests’. Começamos com um teste simples: a nossa média é estatisticamente diferente de um valor específico? Imagine, por exemplo, que as companhias aéreas tinham um atraso médio de 13.4 minutos em 2012 - o valor média em 2013 foi diferente?\r\nEste teste exige uma comparação entre os nossos dados e o valor ‘13.4’, então vamos encaminhar o vetor de atrasos para a função t.test(), especificando o argumento mu para o valor de comparação (o 13.4). E não esquecemos de usar tidy() no final para simplificar o resultado:\r\n\r\n\r\nteste_media <- flights %>% filter(origin!=\"LGA\") %>% \r\n  pull(dep_delay) %>%\r\n  t.test(mu=13.4) %>% \r\n  tidy()\r\n\r\nteste_media\r\n\r\n\r\n\r\n\r\n\r\n\r\nRecebemos muitas informações aqui: a média dos nossos dados é 13.66, pouco acima de 13.4. Mas isso é longe de 13.4 ou próximo? Depende da quantidade de observações. O intervalo de confiança (de 95%) é de 13.49 a 13.83, e o valor ‘p’ é 0.0018, debaixo da padrão comum de 0.05. Então o restulado fica estatisticamente significativa; parece que o atraso média em 2013 realmente é diferente do valor de 13.4 em 2012.\r\nPara comunicar os resultados do t-test, é frequentemente útil gerar gráficos para mostrar a média e o intervalo de confiança. Como podemos construir um gráfico deste tipo? Vamos começar com o parte mais fácil: colocamos a média dos nossos dados (um ponto com geom_point) e uma linha horizontal para indicar o ponto de comparação (com geom_hline que gera uma linha horizontal):\r\n\r\n\r\nteste_media %>% mutate(Variavel=\"Atraso na partida\") %>% \r\n  ggplot() +\r\n  geom_point(aes(x=Variavel, y=estimate)) +\r\n  geom_hline(yintercept=13.4, lty=2, color=\"blue\")\r\n\r\n\r\n\r\nObserve aqui que adicionamos uma coluna com o nome da variável em nosso tibble antes de visualizá-la para que podemos incorporar o nome daquela variável em nosso gráfico. Em breve, quando temos múltiplas variáveis para analisar, podemos nomear eles de forma sistemática. O formato dos resultados num tibble facilita bastante a preparação do gráfico.\r\nAgora, vamos adicionar uma linha que mostra o intervalo de confiança (as variáveis ‘conf.low’ e ‘conf.high’), com a geometria geom_errorbar(), que exige três variáveis: x, ymin e ymax para definir os limites da linha baseado nos valores em nosso tibble:\r\n\r\n\r\nteste_media %>% mutate(Variavel=\"Atraso na partida\") %>% \r\n  ggplot() +\r\n  geom_point(aes(x=Variavel, y=estimate)) +\r\n  geom_hline(yintercept=13.4, lty=2, color=\"blue\") +\r\n  geom_errorbar(aes(x=Variavel, ymin=conf.low, ymax=conf.high), width=0.1)\r\n\r\n\r\n\r\nÉ fácil ver no gráfico que o intervalo de confiança de 95% não sobreposiciona o valor de 13.4, significando que o atraso subiu estatisticamente em 2013.\r\nComparando Médias\r\nQue tal se não temos um ponto de comparação fixa, mas queremos comparar se a média em um grupo é diferente da média num outro grupo? Isso significa que dividimos os nossos dados baseado numa variável categórica em nosso tibble, e comparamos as duas distribuições pela variável contínua. Por exemplo, queremos comparar se o atraso média do aeroporto ‘EWR’ é estatisticamente diferente do atraso média no aeroporto ‘JFK’.\r\nPodemos continuar usando a função t.test, mas agora que temos que definir uma variável discreta e uma variável contínua, precisamos encaminhar o nosso tibble completo e não um vetor (uma variável única), então não precisamos do passo de pull(). Em vez disso, e dado que estamos usando funções fora do tidyverse, temos que indicar para t.test que ela deve trabalhar com os dados que estamos encaminhando pelo pipe com o argumento data=.. (Lembre-se que o ‘.’ significa para R usar os dados produzidos no fluxo do pipe anterior).\r\nHá mais um ajuste necessário: Vários testes, incluindo t.test, exigem que definimos este análise usando uma fórmula, com a variável contínua na esquerda e a variável discreta (os grupos que queremos comparar) na direita: dep_delay ~ origin. Pode ler esta fórumla assim: Pega os dados de atrasos, e divida-os por aeroporto de origem.\r\n\r\nHabilidade Básica de Programação: Fórmulas\r\nUma fórmula é simplesmente uma sintaxe para comparar uma variável dependente (o resultado que queremos comparar) e variáveis independentes (que dividem os nossos dados em grupos ou nós achamos podem correlacionar com a variável dependente).\r\nA variável dependente sempre fica na esquerda, e está separada das variáveis independentes com o símbolo ~. Por exemplo:\r\ndependente ~ independente\r\nPodemos adicionar mais vaiáveis independentes com o símbolo ‘+’:\r\ndependente ~ independente1 + independente2\r\nFórmulas são usadas em vários contextos, incluindo testes estatísticos e regressões.\r\n\r\n\r\nVamos realizar o teste para avaliar se a média de atrasos é ígual entre JFK e EWR:\r\n\r\n\r\nflights %>% filter(origin!=\"LGA\") %>% \r\n  t.test(dep_delay ~ origin, data=.) %>% \r\n  tidy()\r\n\r\n\r\n\r\n\r\n\r\n\r\nNote que filtramos os dados para deixar apenas dois valores na variável origin (o t-test só funciona com dois grupos). O resultado contém muita informação - o ‘estimate’ é a diferença de médias, o ‘estimate1’ a média no primeiro aeroporto (‘EWR’), e o ‘estimate2’ a média no segundo aeroporto (‘JFK’). E temos o valor ‘p’ e o intervalo de confiança. Parece que realmente há uma diferencá significativa, com um atraso média maior em Newark (EWR).\r\nEste tipo de teste é muito comum porque sempre queremos comparar entre grupos. Por exemplo, um t-test deste tipo é a análise feito quando rodamos um experimento para comparar dois grupos: tratamento e controle.\r\nTestes de Correlação\r\nSabemos que existe uma associação entre o atraso médio e o aeroporto - entre uma variável contínua e uma variável discreta. Como podemos comparar a associação entre duas variáveis contínuas? Por exemplo, atraso (dep_delay) e horário de partida (dep_time)?\r\nAssociação neste caso se chama ‘correlação’ e compara todos os valores das duas variáveis contínuas, e não simplesmente as médias. A avaliação do teste de correlação é calcular o coeficiente de correlação (de tipo Pearson, por padrão; basicamente a inclinação da linha entre os pontos no gráfico), que pode ser positivo ou negativo, e comparar com zero, pois zero indica nenhuma correlação.\r\nRodando o teste é fácil: encaminhamos o nosso tibble para cor.test(), com data=., e a fórmula agora tem duas variáveis independentes e nenhuma dependente (dado que estamos tratando as variáveis igualmente). Como sempre, tidy() ajuda para organizar os resultados.\r\n\r\n\r\nflights %>% \r\n  cor.test(~ dep_delay + dep_time, data=.) %>%\r\n  tidy()\r\n\r\n\r\n\r\n\r\n\r\n\r\nOs resultados indicam um coeficiente de correlação de 0.26 (positivo), e um valor ‘p’ de zero. Interpretando: há uma correlação positiva e estatisticamente significativa entre o horário de partida e o atraso. Ou seja, é melhor voar mais cedo!\r\nÉ fácil usar um gráfico de pontos e uma linha (geom_smooth()) para mostrar essa correlação positiva visualmente:\r\n\r\n\r\nflights %>% sample_n(1000) %>% \r\n  ggplot() +\r\n  geom_point(aes(x=dep_time, y=dep_delay)) +\r\n  geom_smooth(aes(x=dep_time, y=dep_delay), method=\"lm\")\r\n\r\n\r\n\r\nTestes de Correlação de Variáveis Categóricas (Chi-squared)\r\nPara completar a tipologia de testes, como podemos comparar duas variáveis categóricas? Por exemplo, queremos comparar as variáveis origin (origem) e carrier (companhia aérea) para saber - estatisticamente - se as mesmas companhias voam de cada aeroporto com a mesma frequência.\r\nNesta circunstância, é apropriado aplicar um teste ‘chi-squared’, usando a função chisq.test(). O formato que a função exige é uma ‘tabela de contingência’ - todas as combinações das duas variáveis possíveis e o número de observações (vôos) para cada combinação.\r\nFelizmente, é fácil construir essa tabela de contingência com a função table(), com um select anterior para definir as duas variáveis que queremos comparar:\r\n\r\n\r\nflights %>% select(origin, carrier) %>% \r\n  table()\r\n\r\n      carrier\r\norigin    9E    AA    AS    B6    DL    EV    F9    FL    HA    MQ\r\n   EWR  1268  3487   714  6557  4342 43939     0     0     0  2276\r\n   JFK 14651 13783     0 42076 20701  1408     0     0   342  7193\r\n   LGA  2541 15459     0  6002 23067  8826   685  3260     0 16928\r\n      carrier\r\norigin    OO    UA    US    VX    WN    YV\r\n   EWR     6 46087  4405  1566  6188     0\r\n   JFK     0  4534  2995  3596     0     0\r\n   LGA    26  8044 13136     0  6087   601\r\n\r\nFaz sentido? A tabela mostra o número de voos de cada aeroporto e cada companhia aérea. É meio-óbvio que a distribuição das companhias é diferente por cada aeroporto, mas vamos testar isso estatisticamente:\r\n\r\n\r\nflights %>% select(origin, carrier) %>% \r\n  table() %>% \r\n  chisq.test() %>%\r\n  tidy()\r\n\r\n\r\n\r\n\r\n\r\n\r\nO valor ‘p’ de zero indica que realmente existe uma diferença nas companhias que voam de cada aeroport.\r\n\r\nExercício 1: Testes Estatísticos\r\nUse a função rnorm(1000, 0, 1) para gerar um vetor de 1000 observações aleatoriamente da distribuição normal. Avalie se os valores gerados sejam realmente distribuido de forma normal com um teste Shapiro-Wilk.\r\n\r\n\r\nMostrar Código\r\n\r\nrnorm(1000, 0, 1) %>% \r\n  shapiro.test() %>%\r\n  tidy()\r\n\r\n\r\nNo banco de dados planes, teste se a média do ano de fabricação dos voos de fabricador Boeing seja diferente de 2000.\r\n\r\n\r\nMostrar Código\r\n\r\nplanes %>% filter(manufacturer==\"BOEING\") %>% \r\n  pull(year) %>%\r\n  t.test(mu=2000)\r\n\r\n\r\nAvalie com um teste apropriado se a velocidade média de voos de Newark (EWR) seja igual à velocidade dos vôos de LaGuardia (LGA). (Lembre-se que tem que calcular a variável velocidade).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(origin!=\"JFK\") %>%\r\n  mutate(velocidade=distance/air_time) %>%\r\n  t.test(velocidade~origin, data=.) %>%\r\n  tidy()\r\n\r\n\r\nUsando o banco de dados weather, qual é a correlação entre temperatura (temp) e pressão (pressure)?\r\n\r\n\r\nMostrar Código\r\n\r\nweather %>% \r\n  cor.test(~temp + pressure, data=.) %>%\r\n  tidy()\r\n\r\n\r\nCrie um gráfico usando geom_errorbar() para comunicar o intervalo de confiança da estimativa de correlação em questão 4. Adicione uma linha horizontal para comparar com uma correlação de zero.\r\n\r\n\r\nMostrar Código\r\n\r\nweather %>% filter(origin!=\"EWR\") %>%\r\n  cor.test(~temp + pressure, data=.) %>%\r\n  tidy() %>%\r\n  mutate(Variavel=\"Correlação entre temperatura e pressão\") %>%\r\n  ggplot() +\r\n  geom_point(aes(x=Variavel, y=estimate)) +\r\n  geom_hline(yintercept=0, lty=2, color=\"blue\") +\r\n  geom_errorbar(aes(x=Variavel, ymin=conf.low, ymax=conf.high), width=0.1)\r\n\r\n\r\n\r\nRegressões Simples\r\nRegressão é correlação. Nada muito mais complexo que isso, então não fica com medo - rodar uma regressão é uma linha única de código, parecido com os testes que executamos acima. Existem variadades infinitas de regressões, e os detalhes ficam fora do curso. Mas é importante entender como a manipular os bancos de dados e os resultados de regressões porque ninguém vai ensinar isso numa disciplina de regressão, e entendendo a preparação de dados facilita bastante o seu foco no entendimento e interpretação de regressão.\r\nComeçamos com a regressão mais simples, um modelo linear, apropriado para variáveis dependentes contínuas. A função é lm(), e indicando data=. podemos passar os nossos dados diretamente para ela no fluxo de pipe. É só inserir a fórmula que define a nossa regressão, como sempre com a variável dependente na esquerda e as variáveis independentes (explicativas) na direita. Por exemplo:\r\n\r\n\r\nflights %>% lm(dep_delay ~ dep_time, data=.)\r\n\r\n\r\nCall:\r\nlm(formula = dep_delay ~ dep_time, data = .)\r\n\r\nCoefficients:\r\n(Intercept)     dep_time  \r\n  -16.27245      0.02143  \r\n\r\nÉ simples assim!\r\nOkay, mas o resultado aqui é complexo e não muito claro. Há duas opções para pedir mais detalhes da regressão:\r\nUse a função summary() para gerar uma tabela de regressão (com coeficientes e desvios padrões dos coeficientes) e várias estatísticas, mas num formato terrível. Isto é útil para uma avaliação inicial, mas não ajuda para relatórios profissionais.\r\n\r\n\r\nflights %>% lm(dep_delay ~ dep_time, data=.) %>%\r\n  summary()\r\n\r\n\r\nCall:\r\nlm(formula = dep_delay ~ dep_time, data = .)\r\n\r\nResiduals:\r\n    Min      1Q  Median      3Q     Max \r\n -70.44  -18.69   -8.08    1.18 1303.54 \r\n\r\nCoefficients:\r\n              Estimate Std. Error t value Pr(>|t|)    \r\n(Intercept) -1.627e+01  1.990e-01  -81.76   <2e-16 ***\r\ndep_time     2.143e-02  1.387e-04  154.48   <2e-16 ***\r\n---\r\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\r\n\r\nResidual standard error: 38.82 on 328519 degrees of freedom\r\n  (8255 observations deleted due to missingness)\r\nMultiple R-squared:  0.06772,   Adjusted R-squared:  0.06772 \r\nF-statistic: 2.386e+04 on 1 and 328519 DF,  p-value: < 2.2e-16\r\n\r\nUse a função tidy() para gerar um tibble com os coeficientes e os seus estatísticos.\r\n\r\n\r\nflights %>% lm(dep_delay ~ dep_time, data=.) %>%\r\n  tidy()\r\n\r\n\r\n\r\n\r\n\r\n\r\nA segunda opção é geralmente o mais útil para relatórios, pois podemos continuar com as nossas funções normais como filter e select para organizar o resultado. Vamos ver em breve alternativas para gerar diretamente tabelas mais bonitas.\r\nObserve que gerando regressões mais complexas só precisa de ajustes na fórmula. Por exemplo para adicionar mais variáveis independentes:\r\n\r\n\r\nflights %>% lm(dep_delay ~ dep_time + origin, data=.) %>% tidy()\r\n\r\n\r\n\r\n\r\n\r\n\r\nPara especificar uma relação entre uma variável independente e o dependente não-linear, ex. quadrático, temos que usar a função I(), por exemplo:\r\n\r\n\r\nflights %>% lm(dep_delay ~ dep_time + I(dep_time^2), data=.) %>% tidy()\r\n\r\n\r\n\r\n\r\n\r\n\r\nTabelas de Resultados de Regressões\r\nÉ muito comum compartilhar os resultados da nossa regressão em uma tabela profissional. Existem várias funções que facilitam este processo; vamos usar stargazer, da biblioteca do mesmo nome. Podemos preparar tabelas em vários formatos, para HTML ou para PDF (com latex, que vamos explorar na aula que vem). PDF é o padrão então se quisemos tabelas de HTML, temos que especificar o argumento type=\"html\".\r\nCuidado: Existe mais uma ajuste necessária. Lembre-se das opções de chunks que especificamos, como echo=FALSE para não mostrar o nosso código? Com stargazer temos que especificar results='asis' nas opções de chunk para que o resultado saia corretamente quando usamos ‘knit’. Veja o exemplo:\r\n```{r, results='asis'}\r\nlibrary(stargazer)\r\nflights %>% lm(dep_delay ~ dep_time + origin, data=.) %>%\r\n  stargazer(type=\"html\")\r\n```\r\n\r\n\r\n\r\n\r\n\r\n\r\nDependent variable:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\ndep_delay\r\n\r\n\r\n\r\n\r\ndep_time\r\n\r\n\r\n0.022***\r\n\r\n\r\n\r\n(0.0001)\r\n\r\n\r\n\r\n\r\n\r\n\r\noriginJFK\r\n\r\n\r\n-4.327***\r\n\r\n\r\n\r\n(0.163)\r\n\r\n\r\n\r\n\r\n\r\n\r\noriginLGA\r\n\r\n\r\n-4.190***\r\n\r\n\r\n\r\n(0.166)\r\n\r\n\r\n\r\n\r\n\r\n\r\nConstant\r\n\r\n\r\n-13.655***\r\n\r\n\r\n\r\n(0.217)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n328,521\r\n\r\n\r\nR2\r\n\r\n0.070\r\n\r\n\r\nAdjusted R2\r\n\r\n0.070\r\n\r\n\r\nResidual Std. Error\r\n\r\n\r\n38.771 (df = 328517)\r\n\r\n\r\nF Statistic\r\n\r\n\r\n8,280.601*** (df = 3; 328517)\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nUma tabela bem-formatada com pouco esforço! É possível ajustar todos os elementos da tabela usando os milhares de argumentos da função stargazer. Por exemplo, podemos especificar um título, renomear as variáveis, ajuste a localização dos desvíos padrões, e escolhar as estatísticas desejadas.\r\n\r\n\r\nlibrary(stargazer)\r\nflights %>% lm(dep_delay ~ dep_time + origin, data=.) %>%\r\n  stargazer(type=\"html\", title=\"Modelo de Atraso de Vôos\",\r\n            single.row = T, keep.stat = c(\"n\"),\r\n            dep.var.labels=\"Atraso\",\r\n            covariate.labels=c(\"Horário\", \"JFK\", \"LGA\"),\r\n            header=F, dep.var.caption=\"\")\r\n\r\n\r\nModelo de Atraso de Vôos\r\n\r\n\r\n\r\n\r\n\r\n\r\nAtraso\r\n\r\n\r\n\r\n\r\nHorário\r\n\r\n\r\n0.022*** (0.0001)\r\n\r\n\r\nJFK\r\n\r\n\r\n-4.327*** (0.163)\r\n\r\n\r\nLGA\r\n\r\n\r\n-4.190*** (0.166)\r\n\r\n\r\nConstant\r\n\r\n\r\n-13.655*** (0.217)\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n328,521\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nEm caso que você querer comparar dois modelos parecidos na mesma tabela, é só salvar as duas regressões como objetos, e encaminhar eles juntos na forma de uma list() para stargazer:\r\n\r\n\r\nreg1 <- flights %>% lm(dep_delay ~ dep_time, data=.)\r\nreg2 <- flights %>% lm(dep_delay ~ dep_time + origin, data=.)\r\n\r\nlist(reg1, reg2) %>% stargazer(type=\"html\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nDependent variable:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\ndep_delay\r\n\r\n\r\n\r\n\r\n(1)\r\n\r\n\r\n(2)\r\n\r\n\r\n\r\n\r\ndep_time\r\n\r\n\r\n0.021***\r\n\r\n0.022***\r\n\r\n\r\n\r\n(0.0001)\r\n\r\n\r\n(0.0001)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\noriginJFK\r\n\r\n\r\n\r\n\r\n-4.327***\r\n\r\n\r\n\r\n\r\n\r\n(0.163)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\noriginLGA\r\n\r\n\r\n\r\n\r\n-4.190***\r\n\r\n\r\n\r\n\r\n\r\n(0.166)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nConstant\r\n\r\n\r\n-16.272***\r\n\r\n-13.655***\r\n\r\n\r\n\r\n(0.199)\r\n\r\n\r\n(0.217)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n328,521\r\n\r\n\r\n328,521\r\n\r\n\r\nR2\r\n\r\n0.068\r\n\r\n\r\n0.070\r\n\r\n\r\nAdjusted R2\r\n\r\n0.068\r\n\r\n\r\n0.070\r\n\r\n\r\nResidual Std. Error\r\n\r\n\r\n38.825 (df = 328519)\r\n\r\n\r\n38.771 (df = 328517)\r\n\r\n\r\nF Statistic\r\n\r\n\r\n23,863.440*** (df = 1; 328519)\r\n\r\n\r\n8,280.601*** (df = 3; 328517)\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nGráficos de Efeitos Marginais das Regressões\r\nAs tabelas de regressão ainda exigem bastante esforço para interpretar. Visualizando os coeficientes de uma regressão é fácil com a combinação de tidy() e ggplot(). Vamos visualizar as nossas estimativas dos efeitos marginais das duas variáveis explicativas no ‘reg2’ criado acima. A única coisa que faltamos é um intervalo de confiança pré-calculada, mas isso é fácil calcular: para o intervalo de confiança de 95%, só ajustamos a nossa estimativa central por 1.96 (o valor correspondente a 95% na distrbuição t) multiplicado pelo desvio padrão, para acima e para abaixo. Também vou tirar o intercept - observe que tudo isso é fácil usando as nossas funções bem conhecidas como mutate e filter porque tidy nos permite trabalhar com um tibble.\r\n\r\n\r\nreg2 %>% tidy() %>%\r\n  mutate(conf.lo=estimate-1.96*std.error,\r\n         conf.hi=estimate+1.96*std.error) %>%\r\n  filter(term!=\"(Intercept)\") %>%\r\n  ggplot() +\r\n  geom_point(aes(x=term, y=estimate)) +\r\n  geom_errorbar(aes(x=term, y=estimate, ymin=conf.lo, ymax=conf.hi), width=0.1) +\r\n  geom_hline(yintercept=0, lty=2)\r\n\r\n\r\n\r\nModelos Alternativos\r\nA partir desta seção, não se preocupe se você não tem muita preperação prévia. Pode acompanhar os exemplos mesmo assim, ou pular para o final do tutorial se preferir.\r\nUma regressão linear é apenas uma das possibilidades. O tipo de regressão reflete o tipo de dado em nossa variável dependente. Usamos uma regressão linear apenas quando a nossa variável dependente é contínua. Variáveis dependentes binárias (0/1), por exemplo, exigem um modelo de regressão de tipo ‘logit’ (ou ‘probit’).\r\nPara acomodar uma variedade de modelos vamos aproveitar do pacote Zelig que aceita várias possibilidades. Observe que o Zelig funciona só se baixamos do site de Github (que vamos explorar mais no próximo tutorial) então o processo de instalação exige um pouco mais de esforço:\r\n\r\n\r\n\r\n\r\n\r\n#install.packages(\"devtools\")\r\n#devtools::install_github('IQSS/Zelig')\r\nlibrary(Zelig)\r\n\r\n\r\nA função zelig é bem parecida à lm. Para replicar o modelo linear nos exemplos acima, é só trocar lm para zelig e adicionar `model=“ls”:\r\n\r\n\r\nflights %>% zelig(dep_delay ~ dep_time + origin, data=., model=\"ls\")\r\n\r\n\r\nOs resultados são iguais, e vamos ver em breve como a encaminhar eles para tabelas/gráficos.\r\nO poder de zelig é facilitando modelos alternativos. Primeiro, vamos ver como a usar um modelo ‘logit’ para variáveis dependentes binárias, por exemplo a presença de um atraso. Precisamos simplesmente especificar model=\"logit\":\r\n\r\n\r\nflights %>% mutate(atraso=case_when(dep_delay>0~1,\r\n                                    TRUE~0)) %>%\r\n  zelig(atraso ~ origin, data=., model=\"logit\")\r\n\r\n\r\n\r\nModel: \r\n\r\nCall:\r\nz5$zelig(formula = formula, data = data, by = by)\r\n\r\nCoefficients:\r\n             Estimate Std. Error z value Pr(>|z|)\r\n(Intercept) -0.256505   0.005801  -44.22   <2e-16\r\noriginJFK   -0.242781   0.008478  -28.64   <2e-16\r\noriginLGA   -0.488579   0.008799  -55.53   <2e-16\r\n\r\n(Dispersion parameter for binomial family taken to be 1)\r\n\r\n    Null deviance: 447727  on 336775  degrees of freedom\r\nResidual deviance: 444598  on 336773  degrees of freedom\r\nAIC: 444604\r\n\r\nNumber of Fisher Scoring iterations: 4\r\n\r\nNext step: Use 'setx' method\r\n\r\nA tabela abaixo mostra o modelo sugerido (existem muitos) para cada tipo de dado usando zelig():\r\n\r\n\r\nTipo de Variável Dependente\r\n\r\n\r\nModel em Zelig\r\n\r\n\r\nContínuo\r\n\r\n\r\nls\r\n\r\n\r\nBinário\r\n\r\n\r\nlogit\r\n\r\n\r\n>2 Categorias\r\n\r\n\r\nmlogit\r\n\r\n\r\nCategorias Ordenadas\r\n\r\n\r\nologit\r\n\r\n\r\nContagem (número de eventos em um período fixo)\r\n\r\n\r\npoisson\r\n\r\n\r\nAgora temos um poder enorme. Para ilustrar, se estajamos interessados em analisar o número de vôos atrasados por mais de quatro horas em cada dia, a variável é um número de eventos então preciseramos de um modelo ‘poisson’. É fácil especificar:\r\n\r\n\r\nflights %>% mutate(atraso_serio=case_when(dep_delay>240 ~ 1,\r\n                                           TRUE ~ 0)) %>%\r\n  group_by(origin, month, day) %>%\r\n  summarize(atrasos_serios=sum(atraso_serio, na.rm=T))  %>%\r\n  ungroup() %>% \r\n  zelig(atrasos_serios ~ origin, data=., model=\"poisson\")\r\n\r\n\r\n\r\nModel: \r\n\r\nCall:\r\nz5$zelig(formula = formula, data = data, by = by)\r\n\r\nCoefficients:\r\n            Estimate Std. Error z value Pr(>|z|)\r\n(Intercept)  0.42625    0.04230  10.078  < 2e-16\r\noriginJFK   -0.26004    0.06410  -4.057 4.98e-05\r\noriginLGA   -0.04575    0.06051  -0.756     0.45\r\n\r\n(Dispersion parameter for poisson family taken to be 1)\r\n\r\n    Null deviance: 3944.4  on 1094  degrees of freedom\r\nResidual deviance: 3925.9  on 1092  degrees of freedom\r\nAIC: 5259.8\r\n\r\nNumber of Fisher Scoring iterations: 6\r\n\r\nNext step: Use 'setx' method\r\n\r\nVeja nos resultados que atrasos de mais de quatro horas são menos prováveis (coeficiente negativo) em JFK comparando com EWR (a categoria ‘base’), mas não tem diferença estatisticamente significativa entre LGA e EWR.\r\nOrganizando os resultados de Zelig exige mais um passo para encaminhar os resultados ao Stargazer para criar tabelas, com a função de ajuda from_zelig_model():\r\n\r\n\r\nflights %>% mutate(atraso=case_when(dep_delay>0~1,\r\n                                    TRUE~0)) %>%\r\n  zelig(atraso ~ origin, data=., model=\"logit\") %>%\r\n  from_zelig_model() %>%\r\n  stargazer(type=\"html\")\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nDependent variable:\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\natraso\r\n\r\n\r\n\r\n\r\noriginJFK\r\n\r\n\r\n-0.243***\r\n\r\n\r\n\r\n(0.008)\r\n\r\n\r\n\r\n\r\n\r\n\r\noriginLGA\r\n\r\n\r\n-0.489***\r\n\r\n\r\n\r\n(0.009)\r\n\r\n\r\n\r\n\r\n\r\n\r\nConstant\r\n\r\n\r\n-0.257***\r\n\r\n\r\n\r\n(0.006)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nObservations\r\n\r\n\r\n336,776\r\n\r\n\r\nLog Likelihood\r\n\r\n\r\n-222,299.000\r\n\r\n\r\nAkaike Inf. Crit.\r\n\r\n\r\n444,604.000\r\n\r\n\r\n\r\n\r\nNote:\r\n\r\n\r\np<0.1; p<0.05; p<0.01\r\n\r\n\r\nPrevisões e Resíduos de Regressões\r\nUma regressão também gera novos dados para cada observação - por exemplo, o valor da variável dependente prevista por nossa regressão, ou os resíduos entre o valor atual e o valor previsto. Dado que há um valor para cada observação, faz sentido adicionar estes valores ao nosso banco de dados (tibble) original.\r\nA função augment() (do pacote broom) permite isso - começando com o nosso modelo rodado acima, augment() gera um novo tibble com os dados originais usados na regressão, mais as colunas adicionais com os resultados da regressão.\r\n\r\n\r\nreg1 %>% augment()\r\n\r\n\r\n\r\n\r\n\r\n\r\nSimulações de Regressões\r\nUma regressão é também uma ‘maquina’ para prever o que vai acontecer com a variável dependente quando as variáveis independentes assumem valores específicos. Claro que a qualidade da previsão pode ser terrível se o modelo não seja correta.\r\nCom o zelig, é fácil gerar essas previsões para valores novos. Seguimos a nossa regressão com uma definição dos valores de variáveis independentes que queremos avaliar usando a função setx(), com um valor para cada variável, e depois a função sim(), sem argumento. Por exemplo, se rodamos um modelo linear para prever o atraso com o horário de partida das 5h na manhã:\r\n\r\n\r\nflights  %>%\r\n  zelig(dep_delay ~ dep_time, data=., model=\"ls\") %>% \r\n  setx(dep_time=0500) %>%\r\n  sim()\r\n\r\n\r\n\r\n\r\n sim x :\r\n -----\r\nev\r\n       mean        sd       50%      2.5%     97.5%\r\n1 -5.554096 0.1374694 -5.552973 -5.816669 -5.280309\r\npv\r\n          mean       sd       50%      2.5%    97.5%\r\n[1,] -4.306131 39.53559 -4.689806 -85.39364 70.92373\r\n\r\nCall:\r\nlm(formula = dep_delay ~ dep_time, data = .)\r\n\r\nCoefficients:\r\n(Intercept)     dep_time  \r\n  -16.27245      0.02143  \r\n\r\nQual é o resultado? São valores previstos - a linha de ‘ev’ é a previsão do atraso se voamos as 5h da manhã, -5.5 minutos na média, que significa que voos nesse horário, em média, decolam 5.5 minutos antes do horário previsto.\r\nEm contraste, quando especificamos o horário de partido das 17h, o atraso média é 20 minutos. (Note que se tivéssemos mais variáveis explicativas, o setx automaticamente fixa os valores na média da variável se não especificamos elas explicitamente.)\r\n\r\n\r\nflights  %>%\r\n  zelig(dep_delay ~ dep_time, data=., model=\"ls\") %>% \r\n  setx(dep_time=1700) %>%\r\n  sim()\r\n\r\n\r\n\r\n\r\n\r\nFinalmente, podemos avaliar a diferença em atraso entre os dois horários, com a adição da função setx1() para especificar o ponto de comparação com setx():\r\n\r\n\r\nflights  %>%\r\n  zelig(dep_delay ~ dep_time, data=., model=\"ls\") %>% \r\n  setx(dep_time=0500) %>%\r\n  setx1(dep_time=1700) %>%\r\n  sim()\r\n\r\n\r\n\r\n\r\n sim x :\r\n -----\r\nev\r\n       mean        sd       50%      2.5%     97.5%\r\n1 -5.556242 0.1363321 -5.554838 -5.820189 -5.284274\r\npv\r\n          mean       sd     50%      2.5%    97.5%\r\n[1,] -6.429133 39.01868 -6.9923 -83.51135 72.86603\r\n\r\n sim x1 :\r\n -----\r\nev\r\n      mean         sd      50%    2.5%    97.5%\r\n1 20.15619 0.08287173 20.15704 19.9925 20.32219\r\npv\r\n         mean       sd      50%      2.5%    97.5%\r\n[1,] 19.49994 37.48289 19.02482 -53.57535 93.89565\r\nfd\r\n      mean        sd      50%     2.5%    97.5%\r\n1 25.71243 0.1645674 25.71065 25.38607 26.02857\r\n\r\nAgora, foca-se na linha fd, que mostra uma diferença de 25.7 minutos na média: muito melhor voar cedo!\r\nComo todas as nossas estimativas de regressões, nunca temos certeza sobre as relações - existe incerteza sobre os nossas estimativas - e o zelig deixa fácil mostrar isso com mais um passo no fluxo de funções. Com get_qi() podemos gerar uma distribuiçõ simulada - uma nova variável - de estimativas da diferença média, incorporando o desvío padrão de incerteza.\r\n\r\n\r\ndiff_simulacoes <- flights  %>%\r\n  zelig(dep_delay ~ dep_time, data=., model=\"ls\") %>% \r\n  setx(dep_time=0500) %>%\r\n  setx1(dep_time=1700) %>% \r\n  sim() %>% \r\n  get_qi(xvalue=\"x1\", qi=\"fd\")\r\n\r\n\r\n\r\n\r\n\r\nAgora, é fácil visualizar essa distribuição:\r\n\r\n\r\ndiff_simulacoes %>% as_tibble() %>% \r\n  rename(\"Diff\"=`1`) %>%\r\n  ggplot() +\r\n  geom_density(aes(x=Diff)) +\r\n  ggtitle(\"Atraso Médio Adicional Estimada para voar as 17h em vez de 5h\") +\r\n  theme_minimal()\r\n\r\n\r\n\r\n\r\nExercício 2: Regressões\r\nUsando uma regressão linear, qual é a associação entre precipitação (precip, variável dependente) e as três variáveis pressão (pressure), temperatura (temp) e humidade (humid) no banco de dados weather? Qual dessas três variáveis tem relação positiva com a variável dependente, e qual uma relação negativa?\r\n\r\n\r\nMostrar Código\r\n\r\nmodel1 <- weather %>% lm(precip ~ pressure + temp + humid, data=.) \r\n\r\nmodel1 %>% tidy()\r\n\r\n\r\nExecute mais um modelo de regressão adicionando mais uma variável explicativa do aeroporto de origin ao modelo de questão 1. Mostre os seus dois modelos juntos numa tabela apropriada.\r\n\r\n\r\nMostrar Código\r\n\r\nmodel2 <- weather %>% lm(precip ~ pressure + temp + humid + origin, data=.) \r\n\r\nlist(model1, model2) %>% stargazer(title=\"Modelo de Precipitação, Q2\", \r\n                                   type=\"html\")\r\n\r\n\r\nCrie um gráfico de efeitos marginais para a sua regressão na questão 2.\r\n\r\n\r\nMostrar Código\r\n\r\nmodel2 %>% tidy() %>%\r\n  mutate(conf.lo=estimate-1.96*std.error,\r\n         conf.hi=estimate+1.96*std.error) %>%\r\n  filter(term!=\"(Intercept)\") %>%\r\n  ggplot() +\r\n  geom_point(aes(x=term, y=estimate)) +\r\n  geom_errorbar(aes(x=term, y=estimate, ymin=conf.lo, ymax=conf.hi), width=0.1)\r\n\r\n\r\nExecute uma regressão do tipo ‘logit’ que explica se um vôo dure mais de três horas ou não (gere esta variável) baseado nas variáveis dep_time, distance e origin.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% mutate(mais_de_tres_horas=case_when(air_time>180 ~ 1,\r\n                                    TRUE ~0)) %>%\r\n  zelig(mais_de_tres_horas ~ dep_time + distance + origin, data=., model=\"logit\") %>%\r\n  from_zelig_model() %>%\r\n  stargazer(title=\"Modelo de Duração, Q3\", \r\n                                   type=\"html\")\r\n\r\n\r\nUse a sua regressão de questão 4 e as funções de Zelig para prever quanto mais provável é que um vôo tenha mais de três horas de duração quando a distância aumenta de 700 para 1300 kilometros.\r\n\r\n\r\nMostrar Código\r\n\r\nmodelo_tres_horas <- flights %>% mutate(mais_de_tres_horas=case_when(air_time>180 ~ 1,\r\n                                    TRUE ~0)) %>%\r\n  mutate(origin=factor(origin)) %>%\r\n  zelig(mais_de_tres_horas ~ dep_time + distance + origin, data=., model=\"logit\")\r\n\r\nmodelo_tres_horas %>%\r\n  setx(distance=700) %>%\r\n  setx1(distance=1300) %>%\r\n  sim()\r\n\r\n\r\n\r\n\r\n\r\nPreparação para Tutorial 10\r\nAntes da próxima aula sobre relatórios reproduzíveis com Git e Latex, por favor tente preparar o seu computador:\r\nInstale git no seu computador.\r\nCrie uma conta no site github.\r\nInstale o TinyTex (uma versão apropriada de Latex) usando o seguinte código em RStudio:\r\n\r\n\r\ninstall.packages('tinytex')\r\ntinytex::install_tinytex()\r\n\r\n\r\nLeia a guia introdutória para Latex, um sistema e linguagem de preparação de relatórios profissionais no site de Overleaf\r\n\r\n\r\n\r\nDesafio 4\r\nO Desafio 4 é uma oportunidade para trocar ideais entre vocês, entender os desafios em interpretar o código de outros, e praticar aperfeiçoar scripts reproduzíveis. Vamos pedir que você oferecer comentários sobre o código do Desafio 3 de uma colega na disciplina.\r\nO prazo para entregar Desafio 4 por email com título “[FLS6397] - D4” à minha conta é 07/07/2022. Por favor entregue apenas o arquivo .Rmd, incluindo os seus comentários adicionais.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:23:28-03:00"
    },
    {
      "path": "Repeticao.html",
      "title": "Repetição",
      "author": [],
      "contents": "\r\n\r\nContents\r\nIntrodução\r\nFunções Customizadas\r\nRepetindo a aplicação de funções (map, map_df)\r\nRepetindo a aplicação de funções para vetores fora de um tibble\r\nRepetindo a aplicação de funções para uma lista\r\nGerando Novas Colunas com map e mutate\r\n\r\nIntrodução\r\nUsar scripts de programação para a análise de dados tem várias vantagens: transparência, reprodutibilidade, etc. Mas uma vantagem fundamental é a capacidade para ganhar escala e para repetição das nossas análises várias vezes, sem repetir o código. A ideia é que podemos preparar uma análise para produzir uma estatística, uma tabela, um gráfico, um teste estatístico ou uma regressão para variáveis e valores específicos, e indicar para R refazer a análise várias vezes, deixando alguns elementos da análise fixos e permitindo a outros variarem.\r\nPor exemplo, imagine que nós queremos calcular a amplitude de uma variável: o máximo menos o mínimo. E queremos rodar a análise para três variáveis:\r\n\r\n\r\nlibrary(\"nycflights13\")\r\nlibrary(\"tidyverse\")\r\n\r\nmax_dep_delay <- flights %>% pull(dep_delay) %>% max(na.rm=T)\r\nmin_dep_delay <- flights %>% pull(dep_delay) %>% min(na.rm=T)\r\nmax_dep_delay - min_dep_delay\r\n\r\nmax_arr_delay <- flights %>% pull(arr_delay) %>% max(na.rm=T)\r\nmin_arr_delay <- flights %>% pull(arr_delay) %>% min(na.rm=T)\r\nmax_arr_delay - min_arr_delay\r\n\r\nmax_distance <- flights %>% pull(distance) %>% max(na.rm=T)\r\nmin_distance <- flights %>% pull(distance) %>% min(na.rm=T)\r\nmax_distance - min_arr_delay\r\n\r\n\r\nVeja quanto do código aqui é repetido! Nove linhas e a única coisa que varia é o nome da variável… Não é simplesmente o esforço de digitação que é problemático aqui - mesmo que copiemos e colemos, temos que lembrar quais elementos precisamos atualizar. Se esquecermos apenas uma mudança, a nossa análise estará errada. Isso é responsável por uma grande parcela de erros na análise de dados. Vocês já identificaram o erro no código acima??\r\nFunções Customizadas\r\nO uso de repetição exige uma separação clara dos dois elementos fundamentais de programação em R: Objetos (tibbles, vetores, valores únicos), e Funções (ações que recebem insumos e geram produtos). Com repetição, normalmente fixamos as funções e ajustamos os objetos, para que os insumos às funções variem, e avaliamos a variação nos produtos finais. A função só precisa ser escrita uma vez, evitando a repetição manual do cálculo.\r\nPodemos gerar uma função que aceita um vetor (uma coluna de nosso tibble), e encaminhar várias colunas para a nossa função. (Revise a introdução a funções em Tutorial 4 se ajudar). Com o exemplo de calcular amplitude:\r\n\r\n\r\n\r\n\r\n\r\namplitude <- function(x) {\r\n  resultado <- max(x, na.rm=T) - min(x, na.rm=T)\r\n  return(resultado)\r\n}\r\n\r\nflights %>% pull(dep_delay) %>% amplitude()\r\nflights %>% pull(arr_delay) %>% amplitude()\r\nflights %>% pull(distance) %>% amplitude()\r\n\r\n\r\nO código aqui gera uma nova função chamada amplitude que recebe um vetor (o x). Dentro dos chaves ({, }) colocamos o nosso cálculo de amplitude - o máximo do vetor x menos o mínimo de x que salvamos como objeto resultado. E finalmente indicamos para a função devolver o valor de resultado como o produto da função. Assim, amplitude fica disponível como qualquer outra função de R para aplicaçõ às variáveis de interesse.\r\nO uso da função já acelera bastante a análise! E também deixa fácil ajustar o cálculo no futuro. Por exemplo, para arredondar os resultados, é só incorporar uma vez na função, e vai afetar todos os cálculos seguintes:\r\n\r\n\r\namplitude <- function(x) {\r\n  resultado <- max(x, na.rm=T) - min(x, na.rm=T)\r\n  return(round(resultado, 0))\r\n}\r\n\r\nflights %>% pull(dep_delay) %>% amplitude()\r\nflights %>% pull(arr_delay) %>% amplitude()\r\nflights %>% pull(distance) %>% amplitude()\r\n\r\n\r\nRepetindo a aplicação de funções (map, map_df)\r\nA parte chata do código acima é que não economizamos tantas linhas de código - temos 6 linhas - e ainda precisamos repetir as linhas finais para aplicar a função à cada variável, abrindo oportunidades para erros.\r\nÉ possível automatizar a aplicação da função? Sim! A função map é bem flexível e permite a aplicação de uma função à uma série de objetos. Os objetos podem ser listas - vamos ver exemplos disso em breve - ou vetores, por exemplo as colunas do nosso tibble. O argumento de map é o nome da função que queremos aplicar.\r\nEm nosso exemplo de amplitude, podemos select as colunas para as quais queremos calcular a amplitude, e map a função amplitude para cada coluna:\r\n\r\n\r\namplitude <- function(x) {\r\n  resultado <- max(x, na.rm=T) - min(x, na.rm=T)\r\n  return(resultado)\r\n}\r\nflights %>% select(dep_delay, arr_delay, distance) %>% \r\n  map(amplitude)\r\n\r\n\r\nMuito mais simples! Agora em mais ou menos quatro linhas. E note o quanto é fácil ampliar a análise para mais variáveis - é só incluí-las dentro de select:\r\n\r\n\r\nflights %>% select(dep_delay, arr_delay, distance, air_time) %>% \r\n  map(amplitude)\r\n\r\n$dep_delay\r\n[1] 1344\r\n\r\n$arr_delay\r\n[1] 1358\r\n\r\n$distance\r\n[1] 4966\r\n\r\n$air_time\r\n[1] 675\r\n\r\nQual o formato do resultado de map? Inspecione ele com class(). É uma lista, um formato genérico e flexível que vamos discutir em breve, mas em geral nesse curso sempre preferimos trabalhar com tibbles. Felizmente, existe uma variedade de map que padroniza o resultado da aplicação repetida da função para um tibble, map_df:\r\n\r\n\r\nflights %>% select(dep_delay, arr_delay, distance, air_time) %>% \r\n  map_df(amplitude)\r\n\r\n\r\n\r\n\r\ndep_delay\r\n\r\n\r\narr_delay\r\n\r\n\r\ndistance\r\n\r\n\r\nair_time\r\n\r\n\r\n1344\r\n\r\n\r\n1358\r\n\r\n\r\n4966\r\n\r\n\r\n675\r\n\r\n\r\nRepetindo a aplicação de funções para vetores fora de um tibble\r\nObserve que a funcionalidade aqui é bem parecida de summarize(across()) do Tutorial 4, permitindo a aplicação de uma função à várias colunas. É verdade, mas o ganho de map é que ela é mais geral e pode ser usada fora do contexto de mutate e summarize, e fora de um tibble único. Por exemplo, imagine que temos um vetor de centenas de arquivos .csv para abrir em R na pasta do nosso projeto - map permite aplicar a função de read_csv para todos os arquivos em uma linha só (gerando dois arquivos de csv primeiramente para ilustrar):\r\n\r\n\r\nflights %>% filter(month==1 & day==1) %>% write_csv(\"flights_jan_01.csv\")\r\nflights %>% filter(month==1 & day==2) %>% write_csv(\"flights_jan_02.csv\")\r\n\r\narquivos <- c(\"flights_jan_01.csv\", \"flights_jan_02.csv\")\r\n\r\ndados <- arquivos %>% map(read_csv)\r\n\r\n\r\nA repetição (‘iteração’) aqui não é sobre múltiplas colunas, mas sobre cada elemento do vetor ‘arquivos’. O resultado ‘dados’ é uma lista. Dentro da lista existem, separadamente, dois tibbles. Para rastrear as diferenças entre os elementos da lista é sempre uma boa ideia nomear os elementos - realizamos isso com a função set_names() antes de uso de map:\r\n\r\n\r\ndados <- arquivos %>% set_names() %>% \r\n  map(read_csv)\r\n\r\n\r\nTemos duas opções para juntar os dois tibbles em um tibble. Podemos substituir map_df para map, como já aprendemos acima. Ou podemos manter map e seguir com bind_rows() que junta tibbles verticalmente:\r\n\r\n\r\ndados <- arquivos %>% map_df(read_csv)\r\n\r\ndados <- arquivos %>% map(read_csv) %>%\r\n  bind_rows()\r\n\r\n\r\nRepetindo a aplicação de funções para uma lista\r\nAté agora, utilizamos map para transformar um vetor (fora de um tibble como vetor mesmo, ou como uma coluna dentro de um tibble) em uma lista ou um tibble. Existe mais uma combinação possível - usar uma lista como o insumo de map. O grande valor aqui é quando queremos trabalhar com múltiplos tibbles.\r\nmap funciona com vetores ou listas, aplicando a função a cada elemento do vetor/lista. Listas são úteis porque eles podem conter uma variedade de outros objetos - valores únicos, vetores, tibbles, outra listas. Se tivermos vários tibbles - por exemplo bancos de dados de anos distintos - podemos organizar eles em uma lista.\r\n\r\nHabilidade Básica de Programação: Listas\r\nUma lista é um conjunto de objetos diversos organizados verticalmente. Não é um tibble com linhas e colunas, listas só têm ‘elementos’, caixas vazias para guardar qualquer tipo de objeto - valores únicos, tibbles ou outras listas. Vetores também são objetos unidimensionais, mas diferem de listas porque vetores apenas contém objetos simples - valores únicos - e de um único tipo (numérico, caracter, lógico etc.).\r\nEm R, listas são fáceis de construir com list(objeto1, objeto2, ...). Vamos ver como parece uma lista de uma mistura de objetos:\r\n\r\n\r\nobjeto1 <- flights %>% filter(month==1 & day==1)\r\nobjeto2 <- 3.14\r\nobjeto3 <- flights %>% filter(month==1 & day==2)\r\nobjeto4 <- \"teste\"\r\n\r\nlista_exemplo <- list(objeto1, objeto2, objeto3, objeto4)\r\nlista_exemplo\r\n\r\n[[1]]\r\n# A tibble: 842 × 19\r\n    year month   day dep_time sched_dep_time dep_delay arr_time\r\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>\r\n 1  2013     1     1      517            515         2      830\r\n 2  2013     1     1      533            529         4      850\r\n 3  2013     1     1      542            540         2      923\r\n 4  2013     1     1      544            545        -1     1004\r\n 5  2013     1     1      554            600        -6      812\r\n 6  2013     1     1      554            558        -4      740\r\n 7  2013     1     1      555            600        -5      913\r\n 8  2013     1     1      557            600        -3      709\r\n 9  2013     1     1      557            600        -3      838\r\n10  2013     1     1      558            600        -2      753\r\n# ℹ 832 more rows\r\n# ℹ 12 more variables: sched_arr_time <int>, arr_delay <dbl>,\r\n#   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\r\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\r\n#   minute <dbl>, time_hour <dttm>\r\n\r\n[[2]]\r\n[1] 3.14\r\n\r\n[[3]]\r\n# A tibble: 943 × 19\r\n    year month   day dep_time sched_dep_time dep_delay arr_time\r\n   <int> <int> <int>    <int>          <int>     <dbl>    <int>\r\n 1  2013     1     2       42           2359        43      518\r\n 2  2013     1     2      126           2250       156      233\r\n 3  2013     1     2      458            500        -2      703\r\n 4  2013     1     2      512            515        -3      809\r\n 5  2013     1     2      535            540        -5      831\r\n 6  2013     1     2      536            529         7      840\r\n 7  2013     1     2      539            545        -6      959\r\n 8  2013     1     2      554            600        -6      845\r\n 9  2013     1     2      554            600        -6      841\r\n10  2013     1     2      554            600        -6      909\r\n# ℹ 933 more rows\r\n# ℹ 12 more variables: sched_arr_time <int>, arr_delay <dbl>,\r\n#   carrier <chr>, flight <int>, tailnum <chr>, origin <chr>,\r\n#   dest <chr>, air_time <dbl>, distance <dbl>, hour <dbl>,\r\n#   minute <dbl>, time_hour <dttm>\r\n\r\n[[4]]\r\n[1] \"teste\"\r\n\r\nSe você abre o objeto lista_exemplo no seu Environment, vai aparecer assim, deixando claro os quatro elementos de vários tipos:\r\nA estrutura de uma listaSe rodar o código lista_exemplo no Console, o R vai mostrar o seu conteúdo com quatro elementos, designado com o sintaxe: [[1]], [[2]] etc. Os colchetes duplos indicam um elemento de uma lista.\r\nPara acessar um elemento único de uma lista, é só indicar qual elemento deseja com os colchetes:\r\n\r\n\r\nlista_exemplo[[1]]\r\n\r\n\r\nTambém podemos nomear os elementos de uma lista para guardar eles mais sistematicamente:\r\n\r\n\r\nlista_exemplo_nomes <- list(tibble1=objeto1, \r\n                      numero=objeto2, \r\n                      tibble2=objeto3, \r\n                      string=objeto4)\r\n\r\nlista_exemplo_nomes\r\n\r\nlista_exemplo_nomes[[\"string\"]]\r\n\r\n\r\nNote que as ações do tidyverse (select, filter, slice etc.) não funcionam com listas. Temos que trabalhar com as ferramentas básicas de R, ou aplicar funções com map como ilustrado neste tutorial.\r\n\r\n\r\nPara entender o uso de map com listas, e especificamente com diversos tibbles, vamos separar o banco de dados de flights em dois meses, organizar eles em uma lista (com a função list()), e aplicar uma função a cada banco (cada tibble). Como exemplo, vamos calcular o atraso médiao por aeroporto com summarize().\r\n\r\n\r\nflights_jan <- flights %>% filter(month==1)\r\nflights_fev <- flights %>% filter(month==2)\r\n\r\nflights_jan_fev <- list(janeiro=flights_jan, \r\n                        fevereiro=flights_fev)\r\n\r\nflights_jan_fev %>% map(summarize, dep_delay=mean(dep_delay, na.rm=T))\r\n\r\n$janeiro\r\n# A tibble: 1 × 1\r\n  dep_delay\r\n      <dbl>\r\n1      10.0\r\n\r\n$fevereiro\r\n# A tibble: 1 × 1\r\n  dep_delay\r\n      <dbl>\r\n1      10.8\r\n\r\nFácil, sim? Não tem tanta diferença entre list(), criando uma lista, e c(), criando um vetor: a diferença é simplesmente que cada elemento de c() tem que ser um valor único, enquanto list() é mais flexível, aceitando qualquer tipo e tamanho de objeto, incluindo tibbles.\r\nAs listas também facilitam a aplicação de nomes aos elementos, que torna mais intuitivo o acesso aos elementos no futuro, e de forma automatizada com outras funções.\r\nO resultado seria ainda mais claro e acessível se forçamos a produção de um tibble em vez de uma lista:\r\n\r\n\r\nflights_jan_fev %>% map_df(summarize, dep_delay=mean(dep_delay, na.rm=T))\r\n\r\n# A tibble: 2 × 1\r\n  dep_delay\r\n      <dbl>\r\n1      10.0\r\n2      10.8\r\n\r\nHá apenas um problema com o resultado aqui - não sabemos qual valor descreve qual mês! É importante manter a identificação dos nossos resultados, e seria útil ter uma coluna com o nome do mês dentro do tibble. Isso é possível a partir dos nomes dos elementos da lista (os tibbles) que contém os detalhes de cada mês. Apenas especificamos um argumento adicional em map_df: o nome da nova coluna no argumento .id=\"nome_de_coluna\".\r\n\r\n\r\nflights_jan_fev %>% map_df(summarize, dep_delay=mean(dep_delay, na.rm=T),\r\n                           .id=\"Mês\")\r\n\r\n# A tibble: 2 × 2\r\n  Mês       dep_delay\r\n  <chr>         <dbl>\r\n1 janeiro        10.0\r\n2 fevereiro      10.8\r\n\r\nAgora, vale a pena resumir os usos de map, porque estamos trabalhando num nível mais abstrato e mais flexível, com uma variedade grande de opções:\r\n\r\n\r\nTable 1: Usos possíveis de map\r\n\r\n\r\nFunção\r\n\r\n\r\nInsumo\r\n\r\n\r\nProduto\r\n\r\n\r\nmap\r\n\r\n\r\nMúltiplas Colunas de um Tibble (com select)\r\n\r\n\r\nLista\r\n\r\n\r\nmap\r\n\r\n\r\nUm Vetor\r\n\r\n\r\nLista\r\n\r\n\r\nmap\r\n\r\n\r\nUma Lista\r\n\r\n\r\nLista\r\n\r\n\r\nmap_df\r\n\r\n\r\nMúltiplas Colunas de um Tibble (com select)\r\n\r\n\r\nTibble\r\n\r\n\r\nmap_df\r\n\r\n\r\nUm Vetor\r\n\r\n\r\nTibble\r\n\r\n\r\nmap_df\r\n\r\n\r\nUma Lista\r\n\r\n\r\nTibble\r\n\r\n\r\nTanta flexibilidade exige cuidado por nosso lado - temos que entender bem qual é o tipo de objeto que contém os itens sobre os quais queremos repetir a função, e qual é o produto desejado.\r\nA família de funções de map ajuda bastante na repetição porque elas automatizam o processo de substituição de cada insumo na função, e a organização do resultado. Porém, é uma família nova, e historicamente a repetição foi realizada com uma ferramenta mais manual, o ‘for loop’. Recomendamos trabalhar com map quando possível para simplicidade, mas é útil e pedagogicamente interessante entender os for loops, então incluímos uma introdução rápida na caixa abaixo.\r\n\r\nHabilidade Básica de Programação: For Loops\r\nUma forma alternativa para repetir ações em R é o uso de ‘for’ loops. Eles são muito comuns em programação, então é bom conhecer. Mas se você conseguir usar map, normalmente é mais eficiente.\r\nUm for loop literalmente repete uma ação várias vezes, substituindo um valor novo cada vez. Há quatro elementos num ‘for’ loop:\r\nA função para repetir - flights %>% pull(i) %>% amplitude(). o i significa o valor/a variável que queremos ajustar cada iteração.\r\nUma definição num vetor dos valores para substituir na função no lugar de ‘i’ - elementos <- c(\"dep_delay\", \"arr_delay\", \"distance\").\r\nA definição do loop mesmo - for (i in elementos) { }. Isso significa que a função dentro das chaves se repete para cada valor do vetor elementos, cada vez substituindo o i na função pelo valor correspondente de elementos.\r\nUm objeto final para guardar os resultados - Dado que vamos repetir a função várias vezes, precisamos de um objeto que aceita múltiplos valores, ou seja, um vetor. Podemos criar anteriormente um vetor vazio com resultado <- c(), e dentro da função salva a amplitude calculada com nome do elemento atual i.\r\n\r\n\r\nelementos <- c(\"dep_delay\", \"arr_delay\", \"distance\")\r\n\r\nresultado <- c()\r\n\r\nfor (i in elementos) {\r\n  resultado[i] <- flights %>% pull(i) %>% amplitude()\r\n}\r\n\r\n\r\n\r\ndep_delay arr_delay  distance \r\n     1344      1358      4966 \r\n\r\nVeja de novo a lógica do ‘for’ loop: a linha da função contém duas instâncias de ‘i’: o índice do destino no resultado e a variável para analisar dentro de pull(). A questão é simplesmente quais variáveis para substituir para ‘i’. Elas são definidas pela linha anterior: i in elementos - todas as variáveis definidas no vetor ‘elementos’ .\r\n\r\nMais uma alternativa: Se você não saiba o número de repetições necessárias, pode repetir até que uma condição seja atendida com um while loop, por exemplo:\r\n\r\n\r\nwhile (condição) {\r\n ...\r\n}\r\n\r\n\r\n\r\n\r\nExercício 1: Repetição\r\nGere três tibbles separados derivados do banco de dados flights, um para cada aeroporto de origem (origin). Em seguida, coloque os três tibbles em uma lista única (list()), com o nome de cada elemento da lista a sigla do aeroporto.\r\n\r\n\r\nMostrar Código\r\n\r\nEWR <- flights %>% filter(origin==\"EWR\")\r\nJFK <- flights %>% filter(origin==\"JFK\")\r\nLGA <- flights %>% filter(origin==\"LGA\")\r\n\r\nflights_por_origem <- list(EWR=EWR,\r\n                           JFK=JFK,\r\n                           LGA=LGA)\r\n\r\n#Ou, mais eficiente: flights_por_origem <- flights %>% split(.$origin)\r\n\r\n\r\nUse map para calcular o número de observações (voos) em cada tibble usando a função nrow.\r\n\r\n\r\nMostrar Código\r\n\r\nflights_por_origem %>% map(nrow)\r\n\r\n\r\nFiltre os três bancos de questão 1 para vôos com destino ‘SFO’ (San Francisco) usando map. Quantos voos (observações) têm cada aeroporto de Nova Iorque para SFO?\r\n\r\n\r\nMostrar Código\r\n\r\nflights_por_origem %>% map(filter, dest==\"SFO\") %>% \r\n  map(nrow)\r\n\r\n\r\nPara cada um dos três bancos de dados de questão 1, calcule a velocidade de cada voo usando map.\r\n\r\n\r\nMostrar Código\r\n\r\nflights_por_origem <- flights_por_origem %>% \r\n  map(mutate, velocidade=distance/air_time)\r\n\r\n\r\nBaseado no seu resultado da questão 4, resuma cada um dos três bancos para calcular a média da velocidade dos voos usando uma função da família map. O resultado deve ser um tibble com todos os detalhes apropriados.\r\n\r\n\r\nMostrar Código\r\n\r\nflights_por_origem %>% map_df(summarize, dep_delay=mean(velocidade, na.rm=T),\r\n                              .id=\"Aeroporto\")\r\n\r\n\r\n\r\nGerando Novas Colunas com map e mutate\r\nTodas as aplicações de map acima produzem novos tibbles ou listas. Mas quando os resultados da aplicação da função cabem no tibble original - por exemplo, cada linha do tibble é um estado e temos um resultado por cada estado - é desejável manter os resultados dentro do tibble original, e apenas adicionar mais uma coluna.\r\nNeste caso, uma forma muito útil de usar map é dentro de mutate. Isso permite inserir os resultados do cálculo repetido em uma nova coluna em nosso tibble. Veja uma forma interessante de abrir os arquivos .csv - podemos gerar um tibble com a primeira coluna documentando os nomes dos arquivos, e depois usar map conjunto com read_csv para inserir os dados de cada arquivo em uma nova coluna. O nosso tibble agora é mais parecido com um armário de arquivos, com cada gaveta bem marcada.\r\nNote que agora temos que indicar para map para qual coluna queremos aplicar a função read_csv - a ordem é map(coluna, função). Cada linha reflete um arquivo, e os dados - literalmente os tibbles - ficam ‘nested’ numa lista-coluna (como descobrimos no tutorial 7).\r\n\r\n\r\n\r\n\r\n\r\ndados_nested <- tibble(dia=c(1, 2),\r\n                       file=c(\"flights_jan_01.csv\", \r\n                              \"flights_jan_02.csv\")) %>% \r\n  mutate(conteudo=map(file, read_csv))\r\n\r\ndados_nested\r\n\r\n# A tibble: 2 × 3\r\n    dia file               conteudo             \r\n  <dbl> <chr>              <list>               \r\n1     1 flights_jan_01.csv <spc_tbl_ [842 × 19]>\r\n2     2 flights_jan_02.csv <spc_tbl_ [943 × 19]>\r\n\r\nEste procedimento pode ajudar a organizar bases de dados grandes, pois podemos trabalhar com uma tabela simples de resumo, e não múltiplas tabelas inteiras.\r\nRepetindo Funções com Tibbles Nested\r\nQual é a classe da coluna de ‘conteudo’ no tibble dados_nested? É uma lista, uma lista de tibbles. Então o nosso fluxo de análise não precisa parar aqui. Podemos continuar usando map para aplicar uma função para cada tibble separadamente.\r\nPor exemplo, vamos adicionar uma nova coluna no tibble de resumo com o número de voos (o número de observações) em cada banco/linha.\r\n\r\n\r\ndados_nested <- dados_nested %>% \r\n  mutate(num_voos=map(conteudo, nrow))\r\n\r\n\r\nPare, Como aparece dados_nested agora? Na coluna num_voos temos uma coisa estranha <int [1]> - isso significa que existe um número dentro da lista, mas não está sendo apresentado. Isso acontece porque map produz uma lista-coluna por padrão. É melhor usar uma variedade de map para resultados que são valores únicos numéricos: map_dbl (de ‘double’, o tipo de variável numérica).\r\n\r\n\r\ndados_nested <- dados_nested %>% \r\n  mutate(num_voos=map_dbl(conteudo, nrow))\r\n\r\n\r\nBem melhor - agora podemos ver o número de linhas diretamente em nossa tabela. Também é possível aplicar uma função customizada para cada banco. Por exemplo, se quisermos resumir a correlação entre dep_delay e dep_time para cada banco, é só escrever uma função que executa esse cálculo para um tibble genérico, e aplicar a função dentro de map para a coluna apropriada:\r\n\r\n\r\ncorr_function <- function(tibble) {\r\n  tibble %>% cor.test(~ dep_delay + dep_time, data=.) %>%\r\n    tidy()\r\n}\r\n\r\ndados_nested <- dados_nested %>% \r\n  mutate(corr=map(conteudo, corr_function))\r\n\r\n\r\nAgora temos todos os resultados do teste de correlação na coluna corr. Para deixar apenas a estimativa central de correlação visível, podemos adaptar a função para extrair o valor específico desejado.\r\n\r\n\r\ncorr_function <- function(tibble) {\r\n  tibble %>% cor.test(~ dep_delay + dep_time, data=.) %>%\r\n    tidy() %>%\r\n    pull(estimate)\r\n}\r\n\r\ndados_nested <- dados_nested %>% \r\n  mutate(corr=map_dbl(conteudo, corr_function))\r\n\r\n\r\nRepetindo Análises\r\nÉ comum em análises empíricas executar várias estimativas. Por exemplo, com regressões podemos ajustar o banco de dados para estimar resultados em amostras diversas. Vamos usar este exemplo para aprender como executar múltiplas regressões em uma única linha de código.\r\nComeçamos com uma regressão simples:\r\n\r\n\r\nflights %>% lm(dep_delay ~ dep_time, data=.)\r\n\r\n\r\nCall:\r\nlm(formula = dep_delay ~ dep_time, data = .)\r\n\r\nCoefficients:\r\n(Intercept)     dep_time  \r\n  -16.27245      0.02143  \r\n\r\nA nossa primeira tarefa é repetir a regressão para vários bancos de dados. Vamos aproveitar da nossa tabela dados_nested. Inserindo a regressão lm dentro de map e mutate aplica a regressão para o banco de dados em cada linha (na coluna ‘conteudo’), e guarda os resultados em uma nova coluna.\r\nPorém, em vez de especificar uma função customizada para aplicação com map, vamos gerar a função de regressão ‘na hora’ (‘anonimamente’) diretamente dentro de map com o uso de til ~ antes da função. É apenas um atalho para facilitar; claro que fica melhor definir uma função explícita anteriormente para cálculos mais complexos.\r\n\r\n\r\ndados_nested <- dados_nested %>% \r\n  mutate(regressão=map(conteudo, ~lm(dep_delay ~ dep_time, data=.)))\r\n\r\n\r\nAgora temos o resultado básico da regressão em nosso tibble. Provavelmente queremos limpar isso para tornar o resultado principal mais acessível. Por exemplo, podemos aplicar tidy com mais uma chamada de mutate e map para gerar um tibble dos resultados:\r\n\r\n\r\ndados_nested <- dados_nested %>% \r\n  mutate(regressão=map(regressão, tidy))\r\n\r\n\r\nE se quisermos extrair um coeficiente de interesse para o tibble de resumo:\r\n\r\n\r\ndados_nested <- dados_nested %>% \r\n  mutate(coef=map(regressão, filter, term==\"dep_time\"),\r\n         coef=map_dbl(coef, pull, estimate))\r\n\r\n\r\nObserve um ponto importante aqui - quando aplicamos uma função com map sem o uso de ~, os argumentos adicionais à função não ficam em parênteses, mas depois de uma vírgula.\r\nNa situação em que começamos com um banco de dados inteiro e queremos aplicar uma regressão por grupo, em que o grupo é definido por uma variável, é só usar group_by e nest para preparar o tibble apropriado. Por exemplo, aplicando regressões distintas por aeroporto de origem:\r\n\r\n\r\nflights_reg_por_origem <- flights %>% \r\n  group_by(origin) %>%\r\n  nest() %>%\r\n  mutate(regressão=map(data, ~lm(dep_delay ~ dep_time, data=.)),\r\n         regressão=map(regressão, tidy),\r\n         coef=map(regressão, filter, term==\"dep_time\"),\r\n         coef=map_dbl(coef, pull,estimate))\r\n\r\n\r\nPreparando, executando, e resumindo três regressões em uma única linha de código., parabéns!\r\nMapeando argumentos múltiplos\r\nNão é apenas o banco de dados que é possível ajustar numa regressão - o lm aceita vários argumentos: ‘data’, mas também ‘formula’, o modelo da regressão. Isso é comum - funções aceitam vários argumentos e às vezes queremos variar mais que um argumento ao longo da nossa repetição. Por exemplo, eu queria rodar modelos A e B para banco de dados X e Y, modelo C para banco de dados Y e Z, e modelo D para banco de dados Z.\r\nOperações desta forma exigem que indiquemos para map duas colunas para encaminhar a nossa função, uma para cada argumento. É simples: verificamos que as duas colunas desejadas existem no tibble, usamos map2 em vez de map, e indicamos os nomes das duas colunas no map2, no ordem em que eles são esperados pela função que vamos aplicar.\r\n\r\n\r\ndados_nested <- dados_nested %>% mutate(formula=c(\"dep_delay ~ dep_time\",\r\n                                  \"arr_delay ~ dep_time\"))\r\n\r\ndados_nested <- dados_nested %>% mutate(resultados=map2(formula, conteudo, lm))\r\n\r\n\r\nAgora, os dois resultados refletem ambos uma amostra (banco de dados) e uma fórmula diferente para cada linha do tibble original (cada aeroporto de origem).\r\nCom as funções de tidyverse básico e a família de map, agora você consegue executar quase qualquer tarefa de análise de dados - são um conjunto de ferramentas muito poderoso. As possibilidades são infinitas- para mais informação e operações mais complexas, veja o cheatsheet aqui.\r\n\r\nExercício 2: Programação Funcional\r\nGere um tibble ‘nested’ com uma linha para cada mês usando o banco de dados weather.\r\n\r\n\r\nMostrar Código\r\n\r\nweather_month <- weather %>% group_by(month) %>% nest()\r\n\r\n\r\nAdicione uma coluna ao tibble gerado em questão 1 que mostra o número de observações em cada mês.\r\n\r\n\r\nMostrar Código\r\n\r\nweather_month <- weather_month %>% mutate(obs=map_dbl(data, nrow))\r\n\r\n\r\nUsando o seu banco de dados nested de questão 2, execute uma regressão para cada mês separadamente, com ‘precip’ (chuva) na variável dependente e ‘temp’ (temperatura) na variável independente na fórmula. Salve o coeficiente da variável temperatura numa coluna nova.\r\n\r\n\r\nMostrar Código\r\n\r\nweather_month %>% mutate(regressão=map(data, ~lm(precip ~ temp, data=.)),\r\n                         coef=map(regressão, tidy),\r\n                         coef=map(coef, filter, term==\"temp\"),\r\n                         coef=map_dbl(coef, pull, estimate))\r\n\r\n\r\nSepare a coluna de temperatura de cada mês em uma nova coluna nested como um vetor para cada mês, e aplique um teste shapiro (veja tutorial 9, shapiro.test) de normalidade para a temperatura de cada mês, processando o resultado para que o valor ‘p’ seja visível no tibble de resumo por mês.\r\n\r\n\r\nMostrar Código\r\n\r\nweather_month <- weather_month %>% \r\n  mutate(temp=map(data, pull, temp),\r\n         normal_temp=map(temp, shapiro.test),\r\n         normal_temp=map(normal_temp, tidy),\r\n         normal_temp=map_dbl(normal_temp, pull, p.value))\r\n\r\n\r\n\r\n\r\n\r\nLeitura para Tutorial 12\r\nAntes da próxima aula, por favor leia R 4 Data Science, Capítulo 14 sobre Strings e Tidy Text Mining Capítulo 1\r\n\r\n\r\n\r\nDesafio 5\r\nO Desafio 5 teste as habilidades fundamentais dos tutoriais de testes estatísticos e repetição usando os dados do Censo 2010.\r\nO prazo para entregar Desafio 5 por email com título “[FLS6397] - D5” à minha conta é 22/07/2021. Por favor entregue (i) o arquivo .Rmd (ou .Rnw se preferir), e (ii) o arquivo .html ou .PDF.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:24:37-03:00"
    },
    {
      "path": "Reprodutibilidade.html",
      "title": "Relatórios Reproduzíveis",
      "author": [],
      "contents": "\r\n\r\nContents\r\nIntrodução\r\nCompilando Scripts de R Markdown para PDF\r\nRelatórios escritos em Latex e compilados para PDF\r\nControle de Versões com Git\r\nBibliotecas Reproduzíveis: Renv\r\n\r\nIntrodução\r\nNeste tutorial, vamos ampliar o nosso conhecimento sobre as ferramentas que funcionam com R para gerar facilmente relatórios reproduzíveis. Como estas ferramentas podem ser acessadas abertamente pelo público (‘open-source’), podemos aproveitar sem custo do mesmo ambiente assim como milhões de outros pesquisadores.\r\nA primeira ferramenta é o Latex, um programa que compila scripts para o formato bem conhecido de PDF. Sua maior vantagem é a profissionalização dos nossos relatórios - PDF é um formato comum para compartilhar relatórios finais porque eles não podem ser fácilmente editados, e - em contraste com HTML - têm páginas distintas.\r\nPara instalar o Latex no seu computador, o jeito mais fácil é rodar o seguinte código em R (existem muitas versões/distribuições; você não precisa repetir a instalação caso já tenha esta ferramenta no seu computador):\r\n\r\n\r\ninstall.packages('tinytex')\r\ntinytex::install_tinytex()\r\n\r\n\r\nSiga as instruções - por exemplo, vão aparecer alguns ‘erros’ mas pode continuar sem problema; eles não são problemáticos. Depois da instalação, feche o seu R e abra de novo.\r\nUm passo adicional para verificar que tudo está bem configurado é acessar em RStudio: Tools -> Global Options -> Sweave -> ‘Weave Rnw files using:’ e escolher ‘knitr’.\r\nCompilando Scripts de R Markdown para PDF\r\nA nossa primeira tarefa não exige nenhuma programação adicional. Na mesma forma que compilamos os nossos documentos com ‘Knit para HTML’ ou ‘Knit para Doc’, a instalação de Latex habilita uma nova opção: ‘Knit para PDF’.\r\nAbra um script anterior seu de R Markdown (.Rmd) que compila bem para HTML. Em seguida, escolha a opcão ‘Knit para PDF’. Fácil, não? Como aparece o novo documento? Mais profissional, eu espero.\r\nNo futuro, você fica no controle: você poderá compilar para qualquer formato que seja o mais apropriado para o seu relatório.\r\nRelatórios escritos em Latex e compilados para PDF\r\nO que acontece quando compilamos o nosso R Markdown para PDF? O R traduz o nosso script de R Markdown para a linguagem de Latex - literalmente ele gera um arquivo com extensão “.tex” - e depois o programa de Latex interpreta e compila este .tex para PDF.\r\nIsso funciona bem, mas nós estamos habituados para preparar os nossos documentos na linguagem de R Markdown, que é bom e muito fácil de aprender, mas limitado. Por exemplo, se quisermos controlar em detalhe a formatação ou a paginação, não é possível em R Markdown.\r\nEntão existe uma segunda forma de usar Latex: preparando o nosso script diretamente na linguagem de Latex, e pulando a etapa de R Markdown. O custo é a necessidade de aprender a linguagem de Latex. Dado o uso frequente de Latex no mundo acadêmico para a preparação de manuscritos, artigos e slides, oferecemos aqui um guia preliminar.\r\nO nome para a combinação de R + Latex é ‘Knitr’. Há quatro diferenças fundamentais em usar Knitr em vez de R Markdown.\r\n1. O Tipo de Arquivo\r\nOs nossos scripts de R Markdown têm extensão “.Rmd” e um cabeçalho simples. Quando preparamos um script diretamente em Latex, ele precisa uma extensão “.Rnw”. É sempre melhor começar com um modelo, então começa com “File -> New File -> R Sweave” (ignore o significativo de ‘Sweave’, é um nome velho).\r\nO documento abre com três linhas de texto; os mínimos necessários para um documento de Latex:\r\n\\documentclass{article} - O tipo de documento que queremos gerar, o mais comum é um article (artigo). Também é possível criar livros inteiros, ou apresentações, que vamos discutir em breve.\r\n\\begin{document} - um indicador do começo do conteúdo a ser inserido no documento final. Antes disso podemos inserir pacotes/bibliotecas e parâmetros. Depois, digitamos diretamente o seu texto na gramática de Latex.\r\n\\end{document} - um indicador do fim do documento. Texto depois ele será ignorado.\r\n2. Compilando o Documento PDF\r\nEscreva algo simples (eg. “Hello World!”) depois de \\begin{document}. Já é um script de Latex/Knitr válido. Como criamos o nosso PDF final a partir desse script? Observe que quando abrimos um arquivo “.Rnw” não há a opção ‘Knit’ em Rstudio. O equivalente é “Compile PDF”. Experimente! Pode demorar um pouco para compilar pela primeira vez, mas, no fim, o R deve ter produzido um PDF, o qual estará salvo na pasta do seu projeto.\r\n3. Formatação de Chunks de Código\r\nA importância de Knitr é que os nossos relatórios contêm os produtos da nossa análise de dados, igual como R Markdown. Mas um ponto chato é que os ‘chunks’ que guardam o nosso código de R têm uma definição diferente.\r\nPara inserir um novo chunk, use a opção ‘+ C’ (ao lado de ‘Run’) em Rstudio. Ele aparece um pouco diferente:\r\n\r\n<<>>=\r\nx <- 1+1\r\nx\r\n@\r\n\r\nMas, em Rmarkdown, isto significa exatamente o mesmo que:\r\n```{r}\r\nx <- 1 + 1\r\nx\r\n```\r\nComo em Rmarkdown, podemos especificar os mesmos parâmetros dos chunks entre <<>>.\r\n<<echo=F, warning=F, message=F>>\r\nFinalmente, você se lembra do nosso código in-line? Ele também é um pouco diferente em Latex/Knitr - precisamos inserir o nome do objeto desejado dentro de \\Sexpr{ }.\r\n4. Linguagem de Formatação de Texto Simples\r\nOs três primeiros passos são ajustes simples que podemos aprender e realizar em alguns minutos. A quarta diferença é a mais complexa, mas também a mais poderosa. É o uso da linguagem do Latex fora dos chunks para formatar o nosso texto.\r\nO Latex é mais preciso e controlado do que o Rmarkdown. O padrão para formatar é \\comando{texto}, onde o ‘texto’ é impresso no documento, enquanto o ‘comando’ significa o tipo de formatação desejada.\r\n\\textbf{Bold} - Bold\r\n\\textit{italic} - italic\r\n\\underline{underline} -  underline\r\nPara gerar listas não ordenadas:\r\n\\begin{itemize}\r\n\\item Texto 1\r\n\\item Texto 2\r\n\\end{itemize}\r\nPara gerar listas ordenadas:\r\n\\begin{enumerate}\r\n\\item Texto 1\r\n\\item Texto 2\r\n\\end{enumerate}\r\nTítulos e Seções numeradas:\r\n\\section{Titulo 1}\r\n\\subsection{Subtitulo 1}\r\n\\subsubsection{Subsubtitulo 1}\r\nTítulos e Seções não-numeradas:\r\n\\section*{Titulo 1}\r\n\\subsection*{Subtitulo 1}\r\n\\subsubsection*{Subsubtitulo 1}\r\nEquações em Latex\r\nAs equações são escritas da mesma forma que em Rmarkdown. Na verdade, o Rmarkdown usa o formato de Latex.\r\n$$\\alpha^2 + \\beta^2 = \\chi^2$$ \\[\\alpha^2 + \\beta^2 = \\chi^2\\]$$\\frac{\\sqrt{1}}{2} * \\frac{a}{2b} = \\frac{a}{4b}$$ \\[\\frac{\\sqrt{1}}{2} * \\frac{a}{2b} = \\frac{a}{4b}\\]\r\n$$\\sum_0^{10} x = ...$$ \\[\\sum_0^{10} x = ...\\]\r\nMais detalhes aqui.\r\nAcentos em Latex\r\nPara inserir acentos, basta abrir um pacote antes de begin{document} e digitar como normal:\r\n\\usepackage[latin1]{inputenc}\r\nPágina inicial do documento\r\nO nosso tipo de documento ‘article’ nos permite especificar um título e várias outras características antes de \\begin{document}.\r\n\\title{Relatório}\r\n\\author{My Name}\r\n\\date{Maio 2019}\r\nSe você compilar o seu PDF agora, não verá nenhuma diferença. Por que? Porque não tem nada diferente entre begin{document} e end{document}. Para fazer estas características aparecem em nosso documento, precisamos inserir o seguinte código depois de \\begin{document}:\r\n\\maketitle\r\nAgora, seu resultado deve ser um documento muito profissional.\r\nTabelas em Knitr\r\nO Latex tem uma gramática de tabelas um pouco chata de preparar. Mas é bem raro precisar digitar ela manualmente. Como em R Markdown, o jeito mais fácil de gerar uma tabela é criar um tibble em R e passar para a função kable(). Após inseri-lo dentro de um chunk no seu documento .Rnw, precisamos fazer apenas mais uma coisa para que ele pereça bonito: adicione o parâmetro results='asis' no header do chunk, como já fizemos com as tabelas de regressão com stargazer no tutorial anterior.\r\n\r\n<<results='asis'>>=\r\nlibrary(\"tidyverse\")\r\nlibrary(\"nycflights13\")\r\n\r\nflights %>% group_by(origin) %>%\r\n  summarize(atraso_media=mean(dep_delay, na.rm=T)) %>% \r\n  kable()\r\n@\r\n\r\n\r\n\r\norigin\r\n\r\n\r\natraso_media\r\n\r\n\r\nEWR\r\n\r\n\r\n15.10795\r\n\r\n\r\nJFK\r\n\r\n\r\n12.11216\r\n\r\n\r\nLGA\r\n\r\n\r\n10.34688\r\n\r\n\r\nFiguras em Knitr\r\nPara inserir gráficos gerados pelo seu código, use a mesma lógica de R Markdown. Crie o gráfico em ggplot dentro de um chunk em seu documento de .Rnw. Não precisamos ajustar nenhum parâmetro do chunk, mas existem várias opções úteis para figuras para controlar o título e tamanho para integrar com Latex.\r\n\r\n<<fig.cap=\"Titulo de Figura\", fig.height=4, fig.width=4>>=\r\nflights %>% group_by(origin) %>%\r\n  summarize(atraso_media=mean(dep_delay, na.rm=T)) %>% \r\n  ggplot() +\r\n  geom_col(aes(x=origin, y=atraso_media))\r\n@\r\n\r\n\r\n\r\n\r\nFigure 1: Titulo de Figura\r\n\r\n\r\n\r\nPara aprender mais sobre Latex, pode explorar as guias aqui, aqui e aqui.\r\nApresentações\r\nO Latex é muito útil para apresentações (slides) profissionais. Há várias opções, mas o mais comum é o estilo ‘beamer’. Comece no início com:\r\n\\documentclass{beamer}\r\nPara definir cada ‘slide’ de nossa apresentação, use o seguinte formato:\r\n\\begin{frame}\r\n\\frametitle{Título do Slide}\r\nTexto, conteúdo normal\r\nMais texto\r\n\\end{frame}\r\nTemos que repetir esta estrutura para cada slide, então 10 slides vão precisar de 10 \\begin{frame} e 10 \\end{frame}. Se quiser inserir uma pausa, aguardando o usuário para avançar, é só inserir \\pause no local apropriado no slide.\r\nPara incluir imagens de um arquivo local salvo na mesma pasta do seu script .Rnw coloque:\r\n\\usepackage{graphicx} - antes de \\begin{document}\r\n\\includegraphics[width=\\linewidth]{image.png} - na página/slide onde a imagem deve aparecer\r\nBibliografias\r\nUm elemento central da pesquisa é a citação das nossas fontes. Uma citação é simplesmente um conjunto de dados sobre um livro/artigo ou outra fonte que colocamos numa nota de rodapé ou apêndice, e um atalho para a citação no texto (frequentemente autor-ano, ex. ‘(Arrow 1961)’).\r\nFelizmente, existe um formato padrão para o armazenamento das citações - num arquivo com extensão ‘.bib’. Várias programas (Zotero, Mendeley, EndNote etc.) podem te ajudar a gerir as citações e gerar arquivos ‘.bib’ que listam todas as citações, então não precisamos nos preocupar com o conteúdo deles. Apenas para referência, eles contém conteúdo tipo:\r\n@article{Arrow1961,\r\nauthor={Arrow, Kenneth J. and Leonid Hurwicz and Hirofumi Uzawa},\r\ntitle={Constraint qualifications in maximization problems},\r\njournal={Naval Research Logistics Quarterly},\r\nvolume={8},\r\nyear=1961,\r\npages={175-191}\r\n}\r\nO elemento crucial aqui é a primeira entrada depois do primeiro ‘{’: ‘Arrow1961’ - isso é o atalho que vamos usar para citar este artigo para não repetir toda essa informação cada vez que queremos citar o mesmo artigo.\r\nEm R Markdown, o uso de bibliografias é assim:\r\nSalve o arquivo “.bib” na pasta do seu projeto.\r\nNo cabeçalho, coloque uma linha “bibliography: nome_do_arquivo.bib” para conectar com o arquivo que contém as citações:\r\n\r\n---\r\ntitle: \"Exemplo\"\r\noutput: html_document\r\nbibliography: nome_do_arquivo.bib\r\n---\r\n\r\nNo lugar apropriado no seu texto simples, quando quiser fazer referência à citação, insira [@Arrow1961], com o atalho apropriado para a citação desejada.\r\nAs referências vão aparecer no final do documento, então pode ser útil inserir um título, como ## Referências no final do documento.\r\nEm Knitr (com o Latex) o uso de bibliografias é um pouco mais complexo infelizmente:\r\nSalve o arquivo “.bib” na pasta do seu projeto.\r\nAntes de ‘\\begin{document}’ coloque o seguinte código:\r\n\\usepackage[backend=bibtex, style=authoryear]{biblatex}\r\n\\addbibresource{Nome_do_Arquivo.bib}\r\nNo lugar desejado do seu texto simples, quando quiser fazer referência à citação, insira \\cite{Arrow1961}, ou \\parencite{Arrow1961} se quiser a citação em parênteses, com o atalho apropriado para a citação desejada.\r\nNo final do seu documento (imediatamente antes de ‘\\end{document}’), coloque \\printbibliography.\r\nCompile o seu script para PDF duas vezes, para que o R consiga incorporar as citações.\r\n\r\nExercício 1: Praticando o Latex\r\nUsando o formato “.Rnw”, crie um PDF com texto simples usando pelo menos cinco das formatações acima (bold, itálico, etc.).\r\nAdicione a famosa equação do teorema de Pitágoras no seu documento.\r\nAdicione uma tabela simples no PDF usando o banco de dados de weather, resumindo o total de precipitação por mês.\r\n\r\n\r\nMostrar Código\r\n\r\nweather %>% group_by(month) %>%\r\n  summarize(precip=sum(precip, na.rm=T))\r\n\r\n\r\nAdicione um gráfico simples usando o banco de dados weather, ilustrando temperatura média por aeroporto.\r\n\r\n\r\nMostrar Código\r\n\r\nweather %>% group_by(month) %>%\r\n  summarize(temp=mean(temp, na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_line(aes(x=month, y=temp, group=1))\r\n\r\n\r\nVerifique que o seu documento compila sem erro para PDF.\r\nAjuste o seu script “.Rnw” acima para gerar uma apresentação do class ‘beamer’ e coloque o texto, a equação, a tabela, e o gráfico em slides diferentes. Compile para PDF de novo.\r\n\r\nControle de Versões com Git\r\nVocê já criou um arquivo com nome ‘Final_v23_depois_edits_4b_final_final_v2.doc’? Dois anos depois, você poderia identificar qual versão do documento você enviou para uma colega?? Rastrear mudanças em nossos scripts é desafiador, sobretudo com análises complexas. Felizmente, programadores desenvolveram várias ferramentas para ajudar. Vamos usar ‘Git’ em conjunto com Github, o parceiro online de Git.\r\nO Git/Github é um sistema de controle de versões com três objetivos:\r\nDisponibilizar um backup online dos seus arquivos;\r\nControlar as versões dos scripts e rastrear mudanças;\r\nPermitir a divulgação/colaboração online com colegas.\r\nPara utilizá-lo (se ainda não executei):\r\n1. Instale git no seu computador.\r\n2. Crie uma conta no site github.\r\n3. Em RStudio, faça um restart e encontre a aba de ‘Terminal’ ao lado de ‘Console’ e ‘R Markdown’. No terminal, digite o seguinte (duas linhas separadas e sequenciais), substituindo os valores de usuário e email com eles que você usou para abrir a conta de Github online:\r\ngit config --global user.name 'usuario_de_github'git config --global user.email 'nome@email.com'\r\nA Lógica de Git\r\nO Git é poderoso e complexo. Neste momento, faz sentido usar apenas as capacidades relevantes para nós. A ideia pode ser separada em dois fluxos de trabalho:\r\nControle de Versões: Vamos organizar cada mudança substancial em nosso código em um pacote, e indicar para o Git uma breve descrição sobre as mudanças feitas. Ex. “Criando gráfico de pontos dos vôos”. Assim, no futuro, podemos identificar o pacote relevante por meio da sua descrição e ver, linha por linha, quais as mudanças feitas neste pacote. Definir um pacote com o Git se chama um commit.\r\nBackup/Colaboração Online: Vamos enviar todos os pacotes do mesmo projeto para um servidor online (um ‘repositório’) do Github, o qual podemos compartilhar com colegas, ou acessar de um outro computador. Enviar um código ao repositório em Git se chama um push.\r\nQuando temos mais de uma pessoa trabalhando no mesmo script, o nosso repositório serve como a versão ‘atual’ do script. Isso exige um pouco mais de esforço - temos que baixar a versão atual do repositório antes de trabalhar nele - fazer um pull em Git - e subir as nossas mudanças - com push - quando terminado para disponibilizar para outros.\r\nO gráfico abaixo mostra como funciona o fluxo de código com as várias comandas:\r\n\r\nAntes de descrever o que fazer em RStudio, recomendamos adotar o seguinte fluxo de atividades para trabalhar com Git. Cada vez que desejar trabalhar no seu projeto, siga estes passos:\r\nAbra o projeto em RStudio (o Git funciona apenas dentro de um projeto)\r\nExecute Pull da versão mais recente do repositório do Github\r\nFaça as suas mudanças/melhorias no código/relatório em RStudio\r\nQuando completar uma tarefa discreta, execute Commit do pacote de mudanças com uma descrição apropriada\r\nExecute Push do seu pacote/commit para o repositório online\r\nFeche o projeto\r\nPreparando Git/Github em RStudio\r\nExiste um pequeno custo fixo para configurar um projeto para trabalhar com o Git/Github. O primeiro passo é criar um repositório online no Github. Após o login no https://github.com, vá para a aba ‘respositories’, e crie o seu próprio repositório com a opção ‘New’ no site. Dê ao repositório um nome e uma descrição, e finalize sua criação. Verifique se existe um link na página principal do seu repositório, tipo “https://github.com/Usuario/repositorio.git”, o qual você deve copiar. (Se não ver o link, tente clicar na botão verde ‘Code’. Ele deve aparecer em seguida).\r\nUma alternativa é baixar um repositório de outra pessoa (se você encontrar alguma dificuldade na etapa anterior, por exemplo). Neste caso, você pode usar um repositório do meu github, através do link https://github.com/JonnyPhillips/repositorio_clone.git.\r\nAgora, vamos usar o link para conectar o Github com RStudio. Após abrir o RStudio, vamos ‘clonar’ este repositório online para um projeto local no seu computador: File -> New Project -> Version Control -> Git. Agora, cole o link do repositório de Github como ‘Repository URL’, e escolha o nome da pasta onde o repositório/projeto será baixado no seu computador.\r\nAgora, temos um projeto ligado ao nosso repositório do Github. Na aba ‘files’ do RStudio agora aparece a lista de arquivos no repositório/projeto. Crie um novo script de R Markdown (.Rmd). Neste novo arquivo, coloque o código seguinte para produzir um gráfico super simples. Salve com nome “teste.Rmd” na mesma pasta do seu projeto/repositório (deve ser a pasta padrão).\r\n\r\n\r\nlibrary(\"tidyverse\")\r\nlibrary(\"nycflights13\")\r\n\r\nflights %>% ggplot() + \r\n  geom_density(aes(dep_delay)) +\r\n  xlim(0, 100)\r\n\r\n\r\n\r\nVá para o repositório na sua conta no github - veja que o arquivo ‘teste.Rmd’ não está presente e só fica no seu computador local. Para sincronizar e ‘atualizar’ o repositório online do github com as nossa mudanças locais, temos que fazer o seguinte:\r\nAbra a aba ‘Git’ em Rstudio (normalmente na mesma região de ‘Environment’)\r\nClique no checkbox ao lado de cada arquivo que você deseja atualizar, incluindo ‘teste.Rmd’. O ‘Status’ vai mudar para “A” (que significa ‘Adicionado’), ou caso você esteja atualizando um arquivo já existente, “M” (que significa ‘Modificado’). Cada vez que você ajusta e salva um arquivo no projeto local, o arquivo vai aparecer na lista nessa aba de Git.\r\nClique em ‘Commit’ na aba do Git e veja que abriu uma caixa que mostra todas as diferenças entre o nosso código local e o código do arquivo no github online: aditivos em verde e remoções em vermelho. A única coisa que temos que fazer nessa caixa é adicionar uma mensagem que descreve o conteúdo da mudança feita, ex. “Adicionar gráfico de atrasos”, e clicar em Commit. Quando terminado, feche as caixas. A aba do Git deve mostrar a notícia de “Your branch is ahead of ‘origin/master’ by 1 commit”. Isso significa que o seu novo script foi cadastrado no fluxo de trabalho do projeto (o controle de versão), mas ainda não foi sincronizado online.\r\nO passo final é clicar em Push na aba ‘Git’ em RStudio (a seta verde). Isso sincroniza as mudanças contidas no commit com a versão dos arquivos online, disponibilizando elas para os seus colegas.\r\nAgora vá para o repositório na sua conta do Github online, atualize a página, e confira que o novo arquivo ‘teste.Rmd’ aparece. (É possível que você precisa aguardar alguns minutos para ele aparecer, mas normalmente é imediato). Se você entrar no link de ‘1 commit’ na linha azul na página do seu repositório, poderá ver todos os seus commits anteriores, e os detalhes individuais de mudanças de código em cada um. Também é possível clicar em cada arquivo e depois em ‘History’ (histórico) rastrear todas as mudanças anteriores.\r\nParabéns, agora o seu trabalho está seguro com um backup online, documentado com o histórico de versões rastreável, e acessível para todos os seus colegas!\r\n\r\n\r\nHabilidade Básica de Programação: Privacidade\r\nO padrão para Github é que os repositórios fiquem abertos para todo o mundo acessar, encorajando transparência e reprodutibilidade. Mas tome cuidado para verificar que o seu projeto não contém dados confidenciais ou alugma outra informação pessoal.\r\nSe você tiver uma conta paga, ou uma conta estudantil, pode tornar a sua conta privada e adicionar apenas os colaboradores desejados - em Github vá para Settings -> Make Private.\r\n\r\n\r\n\r\nExercício 2: Usando Git\r\nCrie um novo repositório na sua conta de Github e conecte (‘clonar’) com um novo projeto no seu RStudio.\r\nCopie o seu script de Exercício 1 acima (o .Rnw) para a pasta local do seu projeto novo criado no passo anterior.\r\nAdicione mais um gráfico ao seu script, mostrando a umidade média por mês do banco de dados de weather.\r\n\r\n\r\nMostrar Código\r\n\r\nweather %>% group_by(month) %>%\r\n  summarize(humid=mean(humid, na.rm=T)) %>%\r\n  ggplot() +\r\n  geom_line(aes(x=month, y=humid, group=1))\r\n\r\n\r\nUsando a aba de Git, execute Commit com a versão atualizada do script Rnw, atribuindo uma descrição apropriada.\r\nExecute Push das mudanças para o seu repositório do Github online. Verifique que o novo arquivo está atualizado no repositório da sua conta deo Github.\r\n\r\nBibliotecas Reproduzíveis: Renv\r\nA última ferramenta listada aqui é menos usada, mas atende um problema que já é familiar para vocês - complexidades e conflitos de bibliotecas e funções de R. Essa seção é optativa porque não é essencial para o seu trabalho pessoal, mas pode ser útil para projetos maiores e colaborativos.\r\nO que vai acontecer se mandamos o nosso script de R Markdown para uma colega? Vai funcionar? Será reprodutível? Frequentemente não. Mesmo que eles tenham exatamente os mesmos arquivos e usem a mesma versão de R e RStudio, não podemos garantir que eles terão acesso às mesmas funções que usamos para fazer nosso script. Lembre-se que tivemos que instalar cada uma das nossas bibliotecas (install.packages()) mas essas linhas de instalação não ficam em nosso script - se o receptor não tiver feito o mesmo ou tiver uma versão diferente de uma biblioteca (eles estão atualizadas frequentemente), nosso código vai quebrar.\r\nPara resolver isso, podemos usar o pacote renv para garantir reprodutibilidade de bibliotecas. O renv salva as bibliotecas na pasta do seu projeto, e documenta as versões que estão sendo usadas. No modo interativo, rodamos a função init() uma vez quando começamos um novo projeto. Em seguida, quando você desejar gravar o status das suas bibliotecas (normalmente depois de abrir novas bibliotecas com library()), você pode usar snapshot().\r\n\r\n\r\n#install.packages(\"renv\")\r\nlibrary(renv)\r\ninit()\r\n\r\n\r\n\r\n\r\nlibrary(tidyverse)\r\nsnapshot()\r\n\r\n\r\nSe você mander o seu script para uma outra pessoa, ou outra máquina, para recuperar exatamente as bibliotecas e versões que você tinha instalada, é só rodar restore() na nova maquina e tudo será instalado de forma idêntica.\r\nMuita coisa, não é mesmo? Mas, quando combinados, o R, o Latex, o Git e o Renv permitem relatórios reproduzíveis que garantem o histórico e a integridade do seu relatório ou artigo profissional.\r\n\r\nLeitura para Tutorial 11\r\nAntes da próxima aula, por favor leia R 4 Data Science, Capítulos 20 e 21 sobre Vetores e Iteração\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:25:32-03:00"
    },
    {
      "path": "Tabelas.html",
      "title": "Construindo Tabelas",
      "description": "Comunicando os nossos Dados\n",
      "author": [],
      "contents": "\r\n\r\nContents\r\nTabelas Estáticas\r\nTabelas Interativas\r\nMudando a Unidade de Observação (Pivot_wide, Pivot_longer)\r\nVoltando ao R Base Brevemente\r\nTotais para Tabelas\r\n\r\nTabelas Estáticas\r\nAté agora, trabalhamos com as tabelas padrões fornecidas pelo R e a opção df_print: paged no cabeçalho. É só digitar o nome do tibble num chunk e no resultado vai aparecer uma tabela com navegação por página e colunas. Mas existem várias funções de ‘formatação’ que traduz o conteúdo de um tibble para uma tabela bonita no documento final. Elas funcionam como qualquer outra função do R e ficam no final de nosso fluxo de pipes.\r\nA primeira função de formatação de tabelas se chama kable e fica num pacote se chama knitr, então temos que instalar (uma vez só, e depois comentado) e abrir o pacote:\r\n\r\n\r\nlibrary(\"tidyverse\")\r\nlibrary(\"tidylog\")\r\nlibrary(\"nycflights13\")\r\n#install.packages(\"knitr\")\r\nlibrary(\"knitr\")\r\n\r\n\r\n\r\n\r\n\r\nAgora, seguimos qualquer tibble com %>% kable() e o R vai produzir uma tabela estática. Tabelas estáticas são simples e limpas, mas geram um risco grande - uma tabela grande será impressa na íntegra. Com um banco de dados de milhares de linhas, isso gera um arquivo enorme e difícil de navegar. Então temos que tomar cuidado: é a sua responsibilidade filter ou slice a sua tabela anteriormente para que o resultado final tenha o tamanho desejado.\r\n\r\n\r\nflights %>% filter(dest==\"ANC\") %>%\r\n  kable()\r\n\r\nyear\r\nmonth\r\nday\r\ndep_time\r\nsched_dep_time\r\ndep_delay\r\narr_time\r\nsched_arr_time\r\narr_delay\r\ncarrier\r\nflight\r\ntailnum\r\norigin\r\ndest\r\nair_time\r\ndistance\r\nhour\r\nminute\r\ntime_hour\r\n2013\r\n7\r\n6\r\n1629\r\n1615\r\n14\r\n1954\r\n1953\r\n1\r\nUA\r\n887\r\nN587UA\r\nEWR\r\nANC\r\n418\r\n3370\r\n16\r\n15\r\n2013-07-06 16:00:00\r\n2013\r\n7\r\n13\r\n1618\r\n1615\r\n3\r\n1955\r\n1953\r\n2\r\nUA\r\n887\r\nN572UA\r\nEWR\r\nANC\r\n404\r\n3370\r\n16\r\n15\r\n2013-07-13 16:00:00\r\n2013\r\n7\r\n20\r\n1618\r\n1615\r\n3\r\n2003\r\n1953\r\n10\r\nUA\r\n887\r\nN567UA\r\nEWR\r\nANC\r\n418\r\n3370\r\n16\r\n15\r\n2013-07-20 16:00:00\r\n2013\r\n7\r\n27\r\n1617\r\n1615\r\n2\r\n1906\r\n1953\r\n-47\r\nUA\r\n887\r\nN559UA\r\nEWR\r\nANC\r\n388\r\n3370\r\n16\r\n15\r\n2013-07-27 16:00:00\r\n2013\r\n8\r\n3\r\n1615\r\n1615\r\n0\r\n2003\r\n1953\r\n10\r\nUA\r\n887\r\nN572UA\r\nEWR\r\nANC\r\n434\r\n3370\r\n16\r\n15\r\n2013-08-03 16:00:00\r\n2013\r\n8\r\n10\r\n1613\r\n1615\r\n-2\r\n1922\r\n1953\r\n-31\r\nUA\r\n887\r\nN559UA\r\nEWR\r\nANC\r\n411\r\n3370\r\n16\r\n15\r\n2013-08-10 16:00:00\r\n2013\r\n8\r\n17\r\n1740\r\n1625\r\n75\r\n2042\r\n2003\r\n39\r\nUA\r\n887\r\nN528UA\r\nEWR\r\nANC\r\n404\r\n3370\r\n16\r\n25\r\n2013-08-17 16:00:00\r\n2013\r\n8\r\n24\r\n1633\r\n1625\r\n8\r\n1959\r\n2003\r\n-4\r\nUA\r\n887\r\nN534UA\r\nEWR\r\nANC\r\n428\r\n3370\r\n16\r\n25\r\n2013-08-24 16:00:00\r\n\r\nUma alternativa de filter ou slice que é útil para apresentar uma amostra aleatória da sua tabela (e também para realizar amostras aleatórias em estudos empíricas) é sample_n(). Escolhemos o número de observações desejadas, e o R vai selecionar aleatoriamente este número de linhas da tabela (Observe que as observações mudam cada vez que rodamos/compilamos o nosso documento):\r\n\r\n\r\nflights %>% sample_n(4) %>%\r\n  kable()\r\n\r\nyear\r\nmonth\r\nday\r\ndep_time\r\nsched_dep_time\r\ndep_delay\r\narr_time\r\nsched_arr_time\r\narr_delay\r\ncarrier\r\nflight\r\ntailnum\r\norigin\r\ndest\r\nair_time\r\ndistance\r\nhour\r\nminute\r\ntime_hour\r\n2013\r\n11\r\n24\r\n1856\r\n1845\r\n11\r\n2150\r\n2152\r\n-2\r\nDL\r\n2391\r\nN941DL\r\nJFK\r\nTPA\r\n137\r\n1005\r\n18\r\n45\r\n2013-11-24 18:00:00\r\n2013\r\n7\r\n8\r\n904\r\n905\r\n-1\r\n1152\r\n1225\r\n-33\r\nDL\r\n874\r\nN341NB\r\nLGA\r\nMIA\r\n147\r\n1096\r\n9\r\n5\r\n2013-07-08 09:00:00\r\n2013\r\n9\r\n7\r\n1552\r\n1600\r\n-8\r\n1821\r\n1847\r\n-26\r\nB6\r\n543\r\nN627JB\r\nEWR\r\nPBI\r\n132\r\n1023\r\n16\r\n0\r\n2013-09-07 16:00:00\r\n2013\r\n10\r\n2\r\n1447\r\n1430\r\n17\r\n1542\r\n1533\r\n9\r\nEV\r\n4696\r\nN16981\r\nEWR\r\nMHT\r\n37\r\n209\r\n14\r\n30\r\n2013-10-02 14:00:00\r\n\r\n\r\nHabilidade Básica de Programação: Aleatoriedade reproduzível\r\nÉ comum usar funções aleatórias em R para gerar distribuições, simulações e amostras. A função sample_n() seleciona linhas aleatórias cada vez que rodamos o código ou compilar o relatório com ‘knit’. Isto é útil, mas impede um dos nossos objetivos - a reprodutibilidade, dado que o relatório final fica diferente depois de cada compilação e não temos condições de saber se a variação seja por causa de um erro no código ou por causa da aleatorização.\r\nA solução é a ‘aleatoriedade reproduzível’: Imediatamente antes de roder sample_n() (fora do pipe, numa linha única), especificamos um ‘seed’. Um seed é como um identificador de uma sequência aleatória. Ele é associado a uma seleção aleatória, mas fixa - ou seja, toda vez que rodarmos o código, a sequência aleatória produzida será a mesma. Para especificar um seed aribtrário, eu sempre gosto de usar um CEP, mas pode escolher qualquer número; não significa nada:\r\n\r\n\r\nset.seed(05508)\r\nflights %>% sample_n(4) \r\n\r\n\r\nExecute este código (tudo o código, incluindo o set.seed) umas vezes e confirme que o resultado não muda.\r\n\r\nCompile o seu script atual com ‘Knit’: como fica a tabela? O número de linhas não é problemático, mas as colunas saiam do lado direito da página… Também é a nossa responsibilidade limitar o número de colunas para incluir apenas elas que cabem no espaço da tabela final com select. Dificilmente queremos ver todas as colunas de uma tabela.\r\n\r\n\r\nflights %>% sample_n(8) %>%\r\n  select(month, day, dep_time, carrier, flight, origin, dest) %>%\r\n  kable()\r\n\r\nmonth\r\nday\r\ndep_time\r\ncarrier\r\nflight\r\norigin\r\ndest\r\n4\r\n5\r\n1256\r\nUS\r\n1459\r\nLGA\r\nCLT\r\n5\r\n22\r\n610\r\nUA\r\n303\r\nJFK\r\nSFO\r\n8\r\n19\r\n1031\r\nB6\r\n2602\r\nJFK\r\nBUF\r\n9\r\n12\r\n1056\r\nEV\r\n5309\r\nLGA\r\nBGR\r\n10\r\n28\r\n1625\r\nEV\r\n4684\r\nEWR\r\nSDF\r\n1\r\n6\r\n604\r\nAA\r\n1837\r\nLGA\r\nMIA\r\n8\r\n8\r\n1415\r\nB6\r\n213\r\nJFK\r\nLGB\r\n12\r\n15\r\n1015\r\nMQ\r\n3644\r\nLGA\r\nATL\r\n\r\nA tabela no relatório final melhorou? Sim. Mas porque investimos todo este esforço? Exige mais trabalho para limitar as linhas e colunas, e não temos as botões para navegar que recebemos com a opção df_print: paged… Há três motivos para trabalhar com tabelas estáticas:\r\nA tabela é apropriada para publicações em que interatividade não é possível, e funciona melhor com relatórios em Word e PDF (que vamos ver em breve). Compile o seu script para Word (‘Knit to Word’ com a flecha ao lado de ‘Knit’) para ver o resultado. Deve ser muito melhor. Lembre-se que um artigo ou dissertação publicada exige tabelas estáticas.\r\nA necessidade de selecionar as observações e colunas necessárias nos motiva a pensar bem sobre o desenho e a estruta mais apropriados para a nossa tabela. Incluir a tabela inteira cada vez gera documentos grandes e pesados.\r\nA função kable é muito mais flexível do que as tabelas padrões de R. Podemos personalizar todos os elementos da tabela. Vejamos alguns exemplos abaixo.\r\nEm primeiro lugar, podemos especificar o título da tabela com a opção caption:\r\n\r\n\r\nflights %>% sample_n(8) %>%\r\n  select(month, day, dep_time, carrier, flight, origin, dest) %>%\r\n  kable(caption=\"Tabela de 8 voos aleatórios\")\r\n\r\nTable 1: Tabela de 8 voos aleatórios\r\nmonth\r\nday\r\ndep_time\r\ncarrier\r\nflight\r\norigin\r\ndest\r\n4\r\n12\r\n2037\r\nEV\r\n5667\r\nEWR\r\nROC\r\n9\r\n25\r\n1849\r\nUA\r\n693\r\nLGA\r\nORD\r\n3\r\n1\r\n2250\r\nB6\r\n112\r\nJFK\r\nBUF\r\n2\r\n28\r\n906\r\nUA\r\n235\r\nEWR\r\nMIA\r\n5\r\n23\r\nNA\r\nEV\r\n4576\r\nEWR\r\nGRR\r\n12\r\n30\r\n1508\r\nUA\r\n249\r\nEWR\r\nTPA\r\n10\r\n26\r\n834\r\n9E\r\n3841\r\nJFK\r\nPHL\r\n7\r\n29\r\n2057\r\nDL\r\n1854\r\nLGA\r\nFLL\r\n\r\nMais profissional. Em segundo lugar, o kable deixa mais fácil formatar os resultados númericos - para arredondar os números com as tabelas padrões temos que manualmente usar mutate para mexer com os valores atuais da tabela. Mas é melhor manter os números ‘corretos’ e completos no tibble, e só ajustar a apresentação na tabela final. Conseguimos realizar uma formatação do número de dígitos com kable com a opção digits, que define o número de casas decimais. A nossa tabela até agora só contém variáveis numéricas do tipo ’integer (integral), então vamos calcular velocidade para ilustrar isso:\r\n\r\n\r\nflights %>% sample_n(8) %>%\r\n  mutate(velocidade=distance/air_time) %>%\r\n  select(month, day, dep_time, carrier, flight, origin, dest, velocidade) %>%\r\n  kable(digits=1)\r\n\r\nmonth\r\nday\r\ndep_time\r\ncarrier\r\nflight\r\norigin\r\ndest\r\nvelocidade\r\n7\r\n10\r\n853\r\nB6\r\n15\r\nJFK\r\nSFO\r\n7.7\r\n2\r\n13\r\n1010\r\nUS\r\n75\r\nEWR\r\nPHX\r\n7.7\r\n10\r\n13\r\n1603\r\n9E\r\n3523\r\nJFK\r\nORD\r\n6.7\r\n12\r\n7\r\n1659\r\nUA\r\n1199\r\nEWR\r\nLAX\r\n6.2\r\n10\r\n25\r\n958\r\nEV\r\n4255\r\nEWR\r\nCHS\r\n6.1\r\n3\r\n6\r\n1542\r\nUA\r\n1200\r\nEWR\r\nSAN\r\n7.1\r\n10\r\n11\r\n747\r\nMQ\r\n3052\r\nJFK\r\nTPA\r\n7.3\r\n12\r\n1\r\n726\r\nB6\r\n461\r\nLGA\r\nPBI\r\n7.3\r\n\r\nEm terceiro lugar, é comum que a descrição das nossas variáveis na tabela final seja diferente que o nome da variável no script de programação. Isto é natural; em nosso script temos que escrever os nomes das variáveis muitas vezes e um atalho é muito mais eficiente, mas na tabela final o leitor tem que entender o significado da variável com apenas a informação na tabela. O kable permite especificar nomes de colunas mais complexas, sem renomear elas no tibble original. Por exemplo, o significado de ‘dep_time’ não é óbvio:\r\n\r\n\r\nflights %>% sample_n(8) %>%\r\n  select(month, day, dep_time, carrier, flight, origin, dest) %>%\r\n    kable(col.names=c(\"Mês\",\"Dia\",\"Hora de Partida\",\"Companhia Aérea\",\"Voo\",\"Origem\",\"Destino\"))\r\n\r\nMês\r\nDia\r\nHora de Partida\r\nCompanhia Aérea\r\nVoo\r\nOrigem\r\nDestino\r\n1\r\n3\r\n1640\r\nB6\r\n139\r\nJFK\r\nRSW\r\n9\r\n25\r\n918\r\nEV\r\n4092\r\nEWR\r\nIND\r\n2\r\n19\r\n1144\r\nDL\r\n1689\r\nLGA\r\nPBI\r\n5\r\n20\r\n1454\r\nUS\r\n2177\r\nLGA\r\nDCA\r\n2\r\n3\r\nNA\r\nMQ\r\n4670\r\nLGA\r\nBNA\r\n4\r\n29\r\n1923\r\n9E\r\n3899\r\nJFK\r\nCLE\r\n8\r\n5\r\n1817\r\nDL\r\n1715\r\nLGA\r\nMSY\r\n9\r\n25\r\n622\r\nB6\r\n675\r\nJFK\r\nMSY\r\n\r\nFinalmente, podemos formatar os números em português (ou qualquer outro local) com o argumento format.args:\r\n\r\n\r\nflights %>% sample_n(8) %>%\r\n  mutate(velocidade=distance/air_time) %>%\r\n  select(month, day, dep_time, carrier, flight, origin, dest, velocidade) %>%\r\n    kable(digits=1, format.args=list(big.mark=\".\", decimal.mark=\",\"))\r\n\r\nmonth\r\nday\r\ndep_time\r\ncarrier\r\nflight\r\norigin\r\ndest\r\nvelocidade\r\n3\r\n15\r\n658\r\nEV\r\n4.547\r\nEWR\r\nBNA\r\n6,9\r\n9\r\n17\r\n1.307\r\nUA\r\n1.401\r\nEWR\r\nMIA\r\n6,9\r\n9\r\n29\r\n1.554\r\nDL\r\n221\r\nLGA\r\nATL\r\n7,1\r\n2\r\n3\r\n1.758\r\nB6\r\n1.016\r\nJFK\r\nBOS\r\n5,1\r\n4\r\n6\r\n2.032\r\nUA\r\n1.071\r\nEWR\r\nBQN\r\n7,4\r\n7\r\n26\r\n1.430\r\nFL\r\n349\r\nLGA\r\nATL\r\n6,0\r\n6\r\n21\r\n913\r\nVX\r\n161\r\nEWR\r\nLAX\r\n7,6\r\n9\r\n18\r\n904\r\nB6\r\n5\r\nEWR\r\nFLL\r\n7,3\r\n\r\nPara mais opções de kable, leia aqui, e para saber mais ainda veja o pacote kableExtra aqui.\r\nNote que existe a opção de gerar tabelas ‘manuais’ diretamente em R markdown, fora de um chunk (detalhes aqui). Não recomendo isso porque a sintaxe é chata para digitar, não temos controle de formatação, e não podemos acessar e transformar o conteúdo no futuro. Se você precisa gerar uma tabela rápida, sempre é recomendado que você gera uma pequena tabela com tibble() e manda para kable(), por exemplo:\r\n\r\n\r\ntibble(Função=c(\"kable\",\"opção df_print: paged\",\"datatable\"),\r\n       Utilidade=c(\"Word/PDF, relatórios estáticos\",\"HTML, relatórios interativos simples\",\"HTML, relatórios interativos complexos\")) %>%\r\n  kable()\r\n\r\nFunção\r\nUtilidade\r\nkable\r\nWord/PDF, relatórios estáticos\r\nopção df_print: paged\r\nHTML, relatórios interativos simples\r\ndatatable\r\nHTML, relatórios interativos complexos\r\n\r\nTabelas Interativas\r\nA terceira entrada na tabela acima é mais uma opção para gerar tabelas. A função datatable() (do pacote DT) tem o mesmo objetivo da opção df_print: paged; gerar tabelas interativas em HTML. O problema com df_print: paged é que ela não tem opções para personalizar a tabela final e temos que fazer toda a preparação manualmente. O datatable é uma função mais avançada que permite personalizações infinitas.\r\nNão entramos nos detalhes de datatable no tutorial; vocês podem explorar a documentação detalhada aqui. Mas vamos mostrar um exemplo com funcionalidade avançado (filtros de colunas, formatação de números, e coloração de células por valor, neste caso velocidade acima de 7,5):\r\n\r\n\r\n#install.packages(\"DT\")\r\nlibrary(DT)\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nflights %>% \r\n  sample_n(100) %>%\r\n  mutate(velocidade=distance/air_time) %>%\r\n  select(month, day, dep_time, carrier, flight, origin, dest, velocidade) %>%\r\n  datatable()\r\n\r\n\r\n\r\n\r\n\r\nflights %>% \r\n  sample_n(100) %>%\r\n  mutate(velocidade=distance/air_time) %>%\r\n  select(month, day, dep_time, carrier, flight, origin, dest, velocidade) %>%\r\n  datatable(colnames=c(\"Mês\",\"Dia\",\"Hora de Partida\",\"Companhia Aérea\",\"Voo\",\"Origem\",\"Destino\",\"Velocidade\"), \r\n            caption=\"Tabela de 100 voos aleatórios\",\r\n            filter='top') %>%\r\n  formatRound(\"velocidade\",1) %>%\r\n  formatStyle('velocidade',\r\n    backgroundColor = styleInterval(7, c('white', 'orange'))\r\n  )\r\n\r\n\r\n\r\n\r\nExercício 1: Tabelas Bonitas\r\nGere uma tabela estática de duração (air_time) média dos voos de cada aeoporto de origem, ordenado de menor a maior duração. Inclua um título e a formatação apropriada na sua tabela.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% group_by(origin) %>%\r\n  summarize(media_air_time=mean(air_time,na.rm=T)) %>%\r\n  arrange(media_air_time) %>%\r\n  kable(digits=1, format.args=list(big.mark=\".\", decimal.mark=\",\"),\r\n        caption=\"Duração média dos voos de Nova Iorque em 2013\")\r\n\r\n\r\nIdentifique os voos de origem ‘EWR’ no dia 1 de Abril com decolagem antes de 6h. Prepare uma tabela estática que mostra as variáveis dep_time, dep_delay, carrier, flight, dest, air_time, distance. Inclua um título e a formatação apropriada.\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(month==4 & day==1 & origin==\"EWR\" & dep_time<600) %>%\r\n  select(dep_time, dep_delay, carrier, flight, dest, air_time, distance) %>%\r\n  kable(caption=\"Voos de EWR no dia 4 de abril, antes de 6h\")\r\n\r\n\r\nDuplique a tabela de questão 2, mas agora mande o resultado para uma tabela interativa de datatable. (Não se preocupe com a formatação).\r\n\r\n\r\nMostrar Código\r\n\r\nflights %>% filter(month==4 & day==1 & origin==\"EWR\" & dep_time<600) %>%\r\n  select(dep_time, dep_delay, carrier, flight, dest, air_time, distance) %>%\r\n  datatable(caption=\"Voos de EWR no dia 4 de abril, antes de 6h\")\r\n\r\n\r\nKnit o seu script para HTML e verifique que as tabelas aparecem limpas e claras.\r\n\r\nMudando a Unidade de Observação (Pivot_wide, Pivot_longer)\r\nNós temos trabalhado com uma distinção entre variáveis (colunas) e observações (linhas) fixa. Mas a distinção na prática é mais flexível, e a estrutura/organização dos nossos dados depende do nosso objetivo. As vezes vamos querer virar a nossa tabela (tibble) para que as variáveis se transformem em observações múltiplas, ou vice-versa. Esse tipo de operação é muito útil quando trabalhamos com ou queremos criar dados em painel, ou para uma tabela específica em nosso relatório.\r\nÉ mais fácil demonstar com um exemplo. Veja a tabela de flights com as variáveis origin e dest:\r\n\r\n\r\nflights %>% filter(dest==\"SNA\") %>% \r\n  select(month, day, origin, dest)\r\n\r\n\r\n\r\n\r\n\r\n\r\nA observação é cada voo, e cada variável é um atributo de cada voo - isto é dados de onde o voo partiu, e onde ele chegou. Mas ambos as variáveis origin e dest são a mesma coisa: aeroportos. Podemos imaginar um banco de dados em que desagregamos os voos em dois ‘eventos’ - decolagens e chegadas. Neste banco de dados alternativo, cada observação é um evento e cada voo tem duas entradas (observações, linhas), um decolagem e uma chegada. Isso pode ser útil, por exemplo, se tenhamos muitos dados sobre cada evento/aeroporto, por exemplo os dados de controle de tráfego aéreo.\r\nDe Largo para Longo\r\nPara ‘virar’ (pivot) a nossa tabela para o formato mais ‘longo’, usamos a função pivot_longer. O objetivo de pivot_longer é converter colunas em observações - no nosso exemplo, converter o evento único “voo” em dois eventos diferentes, pousos e decolagens. Mas não queremos mudar todas as colunas (algumas pertencem ao voo inteiro, como distância, duração); temos que especificar quais colunas queremos virar no argumento cols. É sempre mais que uma coluna, então temos que especificar as colunas dentro de c(). As outras colunas nào mencionadas em cols são colunas ‘identificadoras’ que queremos duplicar para as novas linhas (em nosso exemplo os dados que pertencem ao voo e não ao aeroporto).\r\nComo uma primeira tentativa, o código abaixo é suficiente para virar o nosso tibble:\r\n\r\n\r\nflights %>% filter(dest==\"SNA\") %>% \r\n  select(month, day, origin, dest) %>% \r\n  pivot_longer(cols=c(origin, dest))\r\n\r\n\r\n\r\n\r\n\r\n\r\nNote que agora o nosso banco de dados tem dobro o número de linhas que antes. Cada observação é um evento (decolagen/chegada). As duas colunas ‘origin’ e ‘dest’ agora são linhas separadas, identificadas na colona name, e o aeroporto que antes era um valor abaixo de ‘origin’ ou ‘dest’ na coluna tem a sua própria coluna value. Ou seja, em vez de ler os detalhes do primeiro voo horizontalmente no tibble original, agora lemos verticalmente - origem EWR, destino ANC.\r\nO que falta aqui é que os nomes das colunas name e value são genéricas e não ajudam entender e descrever os dados. Então é importante renomear as colunas como parte de pivot_longer. Há duas colunas para nomear: a coluna de name que contém os nomes de colunas no tibble original (a direção de viagem), que especificamos com o argumento names_to, e a coluna de valor que contém os valores no tibble original (os aeroportos), que especificamos com o argumento values_to.\r\n\r\n\r\nflights %>% filter(dest==\"SNA\") %>% \r\n  select(month, day, origin, dest) %>% \r\n  pivot_longer(cols=c(origin, dest), \r\n               names_to=\"Direção\", \r\n               values_to=\"Aeroporto\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nAgora, recebemos o mesmo resultado, mas é bem mais fácil interpretar, pois a natureza do evento é cadastrada na coluna ‘Direção’ e o local do evento fica na coluna ‘Aeroporto’.\r\nMas ainda existe um problema sério aqui - como sabemos que a primeira linha - o voo com origem em EWR no dia 1 de janeiro é o mesmo voo que chegou no aeroporto SNA no mesmo dia? Não sabemos isso porque não temos dados suficientes para identificar os mesmos voos em linhas separadas. Pode ser que o voo da primeira linha de origem é o mesmo voo na linha 3 ou linha 120.\r\nO problema é que não temos um identificador único para cada voo no banco de dados. Isto é importante para todos os bancos de dados, mas sobretudo quando usamos um ‘pivot’ para mudar a unidade de análise, pois temos que restrear a divisão de uma observação em duas.\r\nPara resolver o problema, temos que incluir colunas suficientes no tibble original. Usando distinct do tutorial 3, podemos verificar que as colunas month, day, dep_time, carrier, flight, origin e dest são suficientes para identificar cada voo único. O banco de dados original tem 336,776 linhas, ígual o resultado do distinct com estas variáveis:\r\n\r\n\r\nflights %>% distinct(month, day, dep_time, carrier, flight, origin, dest) \r\n\r\n\r\nAgora podemos refazer o pivot_longer incluindo estas variáveis identificadores:\r\n\r\n\r\nflights_longo <- flights %>% filter(dest==\"SNA\") %>% \r\n  select(month, day, dep_time, carrier, flight, origin, dest) %>% \r\n  pivot_longer(cols=c(origin, dest), \r\n               names_to=\"Direção\", \r\n               values_to=\"Aeroporto\")\r\n\r\n\r\n\r\n\r\n\r\n\r\nPerfeito! Agora, dá para rastrear cada voo: Voo UA1496 as 0646 no dia 1 de janeiro tem duas entradas - origem em EWR e chegada em SNA.\r\nDe Longo para Largo\r\nÉ comum que recebemos um banco de dados no formato longo e queremos virar (pivot) para o formato largo. Ou seja, tornar observações em variáveis. Imagine-se que recebemos do fornecedor o banco de dados flights_longo produzido no chunk anterior. Como reproduzimos o nosso banco de dados bem conhecido, flights, no formato mais largo?\r\nA função pivot_wider é exatamante o inverso de pivot_longer. Em vez de especificar as colunas que queremos virar, especificamos as colunas de ‘identificação’ que não queremos virar no argumento id_cols; em vez da coluna nova, especificamos a coluna original que contém os nomes das colunas novas, no argumento names_from; e em vez de valores noves, especificamos a coluna de onde vão sair os valores que vão formar as colunas novas (no argumento values_from).\r\nNote que com pivot_longer os argumentos names_to e values_to precisam de aspas porque são colunas novas que não existem em nosso tibble. No pivot_wider os argumentos names_from e values_from são colunas atuais em nosso tibble, então não precisam de aspas.\r\n\r\n\r\nflights_longo %>% pivot_wider(id_cols=c(month, day, dep_time, carrier, flight), \r\n                              names_from=Direção, \r\n                              values_from=Aeroporto)\r\n\r\n\r\n\r\n\r\n\r\n\r\nVeja que o resultado aqui tem metade das linhas de flights_longo, e o mesmo número do nosso banco de dados original. O R peguou os valores da coluna ‘Direção’ e criou uma coluna para cada valor único (uma para ‘origin’, uma para ‘dest’). Os valores destas duas novas colunas são preenchidas da coluna ‘Aeroporto’.\r\nUm atalho para simplificar aqui é quando queremos virar todas as colunas exceto eles mencionados em names_from e values_from, podemos pular a especificação de id_cols:\r\n\r\n\r\nflights_longo %>% pivot_wider(names_from=Direção, \r\n                              values_from=Aeroporto)\r\n\r\n\r\nEssas duas funções de pivot são mais avançadas, mas as vezes são essenciais para gerar a estrutura e formato da tabela desejada. É comum que o resultado da nossa análise em R é em formato ‘larga’, mas seria mais bonito imprimir no relatório final no formato ‘longo’. Podemos usar pivot_longer para rapidamente produzir a tabela desejada. Similarmente, na semana que vem, aprendemos que os gráficos exigem um formato específico - frequentemente o formato ‘longo’ - e estas novas habilidades ajudam bastante.\r\n\r\nExercício 2: Virando Tabelas\r\nUse pivot_longer para virar a tabela flights mais longa, para que cada voo tem duas observações - uma para a hora de partida (dep_time) e uma outra para a hora de chegada (arr_time).\r\n\r\n\r\nMostrar Código\r\n\r\nflights_hora_longo <- flights %>% pivot_longer(c(arr_time, dep_time),\r\n                         names_to=\"Direção\",\r\n                         values_to=\"Hora\")\r\n\r\n\r\nUsando o seu resultado de questão 1, gere uma tabela estática de 10 linhas selecionadas aleatoriamente por R, mostrando as variáveis carrier, flight, origin, dest e as colunas novas que você gerou na questão 1.\r\n\r\n\r\nMostrar Código\r\n\r\nflights_hora_longo %>% \r\n  select(carrier, flight, origin, dest, Direção, Hora) %>%\r\n  sample_n(10) %>%\r\n  kable(caption=\"Tabela de cada Partida e Chegada\")\r\n\r\n\r\nUsando o seu resultado de questão 1, use pivot_wider para recuperar o banco de dados original de flights. Verifique que os números de colunas e linhas são íguais.\r\n\r\n\r\nMostrar Código\r\n\r\nflights_recuperado <- flights_hora_longo %>% pivot_wider(names_from=\"Direção\",\r\n                                                         values_from=\"Hora\")\r\n\r\n\r\n\r\nVoltando ao R Base Brevemente\r\nAs funçoes de filter, select, mutate etc. e o nosso pipe %>% que compõem o tidyverse têm cerca de 5 anos de idade, mas o R tem mais de 25 anos de idade. O que os usuários fizeram antes do tidyverse?\r\nExistem várias formas de interagir e manipular dados em R, mas nada muda os básicos: existem um script, objetos que podemos salvar, e funções que transformam objetos. Também trabalhamos mais frequentemente com um data.frame, que é um tibble um pouco mais básico.\r\nA maior diferença quando trabalhamos no mundo do ‘R básico’ é na forma em que acessamos e transformamos os valores dentro de um data.frame. Não usamos uma sequência de ações/verbos para separar cada passo; temos que usar uma sintaxe e símbolos bem específicos.\r\nNote que nada nesta seção do tutorial é necessário, e encorajamos vocês a trabalhar dentro do tidyverse sempre que possível, para criar análises mais simples, transparentes e reproduizíveis. Porém, as vezes temos que trabalhar com usuários ou pacotes fora do tidyverse, então é útil entender os conceitos básicos, e também ajuda a entender como o R funciona atrás do interface.\r\nOs símbolos mais importantes no R base são os colchetes. Depois de um data.frame, eles significam que queremos ajustar as colunas e/ou as linhas. Dentro dos colchetes, tem dois ‘espaços’; o primeiro para mexer com as linhas, e o segundo para mexer com as colunas, separado por vírgula.\r\n\r\n\r\nflights[ , ]\r\n\r\n\r\nO que inserimos nestes espaços? Vamos começar com as linhas e deixar o espaço para colunas branco. Podemos escolher as linhas para manter por número (como slice) ou por condição (como filter):\r\n\r\n\r\nflights[1:5, ]\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nflights[distance==200, ]\r\n\r\nError in eval(expr, envir, enclos): object 'distance' not found\r\n\r\nHmm, o primeiro funcionou bem, mas o distance==200 não deu certo. As condições no R base são idênticas às que usamos no tidyverse, isso não é o problema. O problema é que no R base, o R não sabe o que significa distance. Ele busca para um objeto (um data.frame) se chama distance, mas realmente distance é uma coluna dentro do objeto flights. Mesmo que começamos com flights, temos que informar R que distance fica dentro de flights de novo (o motivo para exigir a repetição do objeto é que podemos querer no futuro filtrar uma tabela baseado no conteúdo de uma segunda tabela). Digitamos isso assim, separando o data.frame e a coluna com o símbolo $:\r\n\r\n\r\nflights[flights$distance==200, ]\r\n\r\n\r\n\r\n\r\n\r\n\r\nAgora funcionou. Como escolhemos colunas em R base? Usamos o segundo espaço, depois da vírgula, para escrever os nomes das colunas desejadas, agora - e em contraste ao tidyverse - em aspas e dentro de um vetor, c():\r\n\r\n\r\nflights[flights$distance==200, c(\"month\",\"day\", \"dep_time\",\"origin\",\"dest\")]\r\n\r\n\r\n\r\n\r\n\r\n\r\nCompare isso com o equivalente no tidyverse:\r\n\r\n\r\nflights %>% filter(distance==200) %>%\r\n  select(month, day, dep_time, origin, dest)\r\n\r\n\r\nQual você prefere? Para a maioria de tarefas, sobretudo para tarefas mais complexas, é mais intuitivo e transparente usar o tidyverse.\r\nTotais para Tabelas\r\nEm alguns momentos os símbolos de R base voltam no tidyverse também. Por exemplo, se quisermos gerar tabelas resumidas, às vezes é útil adicionar uma linha resumida no final, por exemplo um total ou uma média. Para adicionar mais uma linha no final da nossa tabela, podemos usar a função add_row() no fluxo de pipes, e especificar um argumento para cada coluna na tabela, com o nome de coluna na esquerda do símbolo de íguais, e o valor desejado na direita. É comum adicionar uma linha ‘Total’:\r\n\r\n\r\nflights %>% group_by(origin) %>%\r\n  tally() %>%\r\n  add_row(origin=\"Total\", n=sum(n))\r\n\r\nError in sum(n): invalid 'type' (closure) of argument\r\n\r\nCom toda a nossa intuição do tidyverse isso deve funcionar. Mas infelizmente (e por motivos bem chatos da programação de add_row) não dá. O problema é que o sum(n) na funcão add_row não sabe procurar a colona n na tabela atual (o tibble resultante do último pipe). Ele precisa uma dica para onde procurar. Dentro do tidyverse o símbolo ‘.’ significa o tibble atual, e já aprendemos do R base que o $ nos permitimos especificar uma coluna de um tibble. Então em vez de usar o atalho n, temos que usar .$n. Um conjunto de símbolos estranhos, mas funciona:\r\n\r\n\r\nflights %>% group_by(origin) %>%\r\n  tally() %>%\r\n  add_row(origin=\"Total\", n=sum(.$n))\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\n\r\nLeitura para Tutorial 6\r\nAntes da próxima aula, por favor leia R 4 Data Science, Capítulo 3 e ggplot2: Elegant Graphics for Data Analysis, Capítulos 1-5\r\n\r\n\r\n\r\nDesafio 2\r\nO Desafio 2 teste a sua capacidade de organizar, resumir, agrupar, e apresentar um banco de dados para produzir um relatório bonito e claro em HTML.\r\nO prazo para entregar Desafio 2 por email com título “[FLS6397] - D2” à minha conta é 02/06/2021, antes da aula. Por favor entregue (i) o arquivo .Rmd, e (ii) o arquivo .html.\r\n\r\n\r\n\r\n\r\n",
      "last_modified": "2023-10-06T20:26:22-03:00"
    }
  ],
  "collections": []
}
